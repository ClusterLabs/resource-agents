diff -urN linux-orig/fs/gfs_locking/lock_gulm/gio_wiretypes.h linux-patched/fs/gfs_locking/lock_gulm/gio_wiretypes.h
--- linux-orig/fs/gfs_locking/lock_gulm/gio_wiretypes.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gio_wiretypes.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,416 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+#ifndef __gio_wiretypes_h__
+#define __gio_wiretypes_h__
+
+/* an attempt to do something about tracking changes to the protocol over
+ * the wires.
+ * If I was really cute, this would be effectivily a checksum of this file.
+ */
+#define GIO_WIREPROT_VERS (0x67000011)
+
+/*****************Error codes.
+ * everyone uses these same error codes.
+ */
+#define gio_Err_Ok              (0)
+#define gio_Err_BadLogin        (1001)
+#define gio_Err_BadCluster      (1003)
+#define gio_Err_BadConfig       (1004)
+#define gio_Err_BadGeneration   (1005)
+#define gio_Err_BadWireProto    (1019)
+
+#define gio_Err_NotAllowed      (1006)
+#define gio_Err_Unknown_Cs      (1007)
+#define gio_Err_BadStateChg     (1008)
+#define gio_Err_MemoryIssues    (1009)
+
+#define gio_Err_PushQu          (1010)	/* client should never see this one */
+#define gio_Err_TryFailed       (1011)
+#define gio_Err_AlreadyPend     (1013)
+#define gio_Err_Canceled        (1015)
+
+#define gio_Err_NoSuchFS        (1016)
+#define gio_Err_NoSuchJID       (1017)
+#define gio_Err_NoSuchName      (1018)
+
+/* next free error code: 1002 1012 1014 1020 */
+
+/*
+ * Error:  just sort of a generic error code thing.
+ *    uint32: gERR
+ *    uint32: opcode that this is in reply to. (can be zeros)
+ *    uint32: error code
+ */
+#define gulm_err_reply (0x67455252)	/* gERR */
+
+#define gulm_nop (0x674e4f50)	/* gNOP */
+
+/********************* Core *****************/
+/* 
+ * login request
+ *    uint32: gCL0
+ *    uint32: proto version
+ *    string: cluster ID
+ *    string: My Name
+ *    uint64: generation number
+ *    uint32: config CRC
+ *    uint32: rank
+ * login reply
+ *    uint32: gCL1
+ *    uint64: generation number
+ *    uint32: error code
+ *    uint32: rank
+ *    uint8:  ama
+ *   If I am the Master or Arbitrating and there are no errors, A
+ *   serialization of the current nodelist follows. And a client or slave
+ *   is connecting (not resources).
+ *
+ * logout request:
+ *    uint32: gCL2
+ *    string: node name
+ *    uint8:  S/P/A/M/R
+ * logout reply:   Don't seem to use this....
+ *    uint32: gCL3
+ *    uint32: error code
+ *
+ * resource login request:
+ *    uint32: gCL4
+ *    uint32: proto version
+ *    string: cluster ID
+ *    string: resource name
+ *    uint32: options
+ *  login reply (gCL1) is sent in return.
+ *
+ * beat req
+ *    uint32: gCB0
+ *    string: My Name
+ * beat rpl
+ *    uint32: gCB1
+ *    uint32: error code
+ *
+ * Membership Request
+ *    uint32: gCMA
+ *    string: node name
+ *
+ * Membership update
+ *    uint32: gCMU
+ *    string: node name
+ *    IPv6:   IP
+ *    uint8:  Current State
+ *
+ * Membership list request info.
+ *    uint32: gCMl
+ *
+ * Membership list info.
+ *    uint32: gCML
+ *    list_start_marker
+ *     string: node name
+ *     IPv6:   IP
+ *     uint8:  state
+ *     uint8:  laststate
+ *     uint8:  mode (S/P/A/M/C)
+ *     uint32: missed beats
+ *     uint64: last beat
+ *     uint64: delay avg
+ *     uint64: max delay
+ *    list_stop_marker
+ *
+ * Request Resource info
+ *    uint32: gCR0
+ *
+ * Resource list info
+ *    uint32: gCR1
+ *    list_start_marker
+ *     string: name
+ *    list_stop_marker
+ *
+ * Force node into Expired:
+ *    uint32: gCFE
+ *    string: node name
+ *
+ * Core state request:
+ *    uint32: gCSR
+ *
+ * Core state changes:
+ *    uint32: gCSC
+ *    uint8:  state  (slave, pending, arbitrating, master)
+ *  If state == Slave, then the next two will follow.
+ *    IPv6:   MasterIP
+ *    string: MasterName
+ *
+ * Core shutdown req:
+ *    uint32: gCSD
+ *
+ * Switch core from current state into Pending:
+ *    uint32: gCSP
+ *
+ */
+#define gulm_core_login_req  (0x67434c00)	/* gCL0 */
+#define gulm_core_login_rpl  (0x67434c01)	/* gCL1 */
+#define gulm_core_logout_req (0x67434c02)	/* gCL2 */
+#define gulm_core_logout_rpl (0x67434c03)	/* gCL3 */
+#define gulm_core_reslgn_req (0x67434c04)	/* gCL4 */
+#define gulm_core_beat_req   (0x67434200)	/* gCB0 */
+#define gulm_core_beat_rpl   (0x67434201)	/* gCB1 */
+#define gulm_core_mbr_req    (0x67434d41)	/* gCMA */
+#define gulm_core_mbr_updt   (0x67434d55)	/* gCMU */
+#define gulm_core_mbr_lstreq (0x67434d6c)	/* gCMl */
+#define gulm_core_mbr_lstrpl (0x67434d4c)	/* gCML */
+#define gulm_core_mbr_force  (0x67434645)	/* gCFE */
+#define gulm_core_res_req    (0x67435200)	/* gCR0 */
+#define gulm_core_res_list   (0x67435201)	/* gCR1 */
+#define gulm_core_state_req  (0x67435352)	/* gCSR */
+#define gulm_core_state_chgs (0x67435343)	/* gCSC */
+#define gulm_core_shutdown   (0x67435344)	/* gCSD */
+#define gulm_core_forcepend  (0x67435350)	/* gCSP */
+
+/* in the st field */
+#define gio_Mbr_Logged_in  (0x05)
+#define gio_Mbr_Logged_out (0x06)
+#define gio_Mbr_Expired    (0x07)
+#define gio_Mbr_Killed     (0x08)
+#define gio_Mbr_OM_lgin    (0x09)
+
+/* in the ama field */
+#define gio_Mbr_ama_Slave       (0x01)
+#define gio_Mbr_ama_Master      (0x02)
+#define gio_Mbr_ama_Pending     (0x03)
+#define gio_Mbr_ama_Arbitrating (0x04)
+#define gio_Mbr_ama_Resource    (0x05)
+#define gio_Mbr_ama_Client      (0x06)
+/* the Client entery is ONLY for mode tracking.
+ * nodelist reply is the only place it is used.
+ */
+
+/* options that affect behavors on services. (resources) */
+#define gulm_svc_opt_important (0x00000001)
+
+/********************* Info Traffic *****************
+ *
+ * Note that for many of these, they can be sent to all of the servers and
+ * will get sane replies.  Some of these can only be sent to specific
+ * servers.
+ *
+ * stats req:
+ *    uint32: gIS0
+ * stats rpl:
+ *    uint32: gIS1
+ *    list start:
+ *       string: key
+ *       string: value
+ *    list stop:
+ * Notes:
+ *  The stats reply is a set of string pairs.  This way the server can send
+ *  whatever things it wants, and the same client code will work for
+ *  anything.
+ *
+ * set verbosity:
+ *    uint32: gIV0
+ *    string: verb flags (with -/+) to [un]set
+ * Note:
+ *  We don't bother with a reply for this.  If the server got it, it works.
+ *  If it didn't, it cannot send an error back anyways.
+ *
+ * close socket:
+ *   uint32: gSC0
+ * Note:
+ *   Tells the server to close this connection cleanly.  We're done with
+ *   it.  This is *not* the same as loging out.  You must login before you
+ *   can logout.  And many commands sent from gulm_tool happen without
+ *   logging in.  These commands would be useful for clients in many cases,
+ *   so I don't want to put a close at the end of them, but if I don't,
+ *   there will be error messages printed on the console when gulm_tool
+ *   calls them.
+ *   So we need a way to close a connection cleanly that has not been
+ *   logged in.
+ *
+ * request slave list:
+ *    uint32: gIL0
+ * slave list replay:
+ *    uint32: gIL1
+ *    list start:
+ *       string: name
+ *       uint32: poller idx
+ *    list stop:
+ */
+#define gulm_info_stats_req      (0x67495300)	/* gIS0 */
+#define gulm_info_stats_rpl      (0x67495301)	/* gIS1 */
+#define gulm_info_set_verbosity  (0x67495600)	/* gIV0 */
+#define gulm_socket_close        (0x67534300)	/* gSC0 */
+#define gulm_info_slave_list_req (0x67494c00)	/* gIL0 */
+#define gulm_info_slave_list_rpl (0x67494c01)	/* gIL1 */
+
+/********************* Lock Traffic *****************
+ * All lock traffic.
+ *
+ * login req:
+ *    uint32: gLL0
+ *    uint32: proto version
+ *    string: node name
+ *    uint8:  Client/Slave
+ * login rpl:
+ *    uint32: gLL1
+ *    uint32: error code
+ *    uint8:  Slave/Master
+ *    xdr of current lock state if no errors and master sending reply
+ *       and you're a slave.
+ *       uh, i think i assume that it is only four bytes in some places.
+ *       Need to look into this...
+ *
+ * logout req:
+ *    uint32: gLL2
+ * logout rpl:
+ *    uint32: gLL3
+ *
+ * select lockspace:
+ *    uint32: gLS0
+ *    raw:    usually just four bytes for lockspace name.
+ *            but can be most anything.
+ *
+ * lock req:
+ *    uint32: gLR0
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  state
+ *    uint32: flags
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ * lock rpl:
+ *    uint32: gLR1
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  state
+ *    uint32: flags
+ *    uint32: error code
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ *
+ * lock state update:
+ *    uint32: gLRU
+ *    string: node name
+ *    uint64: sub id
+ *    raw:    key
+ *    uint8:  state
+ *    uint32: flags
+ *    raw:    lvb -- Only exists if hasLVB flag is true.
+ *
+ * Action req:
+ *    uint32: gLA0
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  action
+ *    raw:    lvb -- Only exists if action is SyncLVB
+ * Action Rpl:
+ *    uint32: gLA1
+ *    raw:    key
+ *    uint64: sub id
+ *    uint8:  action
+ *    uint32: error code
+ *
+ * Action update:
+ *    uint32: gLAU
+ *    string: node name
+ *    uint64: sub id
+ *    raw:    key
+ *    uint8:  action
+ *    raw:    lvb -- Only exists if action is SyncLVB
+ *
+ * Slave Update Rply:   -- for both actions and requests.
+ *    uint32: gLUR
+ *    raw:    key
+ *
+ * Drop lock Callback:
+ *    uint32: gLC0
+ *    raw:    key
+ *    uint64: subid
+ *    uint8:  state
+ *
+ * Drop all locks callback:  This is the highwater locks thing
+ *    uint32: gLC2
+ *
+ * Drop expired locks:
+ *    uint32: gLEO
+ *    string: node name  if NULL, then drop all exp for mask.
+ *    raw:    keymask  if keymask & key == key, then dropexp on this lock.
+ *
+ * Lock list req:
+ *    uint32: gLD0
+ * Lock list rpl:
+ *    uint32: gLD1
+ *    list start mark
+ *     uint8: key length
+ *     raw:   key
+ *     uint8: lvb length
+ *     if lvb length > 0, raw: LVB
+ *     uint32: Holder count
+ *     list start mark
+ *      string: holders
+ *      uint64: subid
+ *      uint8: state
+ *     list stop mark
+ *     uint32: LVB holder count
+ *     list start mark
+ *      string: LVB Holders
+ *      uint64: subid
+ *     list stop mark
+ *     uint32: Expired holder count
+ *     list start mark
+ *      string: ExpHolders
+ *      uint64: subid
+ *     list stop mark
+ *    list stop mark
+ *
+ */
+#define gulm_lock_login_req   (0x674C4C00)	/* gLL0 */
+#define gulm_lock_login_rpl   (0x674C4C01)	/* gLL1 */
+#define gulm_lock_logout_req  (0x674C4C02)	/* gLL2 */
+#define gulm_lock_logout_rpl  (0x674C4C03)	/* gLL3 */
+#define gulm_lock_sel_lckspc  (0x674C5300)	/* gLS0 */
+#define gulm_lock_state_req   (0x674C5200)	/* gLR0 */
+#define gulm_lock_state_rpl   (0x674C5201)	/* gLR1 */
+#define gulm_lock_state_updt  (0x674C5255)	/* gLRU */
+#define gulm_lock_action_req  (0x674C4100)	/* gLA0 */
+#define gulm_lock_action_rpl  (0x674C4101)	/* gLA1 */
+#define gulm_lock_action_updt (0x674C4155)	/* gLAU */
+#define gulm_lock_update_rpl  (0x674c5552)	/* gLUR */
+#define gulm_lock_cb_state    (0x674C4300)	/* gLC0 */
+#define gulm_lock_cb_dropall  (0x674C4302)	/* gLC2 */
+#define gulm_lock_drop_exp    (0x674C454F)	/* gLEO */
+#define gulm_lock_dump_req    (0x674c4400)	/* gLD0 */
+#define gulm_lock_dump_rpl    (0x674c4401)	/* gLD1 */
+#define gulm_lock_rerunqueues (0x674c5152)	/* gLQR */
+
+/* marks for the login */
+#define gio_lck_st_Slave     (0x00)
+#define gio_lck_st_Client    (0x01)
+
+/* state change requests */
+#define gio_lck_st_Unlock    (0x00)
+#define gio_lck_st_Exclusive (0x01)
+#define gio_lck_st_Deferred  (0x02)
+#define gio_lck_st_Shared    (0x03)
+/* actions */
+#define gio_lck_st_Cancel    (0x09)
+#define gio_lck_st_HoldLVB   (0x0b)
+#define gio_lck_st_UnHoldLVB (0x0c)
+#define gio_lck_st_SyncLVB   (0x0d)
+
+/* flags */
+#define gio_lck_fg_Do_CB       (0x00000001)
+#define gio_lck_fg_Try         (0x00000002)
+#define gio_lck_fg_Any         (0x00000004)
+#define gio_lck_fg_NoExp       (0x00000008)
+#define gio_lck_fg_hasLVB      (0x00000010)
+#define gio_lck_fg_Cachable    (0x00000020)
+#define gio_lck_fg_Piority     (0x00000040)
+
+#endif /*__gio_wiretypes_h__*/
+/* vim: set ai cin et sw=3 ts=3 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm.h linux-patched/fs/gfs_locking/lock_gulm/gulm.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,290 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef GULM_DOT_H
+#define GULM_DOT_H
+
+#define GULM_RELEASE_NAME "v6.0.0"
+
+#ifdef MODVERSIONS
+#include <linux/modversions.h>
+#endif				/*  MODVERSIONS  */
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#include <asm/uaccess.h>
+#include <linux/spinlock.h>
+#include <asm/atomic.h>
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/smp_lock.h>
+#include <linux/ctype.h>
+#include <linux/string.h>
+
+#ifndef TRUE
+#define TRUE (1)
+#endif
+
+#ifndef FALSE
+#define FALSE (0)
+#endif
+
+#if (BITS_PER_LONG == 64)
+#define PRIu64 "lu"
+#define PRId64 "ld"
+#define PRIo64 "lo"
+#define PRIx64 "lx"
+#define PRIX64 "lX"
+#define SCNu64 "lu"
+#define SCNd64 "ld"
+#define SCNo64 "lo"
+#define SCNx64 "lx"
+#define SCNX64 "lX"
+#else
+#define PRIu64 "Lu"
+#define PRId64 "Ld"
+#define PRIo64 "Lo"
+#define PRIx64 "Lx"
+#define PRIX64 "LX"
+#define SCNu64 "Lu"
+#define SCNd64 "Ld"
+#define SCNo64 "Lo"
+#define SCNx64 "Lx"
+#define SCNX64 "LX"
+#endif
+
+#include <linux/list.h>
+
+#undef MAX
+#define MAX(a,b) ((a>b)?a:b)
+
+#undef MIN
+#define MIN(a,b) ((a<b)?a:b)
+
+/*  Extern Macro  */
+
+#ifndef EXTERN
+#define EXTERN extern
+#define INIT(X)
+#else
+#undef EXTERN
+#define EXTERN
+#define INIT(X) =X
+#endif
+
+/*  Static Macro  */
+#ifndef DEBUG_SYMBOLS
+#define STATIC static
+#else
+#define STATIC
+#endif
+
+/*  Divide x by y.  Round up if there is a remainder.  */
+#define DIV_RU(x, y) (((x) + (y) - 1) / (y))
+
+#include <linux/lm_interface.h>
+
+#include "gulm_prints.h"
+
+#include "libgulm.h"
+
+#include "handler.h"
+
+/* Some fixed length constants.
+ * Some of these should be made dynamic in size in the future.
+ */
+#define GIO_KEY_SIZE  (48)
+#define GIO_LVB_SIZE  (32)
+#define GIO_NAME_SIZE (32)
+#define GIO_NAME_LEN  (GIO_NAME_SIZE-1)
+
+/* What we know about this filesytem */
+struct gulm_fs_s {
+	struct list_head fs_list;
+	char fs_name[GIO_NAME_SIZE];	/* lock table name */
+
+	lm_callback_t cb;	/* file system callback function */
+	lm_fsdata_t *fsdata;	/* private file system data */
+
+	callback_qu_t cq;
+
+	uint32_t fsJID;
+	uint32_t lvb_size;
+
+	struct semaphore get_lock;	/* I am not 100% sure this is needed.
+					 * But it only hurts performance,
+					 * not correctness if it is
+					 * useless.  Sometime post52, need
+					 * to investigate.
+					 */
+
+	/* Stuff for the first mounter lock and state */
+	int firstmounting;
+	/* the recovery done func needs to behave slightly differnt when we are
+	 * the first node in an fs.
+	 */
+
+	void *mountlock;	/* this lock holds the Firstmounter state of the FS */
+	/* this is because all lock traffic is async, and really at this point
+	 * in time we want a sync behavor, so I'm left with doing something to
+	 * achive that.
+	 *
+	 * this works, but it is crufty, but I don't want to build a huge
+	 * queuing system for one lock that we touch twice at the beginning and
+	 * once on the end.
+	 *
+	 * I should change the firstmounter lock to work like the journal locks
+	 * and the node locks do.  Things are a lot cleaner now with the libgulm
+	 * interface than before. (when the firstmounter lock code was written)
+	 */
+	struct completion sleep;
+
+	/* Stuff for JID mapping locks */
+	uint32_t JIDcount;	/* how many JID locks are there. */
+};
+typedef struct gulm_fs_s gulm_fs_t;
+
+/* What we know about each locktable.
+ * only one now-a-days. (the LTPX)
+ * */
+typedef struct lock_table_s {
+	uint32_t magic_one;
+
+	int running;
+	struct task_struct *recver_task;
+	struct completion startup;
+	struct semaphore sender;
+
+	struct task_struct *sender_task;
+	wait_queue_head_t send_wchan;
+	spinlock_t queue_sender;
+	struct list_head to_be_sent;
+
+	int hashbuckets;
+	spinlock_t *hshlk;
+	struct list_head *lkhsh;
+
+	/* stats
+	 * it may be wise to make some of these into atomic numbers.
+	 * or something.  or not.
+	 * */
+	uint32_t locks_total;
+	uint32_t locks_unl;
+	uint32_t locks_exl;
+	uint32_t locks_shd;
+	uint32_t locks_dfr;
+	uint32_t locks_lvbs;
+	atomic_t locks_pending;
+	/* cannot count expired here. clients don't know this */
+
+	uint32_t lops;		/* just incr on each op */
+
+} lock_table_t;
+
+typedef struct gulm_cm_s {
+	uint8_t myName[64];
+	uint8_t clusterID[256]; /* doesn't need to be 256. */
+	uint8_t loaded;		/* True|False whether we grabbed the config data */
+	uint8_t starts;
+
+	uint32_t handler_threads;	/* howmany to have */
+	uint32_t verbosity;
+
+	uint64_t GenerationID;
+
+	lock_table_t ltpx;
+
+	gulm_interface_p hookup;
+
+} gulm_cm_t;
+
+/* things about each lock. */
+typedef struct gulm_lock_s {
+	struct list_head gl_list;
+	atomic_t count;
+
+	uint32_t magic_one;
+	gulm_fs_t *fs;		/* which filesystem we belong to. */
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen;
+	uint8_t last_suc_state;	/* last state we succesfully got. */
+	char *lvb;
+
+	/* this is true when there is a lock request sent out for this lock.
+	 * All it really means is that if we've lost the master, and reconnect
+	 * to another, this lock needs to have it's request resent.
+	 *
+	 * This now has two stages.  Since a lock could be pending, but still in
+	 * the send queue.  So we don't want to resend requests that haven't
+	 * been sent yet.
+	 *
+	 * we don't handle the master losses here any more.  LTPX does that for
+	 * us.  Should consider removing the dupicated code then.
+	 */
+	int actuallypending;	/* may need to be atomic */
+	int in_to_be_sent;
+
+	enum { glck_nothing, glck_action, glck_state } req_type;
+	/* these three for the lock req.  We save them here so we can rebuild
+	 * the lock request if there was a server failover. (?still needed?)
+	 */
+	unsigned int cur_state;
+	unsigned int req_state;
+	unsigned int flags;
+
+	/* these three for actions. First is the action, next is result, last is
+	 * what threads wait on for the reply.
+	 */
+	int action;
+	int result;		/* ok, both are using this. */
+	struct completion actsleep;
+
+} gulm_lock_t;
+
+/*****************************************************************************/
+/* cross pollenate prototypes */
+
+/* from gulm_lt.c */
+int pack_lock_key(uint8_t *key, uint16_t keylen, uint8_t type,
+		uint8_t *fsname, uint8_t *pk, uint8_t pklen);
+void lt_logout (void);
+int lt_login (void);
+int get_mount_lock (gulm_fs_t * fs, int *first);
+int downgrade_mount_lock (gulm_fs_t * fs);
+int drop_mount_lock (gulm_fs_t * fs);
+int send_drop_all_exp (lock_table_t * lt);
+int send_drop_exp (gulm_fs_t * fs, lock_table_t * lt, char *name);
+
+/*from gulm_core.c */
+void cm_logout (void);
+int cm_login (void);
+void delete_ipnames (struct list_head *namelist);
+
+/* from gulm_fs.c */
+void init_gulm_fs (void);
+void request_journal_replay (uint8_t * name);
+void passup_droplocks (void);
+gulm_fs_t *get_fs_by_name (uint8_t * name);
+void dump_internal_lists (void);
+void gulm_recovery_done (lm_lockspace_t * lockspace,
+			 unsigned int jid, unsigned int message);
+void gulm_unmount (lm_lockspace_t * lockspace);
+void gulm_others_may_mount (lm_lockspace_t * lockspace);
+int gulm_mount (char *table_name, char *host_data,
+		lm_callback_t cb, lm_fsdata_t * fsdata,
+		unsigned int min_lvb_size, struct lm_lockstruct *lockstruct);
+
+extern struct lm_lockops gulm_ops;
+
+#endif				/*  GULM_DOT_H  */
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_core.c linux-patched/fs/gfs_locking/lock_gulm/gulm_core.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_core.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_core.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,255 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "util.h"
+#include "utils_tostr.h"
+
+extern gulm_cm_t gulm_cm;
+
+/* private vars. */
+int cm_thd_running;
+struct completion cm_thd_startup;
+struct task_struct *cm_thd_task;
+
+/**
+ */
+int
+gulm_core_login_reply (void *misc, uint64_t gen, uint32_t error,
+		       uint32_t rank, uint8_t corestate)
+{
+	if (error != 0) {
+		log_err ("Core returned error %d:%s.\n", error,
+			 gio_Err_to_str (error));
+		cm_thd_running = FALSE;
+		return error;
+	}
+
+	if( gulm_cm.GenerationID != 0 ) {
+		GULM_ASSERT(gulm_cm.GenerationID == gen,
+				printk("us: %"PRIu64" them: %"PRIu64"\n",
+					gulm_cm.GenerationID,gen);
+				);
+	}
+	gulm_cm.GenerationID = gen;
+
+	error = lt_login ();
+	if (error != 0) {
+		log_err ("lt_login failed. %d\n", error);
+		lg_core_logout (gulm_cm.hookup);	/* XXX is this safe? */
+		return error;
+	}
+
+	log_msg (lgm_Network2, "Logged into local core.\n");
+
+	return 0;
+}
+
+/**
+ * gulm_core_logout_reply - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_core_logout_reply (void *misc)
+{
+	log_msg (lgm_Network2, "Logged out of local core.\n");
+	return 0;
+}
+
+/**
+ */
+int
+gulm_core_nodechange (void *misc, char *nodename,
+		      struct in6_addr *nodeip, uint8_t nodestate)
+{
+	if (nodestate == lg_core_Fenced) {
+		request_journal_replay (nodename);
+	}
+	/* if me and state is logout, Need to close out things if we can.
+	 */
+	if (gulm_cm.starts && nodestate == lg_core_Logged_out &&
+			strcmp(gulm_cm.myName, nodename) == 0 ) {
+		lt_logout();
+		cm_thd_running = FALSE;
+		lg_core_logout (gulm_cm.hookup);
+		return -1;
+	}
+	return 0;
+}
+
+int gulm_core_statechange (void *misc, uint8_t corestate,
+                           struct in6_addr *masterip, char *mastername)
+{
+	int *cst = (int *)misc;
+	if( misc != NULL ) {
+		if( corestate != lg_core_Slave &&
+				corestate != lg_core_Master ) {
+			*cst = TRUE;
+		}else{
+			*cst = FALSE;
+		}
+	}
+	return 0;
+}
+
+/**
+ */
+int
+gulm_core_error (void *misc, uint32_t err)
+{
+	log_err ("Got error code %d %#x back fome some reason!\n", err, err);
+	return 0;
+}
+
+static lg_core_callbacks_t core_cb = {
+      login_reply:gulm_core_login_reply,
+      logout_reply:gulm_core_logout_reply,
+      nodechange:gulm_core_nodechange,
+      statechange:gulm_core_statechange,
+      error:gulm_core_error
+};
+
+/**
+ * cm_io_recving_thread - 
+ * @data: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+cm_io_recving_thread (void *data)
+{
+	int err;
+
+	daemonize ("gulm_res_recvd");
+	cm_thd_task = current;
+	complete (&cm_thd_startup);
+
+	while (cm_thd_running) {
+		err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, NULL);
+		if (err != 0) {
+			log_err
+			    ("Got an error in gulm_res_recvd err: %d\n", err);
+			if (!cm_thd_running)
+				break;
+			/* 
+			 * Pause a bit, then try to log back into the local
+			 * lock_gulmd.  Keep doing this until an outside force
+			 * stops us. (which I don't think there is any at this
+			 * point.  forceunmount would be one, if we ever do
+			 * that.)
+			 *
+			 * If we are still in the gulm_mount() function, we
+			 * should not retry. We should just exit.
+			 */
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout (3 * HZ);
+
+			while ((err =
+				lg_core_login (gulm_cm.hookup, TRUE)) != 0) {
+				log_err
+				    ("Got a %d trying to login to lock_gulmd.  Is it running?\n",
+				     err);
+				current->state = TASK_INTERRUPTIBLE;
+				schedule_timeout (3 * HZ);
+			}
+		}
+	}			/* while( gulm_cm.cm_thd_running ) */
+
+	complete (&cm_thd_startup);
+	return 0;
+}
+
+/**
+ * cm_logout - 
+ */
+void
+cm_logout (void)
+{
+
+	if (cm_thd_running) {
+		cm_thd_running = FALSE;
+		lg_core_logout (gulm_cm.hookup);
+
+		/* wait for thread to finish */
+		wait_for_completion (&cm_thd_startup);
+	}
+
+}
+
+/**
+ * cm_login - 
+ * 
+ * Returns: int
+ */
+int
+cm_login (void)
+{
+	int err = -1;
+	int cst=TRUE;
+
+	cm_thd_running = FALSE;
+	init_completion (&cm_thd_startup);
+
+	err = lg_core_login (gulm_cm.hookup, TRUE);
+	if (err != 0) {
+		log_err
+		    ("Got a %d trying to login to lock_gulmd.  Is it running?\n",
+		     err);
+		goto exit;
+	}
+	/* handle login reply.  which will start the lt thread. */
+	err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, NULL);
+	if (err != 0) {
+		goto exit;
+	}
+
+	/* do not pass go until Slave(client) or Master */
+	while(cst) {
+		lg_core_corestate(gulm_cm.hookup);
+		err = lg_core_handle_messages (gulm_cm.hookup, &core_cb, &cst);
+		if (err != 0) {
+			goto exit;
+		}
+		if(cst) {
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout (3 * HZ);
+			/* if interrupted, exit */
+		}
+	}
+
+	/* start recver thread. */
+	cm_thd_running = TRUE;
+	err = kernel_thread (cm_io_recving_thread, NULL, 0);
+	if (err < 0) {
+		log_err ("Failed to start gulm_res_recvd. (%d)\n", err);
+		goto exit;
+	}
+	wait_for_completion (&cm_thd_startup);
+
+	err = 0;
+      exit:
+	return err;
+}
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_fs.c linux-patched/fs/gfs_locking/lock_gulm/gulm_fs.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_fs.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_fs.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,620 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "util.h"
+#include "load_info.h"
+#include "handler.h"
+#include "gulm_procinfo.h"
+#include "gulm_jid.h"
+
+/* things about myself */
+extern gulm_cm_t gulm_cm;
+
+/* globals for this file.*/
+uint32_t filesystems_count = 0;
+LIST_HEAD (filesystems_list);
+struct semaphore filesystem_lck;	/* we use a sema instead of a spin here because
+					 * all of the interruptible things we do inside
+					 * of it.
+					 * If i stop doing nasty things within this it doesn't need
+					 * to be a sema.
+					 */
+struct semaphore start_stop_lock;
+atomic_t start_stop_cnt;
+
+/**
+ * init_gulm_fs - 
+ */
+void
+init_gulm_fs (void)
+{
+	init_MUTEX (&filesystem_lck);
+	init_MUTEX (&start_stop_lock);
+	atomic_set (&start_stop_cnt, 0);
+}
+
+/*****************************************************************************/
+struct rjrpf_s {
+	gulm_fs_t *fs;
+	uint8_t *name;
+};
+
+void
+request_journal_replay_per_fs (void *d)
+{
+	struct rjrpf_s *rf = (struct rjrpf_s *) d;
+	uint32_t jid;
+	unsigned int ujid;
+
+	/* lookup jid <=> name mapping */
+	if (find_jid_by_name_and_mark_replay (rf->fs, rf->name, &jid) != 0) {
+		log_msg (lgm_JIDMap,
+			 "In fs (%s), no jid for name (%s) was found.\n",
+			 rf->fs->fs_name, rf->name);
+	} else {
+		log_msg (lgm_JIDMap,
+			 "In fs (%s), jid %d was found for name (%s).\n",
+			 rf->fs->fs_name, jid, rf->name);
+
+		/* all that the replay journal call back into gfs does is malloc
+		 * some memory and add it to a list.  So we really don't need to
+		 * queue that action.  Since that is what gfs is doing.
+		 *
+		 * This will need to change if gfs changes.
+		 *
+		 * Basically, we assume that the callback is non-blocking.
+		 */
+		ujid = jid;
+		rf->fs->cb (rf->fs->fsdata, LM_CB_NEED_RECOVERY, &ujid);
+	}
+
+	kfree (rf->name);
+	kfree (rf);
+
+}
+
+/**
+ * request_journal_replay - give a journal replay request to mounted filesystems
+ * @name: < the name of the node that died.
+ * 
+ * 
+ * Returns: void
+ */
+void
+request_journal_replay (uint8_t * name)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	struct rjrpf_s *rf;
+
+	log_msg (lgm_Always, "Checking for journals for node \"%s\"\n",
+		 name);
+
+	down (&filesystem_lck);
+
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+
+		/* we don't want to process replay requests when we are
+		 * still in the first mounter state.  All the journals are
+		 * getting replayed anyways, and there could be some issue
+		 * with stuff happening twice.
+		 */
+		if (fs->firstmounting)
+			continue;
+
+		/* due to the way the new jid mapping code works, we had to
+		 * move it out of here.
+		 */
+
+		rf = kmalloc (sizeof (struct rjrpf_s), GFP_KERNEL);
+		GULM_ASSERT (rf != NULL,);
+
+		rf->fs = fs;
+		rf->name = kmalloc (strlen (name) + 1, GFP_KERNEL);
+		GULM_ASSERT (rf->name != NULL,);
+		memcpy (rf->name, name, strlen (name) + 1);
+
+		qu_function_call (&fs->cq, request_journal_replay_per_fs, rf);
+
+	}
+	up (&filesystem_lck);
+}
+
+/**
+ * passup_droplocks - 
+ */
+void
+passup_droplocks (void)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		qu_drop_req (&fs->cq, fs->cb, fs->fsdata, LM_CB_DROPLOCKS, 0,
+			     0);
+		/* If this decides to block someday, we need to change this function.
+		 */
+	}
+	up (&filesystem_lck);
+}
+
+/**
+ * dump_internal_lists - 
+ * 
+ */
+void
+dump_internal_lists (void)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		log_msg (lgm_Always, "Handler queue for %s\n", fs->fs_name);
+		display_handler_queue (&fs->cq);
+		/* other lists? */
+	}
+	up (&filesystem_lck);
+}
+
+/**
+ * get_fs_by_name - 
+ * @name: 
+ * 
+ * 
+ * Returns: gulm_fs_t
+ */
+gulm_fs_t *
+get_fs_by_name (uint8_t * name)
+{
+	struct list_head *tmp;
+	gulm_fs_t *fs = NULL;
+	down (&filesystem_lck);
+	list_for_each (tmp, &filesystems_list) {
+		fs = list_entry (tmp, gulm_fs_t, fs_list);
+		if (strcmp (name, fs->fs_name) == 0) {
+			up (&filesystem_lck);
+			return fs;
+		}
+	}
+	up (&filesystem_lck);
+	return NULL;
+}
+
+/*****************************************************************************/
+
+/**
+ * clear_locks - 
+ * 
+ * quick check to see if there was leaking
+ * should I panic on these? or just complain?
+ * 
+ * Returns: void
+ */
+void
+clear_locks (void)
+{
+	int i;
+	lock_table_t *lt = &gulm_cm.ltpx;
+
+	for (i = 0; i < lt->hashbuckets; i++) {
+		struct list_head *lcktmp, *lckfoo;
+		spin_lock (&lt->hshlk[i]);
+		list_for_each_safe (lcktmp, lckfoo, &lt->lkhsh[i]) {
+			gulm_lock_t *lck = NULL;
+			lck = list_entry (lcktmp, gulm_lock_t, gl_list);
+			/* need to relelase it. umm, should any even exist? */
+			log_err ("AH! Rogue lock buffer! refcount:%d\n",
+				 atomic_read (&lck->count));
+
+			if (lck->lvb) {
+				log_err ("AH! Rogue lock buffer with LVB!\n");
+				kfree (lck->lvb);
+			}
+
+			list_del (lcktmp);
+			kfree (lck);
+
+		}
+		spin_unlock (&lt->hshlk[i]);
+	}
+	kfree (lt->hshlk);
+	lt->hshlk = NULL;
+	kfree (lt->lkhsh);
+	lt->lkhsh = NULL;
+}
+
+/*****************************************************************************/
+/**
+ * start_gulm_threads - 
+ * @host_data: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+start_gulm_threads (char *csnm, char *host_data)
+{
+	int error = 0;
+
+	down (&start_stop_lock);
+	atomic_inc (&start_stop_cnt);
+	if (atomic_read (&start_stop_cnt) == 1) {
+		/* first one. get stuff going */
+		strncpy (gulm_cm.clusterID, csnm, 255);
+		gulm_cm.clusterID[255] = '\0';
+
+		error = lg_initialize (&gulm_cm.hookup, gulm_cm.clusterID,
+				       "GFS Kernel Interface");
+		if (error != 0) {
+			log_err ("lg_initialize failed, %d\n", error);
+			goto fail;
+		}
+		gulm_cm.starts = TRUE;
+
+		error = load_info (host_data);
+		if (error != 0) {
+			log_err ("load_info failed. %d\n", error);
+			goto fail;
+		}
+
+		jid_init ();
+
+		error = cm_login ();
+		if (error != 0) {
+			log_err ("cm_login failed. %d\n", error);
+			goto fail;
+		}
+
+		/* lt_login() is called after the success packet for cm_login()
+		 * returns.
+		 */
+	}
+      fail:
+	up (&start_stop_lock);
+	return error;
+}
+
+/**
+ * stop_gulm_threads - 
+ */
+void
+stop_gulm_threads (void)
+{
+	down (&start_stop_lock);
+	atomic_dec (&start_stop_cnt);
+	if (atomic_read (&start_stop_cnt) == 0) {
+		/* last one, put it all away. */
+		lt_logout ();
+		cm_logout ();
+		clear_locks ();
+		lg_release (gulm_cm.hookup);
+		gulm_cm.hookup = NULL;
+		gulm_cm.loaded = FALSE;
+		gulm_cm.GenerationID = 0;
+	}
+	up (&start_stop_lock);
+}
+
+/*****************************************************************************/
+
+/**
+ * gulm_mount
+ * @table_name: clusterID:FS_Name
+ * @host_data:
+ * @cb: GFS callback function
+ * @fsdata: opaque GFS handle
+ * @lockstruct: the structure of crap to fill in
+ *
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_mount (char *table_name, char *host_data,
+	    lm_callback_t cb, lm_fsdata_t * fsdata,
+	    unsigned int min_lvb_size, struct lm_lockstruct *lockstruct)
+{
+	gulm_fs_t *gulm;
+	char *work=NULL, *tbln;
+	int first;
+	int error = -1;
+	struct list_head *lltmp;
+
+	work = kmalloc(256, GFP_KERNEL);
+	if(work == NULL ) {
+		log_err("Out of Memory.\n");
+		error = -ENOMEM;
+		goto fail;
+	}
+	strncpy (work, table_name, 256);
+
+	tbln = strstr (work, ":");
+	if (tbln == NULL) {
+		log_err
+		    ("Malformed table name. Couldn't find separator ':' between "
+		     "clusterID and lockspace name.\n");
+		error = -1;
+		goto fail;
+	}
+	*tbln++ = '\0';
+
+	/* make sure that the cluster name exists. */
+	if (strlen (work) <= 0) {
+		log_err ("Cluster name \"%s\" is too short.\n", work);
+		error = -EPROTO;
+		goto fail;
+	}
+	if (strlen (work) > 16) {
+		log_err ("Cluster name \"%s\" is too long.\n", work);
+		error = -EPROTO;
+		goto fail;
+	}
+
+	/* the second one is an artifact of the way I use the name.  
+	 * A better fix to this will happen when I actually get dynamic key
+	 * lengths working.
+	 */
+	if (strlen (tbln) > MIN (GIO_NAME_LEN, (GIO_KEY_SIZE - 15))) {
+		log_err
+		    ("Warning! lockspace name (%s) is longer than %d chars!\n",
+		     tbln, MIN (GIO_NAME_LEN, (GIO_KEY_SIZE - 15)));
+		error = -EPROTO;
+		goto fail;
+	}
+	if (strlen (tbln) <= 0) {
+		log_err ("Table name \"%s\" is too short.\n", tbln);
+		error = -EPROTO;
+		goto fail;
+	}
+
+	/*  Check to make sure this lock table isn't already being used  */
+	down (&filesystem_lck);
+	list_for_each (lltmp, &filesystems_list) {
+		gulm = list_entry (lltmp, gulm_fs_t, fs_list);
+		if (!strncmp (gulm->fs_name, tbln, GIO_NAME_LEN)) {
+			log_err ("\"%s\" is already in use\n", tbln);
+			error = -EEXIST;
+			up (&filesystem_lck);
+			goto fail;
+		}
+	}
+	up (&filesystem_lck);
+
+	/*  Set up our main structure  */
+
+	gulm = kmalloc (sizeof (gulm_fs_t), GFP_KERNEL);
+	if (!gulm) {
+		log_err ("out of memory\n");
+		error = -ENOMEM;
+		goto fail;
+	}
+	memset (gulm, 0, sizeof (gulm_fs_t));
+
+	INIT_LIST_HEAD (&gulm->fs_list);
+
+	strncpy (gulm->fs_name, tbln, GIO_NAME_LEN);
+	gulm->cb = cb;
+	gulm->fsdata = fsdata;
+	gulm->lvb_size = min_lvb_size;
+	init_completion (&gulm->sleep);
+	init_MUTEX (&gulm->get_lock);
+
+	if ((error = start_gulm_threads (work, host_data)) != 0) {
+		log_err ("Got a %d trying to start the threads.\n", error);
+		goto fail_free_gulm;
+	}
+
+	if ((error =
+	     start_callback_qu (&gulm->cq, gulm_cm.handler_threads)) < 0) {
+		log_err ("fsid=%s: Failed to start the callback handler.\n",
+			 gulm->fs_name);
+		goto fail_free_gulm;
+	}
+
+	/* the mount lock HAS to be the first thing done in the LTs for this fs. */
+	error = get_mount_lock (gulm, &first);
+	if (error != 0) {
+		log_err
+		    ("fsid=%s: Error %d while trying to get the mount lock\n",
+		     gulm->fs_name, error);
+		goto fail_callback;
+	}
+
+	jid_lockstate_reserve (gulm, first);
+	jid_fs_init (gulm);
+	get_journalID (gulm);
+
+	/* things act a bit different until the first mounter is finished.
+	 */
+	if (first)
+		gulm->firstmounting = TRUE;
+
+	/*  Success  */
+	down (&filesystem_lck);
+	list_add (&gulm->fs_list, &filesystems_list);
+	filesystems_count++;
+	up (&filesystem_lck);
+
+	log_msg (lgm_JIDMap, "fsid=%s: We will be using jid %d\n",
+		 gulm->fs_name, gulm->fsJID);
+
+	if (add_to_proc (gulm) != 0) {
+		/* ignored for now */
+	}
+
+	lockstruct->ls_jid = gulm->fsJID;
+	lockstruct->ls_first = first;
+	lockstruct->ls_lvb_size = gulm->lvb_size;
+	lockstruct->ls_lockspace = gulm;
+	lockstruct->ls_ops = &gulm_ops;
+#ifdef USE_SYNC_LOCKING
+	lockstruct->ls_flags = 0;
+
+	log_msg (lgm_Network2, "Done: %s, sync mode\n", table_name);
+#else
+	lockstruct->ls_flags = LM_LSFLAG_ASYNC;
+
+	log_msg (lgm_Network2, "Done: %s, async mode\n", table_name);
+#endif
+
+	gulm_cm.starts = FALSE;
+	return 0;
+
+      fail_callback:
+	stop_callback_qu (&gulm->cq);
+
+      fail_free_gulm:
+	kfree (gulm);
+	stop_gulm_threads ();
+
+      fail:
+
+	if(work != NULL ) kfree(work);
+	gulm_cm.starts = FALSE;
+	log_msg (lgm_Always, "fsid=%s: Exiting gulm_mount with errors %d\n",
+		 table_name, error);
+	return error;
+}
+
+/**
+ * gulm_others_may_mount
+ * @lockspace: handle to specific lock space
+ *
+ * GFS calls this function if it was the first mounter after it's done
+ * checking all the journals.
+ *
+ */
+void
+gulm_others_may_mount (lm_lockspace_t * lockspace)
+{
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	int err = 0;
+	lock_table_t *lt = &gulm_cm.ltpx;
+
+	/* first send the drop all exp message.
+	 * */
+	err = send_drop_exp (fs, lt, NULL);
+	if (err < 0)
+		log_err
+		    ("fsid=%s: Problems sending DropExp request to LTPX: %d\n",
+		     fs->fs_name, err);
+
+	/* then move the FirstMountLock to shared so others can mount. */
+	err = downgrade_mount_lock (fs);
+
+	if (err < 0) {
+		log_err ("fsid=%s: error sending Fs_FinMount_Req.(%d)\n",
+			 fs->fs_name, err);
+	}
+
+	/* first mounter is all done.  let the gulm_recovery_done function
+	 * behave as normal now.
+	 */
+	fs->firstmounting = FALSE;
+}
+
+/**
+ * gulm_umount
+ * @lockspace: handle to specific lock space
+ *
+ */
+void
+gulm_unmount (lm_lockspace_t * lockspace)
+{
+	gulm_fs_t *gulm_fs = (gulm_fs_t *) lockspace;
+
+	down (&filesystem_lck);
+	list_del (&gulm_fs->fs_list);
+	--filesystems_count;
+	up (&filesystem_lck);
+
+	/* close and release stuff */
+	drop_mount_lock (gulm_fs);
+	put_journalID (gulm_fs);
+	jid_fs_release (gulm_fs);
+	jid_lockstate_release (gulm_fs);
+
+	stop_callback_qu (&gulm_fs->cq);
+
+	remove_from_proc (gulm_fs);
+
+	kfree (gulm_fs);
+
+	stop_gulm_threads ();
+
+}
+
+/**
+ * gulm_recovery_done - 
+ * @lockspace: 
+ * @jid: 
+ * 
+ * Returns: void
+ */
+void
+gulm_recovery_done (lm_lockspace_t * lockspace, unsigned int jid,
+		    unsigned int message)
+{
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	int err;
+	uint8_t name[64];
+
+	if (message != LM_RD_SUCCESS) {
+		/* Need to start thinking about how I want to use this... */
+		return;
+	}
+
+	if (jid == fs->fsJID) {	/* this may be drifting crud through. */
+		/* hey! its me! */
+		strncpy (name, gulm_cm.myName, 64);
+	} else if (lookup_name_by_jid (fs, jid, name) != 0) {
+		log_msg (lgm_JIDMap,
+			 "fsid=%s: Could not find a client for jid %d\n",
+			 fs->fs_name, jid);
+		return;
+	}
+	if (strlen (name) == 0) {
+		log_msg (lgm_JIDMap, "fsid=%s: No one mapped to jid %d\n",
+			 fs->fs_name, jid);
+		return;
+	}
+	log_msg (lgm_JIDMap, "fsid=%s: Found %s for jid %d\n",
+		 fs->fs_name, name, jid);
+
+	err = send_drop_exp (fs, &gulm_cm.ltpx, name);
+
+	if (jid != fs->fsJID) {
+		/* rather dumb to do this to ourselves right after we mount... */
+		log_msg (lgm_JIDMap,
+			 "fsid=%s: Clearing JID %d for use by others\n",
+			 fs->fs_name, jid);
+		release_JID (fs, jid, FALSE);
+	}
+
+	/* If someone died while replaying someoneelse's journal, there will be
+	 * stale expired jids.
+	 */
+	check_for_stale_expires (fs);
+
+}
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.c linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,822 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "util.h"
+
+extern gulm_cm_t gulm_cm;
+
+/****************************************************************************/
+
+/* jid locks:
+ *
+ * Header lock: "JHeader" + \0\0\0 + fsname
+ *         lvb: <uint32> :number of JIDs
+ * Mappinglock: "JM" + <uint32> + \0\0\0\0 + fsname
+ *         lvb: [012] + <node name>
+ *              0: unused
+ *              1: replaying journal
+ *              2: Mounted
+ * list lock  : "JL" + "listlock" + fsname
+ * Node Locks : "JN" + <nodename[8]> + fsname
+ *
+ */
+#define jid_header_lvb_size (8)
+
+struct jid_lookup_item_s {
+	struct list_head jp_list;
+	uint8_t *key;
+	uint16_t keylen;
+	uint8_t *lvb;
+	uint16_t lvblen;
+	struct completion waitforit;
+};
+typedef struct jid_lookup_item_s jid_lookup_item_t;
+
+LIST_HEAD (jid_pending_locks);
+spinlock_t jid_pending;
+struct semaphore jid_listlock;
+
+/**
+ * jid_init - 
+ */
+void
+jid_init (void)
+{
+	spin_lock_init (&jid_pending);
+	init_MUTEX (&jid_listlock);
+}
+
+/**
+ * jid_get_header_name - 
+ * @fs: <
+ * @key: <>
+ * @keylen: <> 
+ * 
+ * key is buffer to write to, keylen is size of buffer on input, and real
+ * length on output.
+ * 
+ * Returns: int
+ */
+int
+jid_get_header_name (uint8_t * fsname, uint8_t * key, uint16_t * keylen)
+{
+	int len;
+
+	len = pack_lock_key(key, *keylen, 'J', fsname, "Header\0\0\0", 9);
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+int
+jid_get_listlock_name (uint8_t * fsname, uint8_t * key, uint16_t * keylen)
+{
+	int len;
+
+	len = pack_lock_key(key, *keylen, 'J', fsname, "Llistlock", 9);
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+/**
+ * jid_get_lock_name - 
+ * @fs: <
+ * @jid: <
+ * @key: <>
+ * @keylen: <>
+ * 
+ * key is buffer to write to, keylen is size of buffer on input, and real
+ * length on output.
+ * 
+ * Returns: int
+ */
+int
+jid_get_lock_name (uint8_t * fsname, uint32_t jid, uint8_t * key,
+		   uint16_t * keylen)
+{
+	int len;
+	uint8_t temp[9];
+
+	temp[0] = 'M';
+	temp[1] = (jid >> 0) & 0xff;
+	temp[2] = (jid >> 8) & 0xff;
+	temp[3] = (jid >> 16) & 0xff;
+	temp[4] = (jid >> 24) & 0xff;
+	temp[5] = 0;
+	temp[6] = 0;
+	temp[7] = 0;
+	temp[8] = 0;
+
+	len = pack_lock_key(key, *keylen, 'J', fsname, temp, 9);
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+/**
+ * jid_hold_lvb - 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ */
+void
+jid_hold_lvb (uint8_t * key, uint16_t keylen)
+{
+	jid_lookup_item_t jp;
+	GULM_ASSERT (keylen > 6,);
+	jp.key = key;
+	jp.keylen = keylen;
+	jp.lvb = NULL;
+	jp.lvblen = 0;
+	INIT_LIST_HEAD (&jp.jp_list);
+	init_completion (&jp.waitforit);
+
+	spin_lock (&jid_pending);
+	list_add (&jp.jp_list, &jid_pending_locks);
+	spin_unlock (&jid_pending);
+
+	lg_lock_action_req (gulm_cm.hookup, key, keylen, 0,
+			    lg_lock_act_HoldLVB, NULL, 0);
+
+	wait_for_completion (&jp.waitforit);
+}
+
+void
+jid_unhold_lvb (uint8_t * key, uint16_t keylen)
+{
+	jid_lookup_item_t jp;
+	GULM_ASSERT (keylen > 6,);
+	jp.key = key;
+	jp.keylen = keylen;
+	jp.lvb = NULL;
+	jp.lvblen = 0;
+	INIT_LIST_HEAD (&jp.jp_list);
+	init_completion (&jp.waitforit);
+
+	spin_lock (&jid_pending);
+	list_add (&jp.jp_list, &jid_pending_locks);
+	spin_unlock (&jid_pending);
+
+	lg_lock_action_req (gulm_cm.hookup, key, keylen, 0,
+			    lg_lock_act_UnHoldLVB, NULL, 0);
+
+	wait_for_completion (&jp.waitforit);
+}
+
+void
+jid_sync_lvb (uint8_t * key, uint16_t keylen, uint8_t * lvb, uint16_t lvblen)
+{
+	jid_lookup_item_t jp;
+	GULM_ASSERT (keylen > 6,);
+	jp.key = key;
+	jp.keylen = keylen;
+	jp.lvb = NULL;
+	jp.lvblen = 0;
+	INIT_LIST_HEAD (&jp.jp_list);
+	init_completion (&jp.waitforit);
+
+	spin_lock (&jid_pending);
+	list_add (&jp.jp_list, &jid_pending_locks);
+	spin_unlock (&jid_pending);
+
+	lg_lock_action_req (gulm_cm.hookup, key, keylen, 0,
+			    lg_lock_act_SyncLVB, lvb, lvblen);
+
+	wait_for_completion (&jp.waitforit);
+}
+
+/**
+ * jid_action_reply - 
+ * @key: 
+ * @keylen: 
+ * 
+ * called from the lock handler callback.
+ * 
+ * Returns: void
+ */
+void
+jid_action_reply (uint8_t * key, uint16_t keylen)
+{
+	struct list_head *tmp, *nxt;
+	jid_lookup_item_t *jp, *fnd = NULL;
+	spin_lock (&jid_pending);
+	list_for_each_safe (tmp, nxt, &jid_pending_locks) {
+		jp = list_entry (tmp, jid_lookup_item_t, jp_list);
+		if (memcmp (key, jp->key, MIN (keylen, jp->keylen)) == 0) {
+			fnd = jp;
+			list_del (tmp);
+			break;
+		}
+	}
+	spin_unlock (&jid_pending);
+
+	if (fnd != NULL)
+		complete (&fnd->waitforit);
+}
+
+/**
+ * jid_get_lock_state_inr - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags:
+ * @lvb: 
+ * @lvblen: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state_inr (uint8_t * key, uint16_t keylen, uint8_t state,
+			uint32_t flags, uint8_t * lvb, uint16_t lvblen)
+{
+	jid_lookup_item_t jp;
+	GULM_ASSERT (keylen > 6,
+			printk("keylen: %d\n", keylen););
+	jp.key = key;
+	jp.keylen = keylen;
+	jp.lvb = lvb;
+	jp.lvblen = lvblen;
+	INIT_LIST_HEAD (&jp.jp_list);
+	init_completion (&jp.waitforit);
+
+	spin_lock (&jid_pending);
+	list_add (&jp.jp_list, &jid_pending_locks);
+	spin_unlock (&jid_pending);
+
+	lg_lock_state_req (gulm_cm.hookup, key, keylen, 0, 0, ~((uint64_t)0),
+			state, flags, lvb, lvblen);
+
+	wait_for_completion (&jp.waitforit);
+}
+
+/**
+ * jid_get_lock_state_lvb - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @lvb: 
+ * @lvblen: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state_lvb (uint8_t * key, uint16_t keylen, uint8_t state,
+			uint8_t * lvb, uint16_t lvblen)
+{
+	jid_get_lock_state_inr (key, keylen, state, 0, lvb, lvblen);
+}
+/**
+ * jid_get_lock_state - 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * 
+ * 
+ */
+void
+jid_get_lock_state (uint8_t * key, uint16_t keylen, uint8_t state)
+{
+	jid_get_lock_state_inr (key, keylen, state, 0, NULL, 0);
+}
+
+/**
+ * jid_state_reply - 
+ * @key: 
+ * @keylen: 
+ * @lvb: 
+ * @lvblen: 
+ * 
+ * 
+ */
+void
+jid_state_reply (uint8_t * key, uint16_t keylen, uint8_t * lvb, uint16_t lvblen)
+{
+	struct list_head *tmp, *nxt;
+	jid_lookup_item_t *jp, *fnd = NULL;
+	spin_lock (&jid_pending);
+	list_for_each_safe (tmp, nxt, &jid_pending_locks) {
+		jp = list_entry (tmp, jid_lookup_item_t, jp_list);
+		if (memcmp (key, jp->key, MIN (keylen, jp->keylen)) == 0) {
+			fnd = jp;
+			list_del (tmp);
+			break;
+		}
+	}
+	spin_unlock (&jid_pending);
+
+	if (fnd != NULL) {
+		if (lvb != NULL && fnd->lvb != NULL)
+			memcpy (fnd->lvb, lvb, MIN (fnd->lvblen, lvblen));
+		complete (&fnd->waitforit);
+	}
+}
+
+/****************************************************************************/
+
+/**
+ * jid_hold_list_lock - 
+ * @fs: 
+ * 
+ * only make one call to this per node.
+ * 
+ * Returns: void
+ */
+void
+jid_hold_list_lock (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	down (&jid_listlock);
+
+	keylen = sizeof (key);
+	jid_get_listlock_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+			lg_lock_flag_IgnoreExp, NULL, 0);
+
+}
+
+/**
+ * jid_release_list_lock - 
+ * @fs: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+jid_release_list_lock (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	keylen = sizeof (key);
+	jid_get_listlock_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	up (&jid_listlock);
+}
+
+/**
+ * jid_rehold_lvbs - 
+ * @fs: 
+ * 
+ * 
+ */
+void
+jid_rehold_lvbs (gulm_fs_t * fs)
+{
+	int i;
+	uint32_t oldjcnt;
+	uint8_t key[GIO_KEY_SIZE], lvb[jid_header_lvb_size];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	oldjcnt = fs->JIDcount;
+
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state_lvb (key, keylen, lg_lock_state_Shared, lvb,
+				jid_header_lvb_size);
+	fs->JIDcount = (uint32_t) (lvb[0]) << 0;
+	fs->JIDcount |= (uint32_t) (lvb[1]) << 8;
+	fs->JIDcount |= (uint32_t) (lvb[2]) << 16;
+	fs->JIDcount |= (uint32_t) (lvb[3]) << 24;
+
+	for (i = oldjcnt; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_hold_lvb (key, keylen);
+	}
+
+}
+
+void
+jid_grow_space (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[jid_header_lvb_size];
+	uint16_t keylen = GIO_KEY_SIZE;
+	uint32_t jidc;
+
+	keylen = sizeof (key);
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb,
+				jid_header_lvb_size);
+	jidc = (uint32_t) (lvb[0]) << 0;
+	jidc |= (uint32_t) (lvb[1]) << 8;
+	jidc |= (uint32_t) (lvb[2]) << 16;
+	jidc |= (uint32_t) (lvb[3]) << 24;
+	jidc += 300;
+	lvb[3] = (jidc >> 24) & 0xff;
+	lvb[2] = (jidc >> 16) & 0xff;
+	lvb[1] = (jidc >> 8) & 0xff;
+	lvb[0] = (jidc >> 0) & 0xff;
+	jid_sync_lvb (key, keylen, lvb, jid_header_lvb_size);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+	/* do an unlock here, so that when rehold grabs it shared, there is no
+	 * lvb writing.
+	 */
+
+	jid_rehold_lvbs (fs);
+}
+
+/**
+ * lookup_name_by_jid - 
+ * @fs: 
+ * @jid: 
+ * @name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lookup_name_by_jid (gulm_fs_t * fs, uint32_t jid, uint8_t * name)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	int err = 0;
+
+	if (jid >= fs->JIDcount) {
+		err = -1;
+		goto exit;
+	}
+
+	jid_hold_list_lock (fs);
+
+	jid_get_lock_name (fs->fs_name, jid, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb, 64);
+
+	if (lvb[0] != 0) {
+		memcpy (name, &lvb[1], strlen (&lvb[1]) + 1);
+	} else {
+		err = -1;
+	}
+
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	jid_release_list_lock (fs);
+
+      exit:
+	return err;
+}
+
+/**
+ * Release_JID - 
+ * @fs: 
+ * @jid: 
+ * 
+ * actually may only need to et first byte to zero
+ * 
+ * Returns: int
+ */
+int
+release_JID (gulm_fs_t * fs, uint32_t jid, int nop)
+{
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	/* there is no such, so this becomes a nop. */
+	if (jid >= fs->JIDcount)
+		goto exit;
+
+	jid_hold_list_lock (fs);
+
+	jid_get_lock_name (fs->fs_name, jid, key, &keylen);
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+				lg_lock_flag_IgnoreExp, lvb, 64);
+	lvb[0] = 0;
+	jid_sync_lvb (key, keylen, lvb, strlen (&lvb[1]) + 2);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	jid_release_list_lock (fs);
+
+      exit:
+	return 0;
+}
+
+void
+put_journalID (gulm_fs_t * fs)
+{
+	release_JID (fs, fs->fsJID, TRUE);
+}
+
+/**
+ * get_journalID - 
+ * @fs: 
+ * @jid: 
+ * 
+ * This is broken.
+ * 
+ * Returns: int
+ */
+void
+get_journalID (gulm_fs_t * fs)
+{
+	uint32_t i = 0;
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	int first_clear = -1;
+
+      retry:
+	jid_hold_list_lock (fs);
+
+	/* find an empty space, or ourselves again */
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+		if (first_clear == -1 && lvb[0] == 0 ) {
+			first_clear = i;
+		} else if (strcmp (gulm_cm.myName, &lvb[1]) == 0) {
+			first_clear = i;
+			break;
+		}
+	}
+	if (first_clear >= 0) {
+		/* take the jid we have found */
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, first_clear, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		lvb[0] = 2;
+		memcpy (&lvb[1], gulm_cm.myName, strlen (gulm_cm.myName) + 1);
+		jid_sync_lvb (key, keylen, lvb, strlen (gulm_cm.myName) + 2);
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+		fs->fsJID = first_clear;
+	}
+
+	/* unlock the header lock */
+	jid_release_list_lock (fs);
+
+	if (first_clear < 0) {
+		/* nothing found, grow and try again. */
+		jid_grow_space (fs);
+		goto retry;
+	}
+
+}
+
+/**
+ * find_jid_by_name_and_mark_replay - 
+ * @fs: 
+ * @name: 
+ * @jid: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+find_jid_by_name_and_mark_replay (gulm_fs_t * fs, uint8_t * name,
+				  uint32_t * jid)
+{
+	uint32_t i, found = -1;
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	/* grab list lock */
+	jid_hold_list_lock (fs);
+
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		if (strcmp (name, &lvb[1]) == 0) {
+			*jid = i;
+			found = 0;
+			lvb[0] = 1;
+			jid_sync_lvb (key, keylen, lvb, strlen (&lvb[1]) + 2);
+			jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+			break;
+		}
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	}
+	/* unlock the list lock */
+	jid_release_list_lock (fs);
+
+	return found;
+}
+
+/**
+ * Check_for_replays - 
+ * @fs: 
+ * 
+ * 
+ * Returns: int
+ */
+void
+check_for_stale_expires (gulm_fs_t * fs)
+{
+	uint32_t i;
+	uint8_t key[GIO_KEY_SIZE], lvb[64];
+	uint16_t keylen = GIO_KEY_SIZE;
+	unsigned int ujid;
+
+	/* grab list lock */
+	jid_hold_list_lock (fs);
+
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+					lg_lock_flag_IgnoreExp, lvb, 64);
+		jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+		if (lvb[0] == 1) {
+			log_msg (lgm_JIDMap,
+				 "fsid=%s: stale JID %d found\n",
+				 fs->fs_name, i);
+			ujid = i;
+			fs->cb (fs->fsdata, LM_CB_NEED_RECOVERY, &ujid);
+		}
+	}
+
+	/* unlock the list lock */
+	jid_release_list_lock (fs);
+}
+
+/**
+ * jid_fs_init - 
+ * @fs: 
+ * 
+ */
+void
+jid_fs_init (gulm_fs_t * fs)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	fs->JIDcount = 0;
+
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_hold_lvb (key, keylen);
+	jid_rehold_lvbs (fs);
+}
+
+/**
+ * jid_fs_release - 
+ * @fs: 
+ * 
+ */
+void
+jid_fs_release (gulm_fs_t * fs)
+{
+	uint32_t i;
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+	for (i = 0; i < fs->JIDcount; i++) {
+		keylen = sizeof (key);
+		jid_get_lock_name (fs->fs_name, i, key, &keylen);
+		jid_unhold_lvb (key, keylen);
+	}
+	keylen = sizeof (key);
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_unhold_lvb (key, keylen);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+}
+
+/**
+ * jid_unlock_callback - 
+ * @d: 
+ * 
+ * *MUST* be called from a Handler thread.
+ * 
+ * Returns: int
+ */
+void
+jid_unlock_callback (void *d)
+{
+	uint8_t key[GIO_KEY_SIZE];
+	uint16_t keylen = GIO_KEY_SIZE;
+
+	gulm_fs_t *fs = (gulm_fs_t *) d;
+	jid_get_header_name (fs->fs_name, key, &keylen);
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+	jid_rehold_lvbs (fs);
+}
+
+/**
+ * jid_header_lock_drop - 
+ * @key: 
+ * @keylen: 
+ * 
+ * Returns: void
+ */
+void
+jid_header_lock_drop (uint8_t * key, uint16_t keylen)
+{
+	gulm_fs_t *fs;
+	/* make sure this is the header lock.... */
+	if (key[1] == 'H' && (fs = get_fs_by_name (&key[10])) != NULL) {
+		qu_function_call (&fs->cq, jid_unlock_callback, fs);
+	}
+}
+
+/****************************************************************************/
+/**
+ * jid_get_lsresv_name - 
+ * @fsname: 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+jid_get_lsresv_name (char *fsname, uint8_t * key, uint16_t * keylen)
+{
+	int len;
+
+	len = strlen(gulm_cm.myName);
+	len = pack_lock_key(key, *keylen, 'N', fsname, gulm_cm.myName,
+			MIN(64,len));
+	if( len <=0 ) return len;
+
+	*keylen = len;
+
+	return 0;
+}
+
+/**
+ * jid_lockstate_reserve - 
+ * @fs: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+jid_lockstate_reserve (gulm_fs_t * fs, int first)
+{
+	uint8_t key[5 + 32 + 64];
+	uint16_t keylen = 5 + 32 + 64;
+	/* 5 bytes for stuff in key (lengths and type bytes)
+	 * 32 for fs name
+	 * 64 for node name.
+	 */
+
+	jid_get_lsresv_name (fs->fs_name, key, &keylen);
+
+	/* if we are expired, this will block until someone else has
+	 * cleaned our last mess up.
+	 *
+	 * Will very well may need to put in some kind of timeout
+	 * otherwise this may do a forever lockup much like the
+	 * FirstMounter lock had.
+	 */
+	jid_get_lock_state_inr (key, keylen, lg_lock_state_Exclusive,
+			first?lg_lock_flag_IgnoreExp:0, NULL, 0);
+
+}
+
+/**
+ * jid_lockstate_release - 
+ * @fs: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+jid_lockstate_release (gulm_fs_t * fs)
+{
+	uint8_t key[5 + 32 + 64];
+	uint16_t keylen = 5 + 32 + 64;
+
+	jid_get_lsresv_name (fs->fs_name, key, &keylen);
+
+	jid_get_lock_state (key, keylen, lg_lock_state_Unlock);
+
+}
+
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.h linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_jid.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_jid.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,41 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __GULM_JID_H__
+#define __GULM_JID_H__
+#include "gulm.h"
+void jid_init (void);
+void jid_fs_init (gulm_fs_t * fs);
+void jid_fs_release (gulm_fs_t * fs);
+int get_journalID (gulm_fs_t * fs);
+int lookup_jid_by_name (gulm_fs_t * fs, uint8_t * name, uint32_t * injid);
+int lookup_name_by_jid (gulm_fs_t * fs, uint32_t jid, uint8_t * name);
+void release_JID (gulm_fs_t * fs, uint32_t jid, int owner);
+void put_journalID (gulm_fs_t * fs);
+void check_for_stale_expires (gulm_fs_t * fs);
+
+int
+ find_jid_by_name_and_mark_replay (gulm_fs_t * fs, uint8_t * name, uint32_t * jid);
+
+void jid_start_journal_reply (gulm_fs_t * fs, uint32_t jid);
+void jid_finish_journal_reply (gulm_fs_t * fs, uint32_t jid);
+
+void jid_lockstate_reserve (gulm_fs_t * fs, int first);
+void jid_lockstate_release (gulm_fs_t * fs);
+
+/* to be called from the lg_lock callbacks. */
+void jid_state_reply (uint8_t * key, uint16_t keylen, uint8_t * lvb,
+		      uint16_t lvblen);
+void jid_action_reply (uint8_t * key, uint16_t keylen);
+void jid_header_lock_drop (uint8_t * key, uint16_t keylen);
+#endif /*__GULM_JID_H__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h linux-patched/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_log_msg_bits.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,40 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_log_msg_bits_h__
+#define __gulm_log_msg_bits_h__
+/* log_msg bit flags
+ * These got thier own file so I can easily include them in both user and
+ * kernel space.
+ * */
+#define lgm_Always      (0x00000000)	/*Print Message no matter what */
+#define lgm_Network     (0x00000001)
+#define lgm_Network2    (0x00000002)
+#define lgm_Stomith     (0x00000004)
+#define lgm_Heartbeat   (0x00000008)
+#define lgm_locking     (0x00000010)
+#define lgm_FuncDebug   (0x00000020)
+#define lgm_Forking     (0x00000040)
+#define lgm_JIDMap      (0x00000080)
+#define lgm_Subscribers (0x00000100)
+#define lgm_LockUpdates (0x00000200)
+#define lgm_LoginLoops  (0x00000400)
+#define lgm_Network3    (0x00000800)
+#define lgm_JIDUpdates  (0x00001000)
+#define lgm_ServerState (0x00002000)
+
+#define lgm_ReallyAll   (0xffffffff)
+
+#define lgm_BitFieldSize (32)
+
+#endif /*__gulm_log_msg_bits_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_lt.c linux-patched/fs/gfs_locking/lock_gulm/gulm_lt.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_lt.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_lt.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,2024 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/slab.h>
+#include <linux/file.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "util.h"
+#include "handler.h"
+#include "utils_tostr.h"
+#include "gulm_jid.h"
+
+extern gulm_cm_t gulm_cm;
+
+/****************************************************************************/
+/* A bunch of prints that hopefully contain more information that is also
+ * useful
+ *
+ * these are a mess.
+ */
+
+/**
+ * lck_key_to_hex - 
+ * @key: 
+ * @len: 
+ * @workspace: <> place to put string. !! better be 2x len !!
+ * 
+ * 
+ * Returns: char
+ */
+static char *
+lck_key_to_hex (uint8_t * key, uint16_t len, char *workspace)
+{
+	int i;
+	for (i = 0; i < len; i++)
+		sprintf (&workspace[i * 2], "%02x", (key[i] & 0xff));
+	return workspace;
+}
+
+static void __inline__
+db_lck_entered (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	printk ("Started  lock 0x%s cur:%#x req:%#x flags:%#x\n", bb,
+		lck->cur_state, lck->req_state, lck->flags);
+}
+static void __inline__
+db_lck_exited (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	printk ("Finished lock 0x%s result:%#x\n", bb, lck->result);
+}
+
+static void __inline__
+dump_gulm_lock_t (gulm_lock_t * lck)
+{
+	char bb[GIO_KEY_SIZE * 2 + 3];
+
+	lck_key_to_hex (lck->key, lck->keylen, bb);
+	log_msg (lgm_Always, " key = 0x%s\n", bb);
+	log_msg (lgm_Always, " req_type = %#x\n", lck->req_type);
+	log_msg (lgm_Always, " last_suc_state = %#x\n", lck->last_suc_state);
+	log_msg (lgm_Always, " actuallypending = %d\n", lck->actuallypending);
+	log_msg (lgm_Always, " in_to_be_sent = %d\n", lck->in_to_be_sent);
+	log_msg (lgm_Always, " cur_state = %d\n", lck->cur_state);
+	log_msg (lgm_Always, " req_state = %d\n", lck->req_state);
+	log_msg (lgm_Always, " flags = %#x\n", lck->flags);
+	log_msg (lgm_Always, " action = %d\n", lck->action);
+	log_msg (lgm_Always, " result = %d\n", lck->result);
+}
+
+/* DEBUG_BY_LOCK is gone.  I may later add something back if needed.
+ *
+ * I love the idea of being able to log only certain locks, I just cannot
+ * think of an easy way to do it.  The best I can come up with is some
+ * pattern (or set of) that are used to decide which locks get logged.  But
+ * that could be expensive if the pattern is checked everytime, and won't
+ * behave as expected if only applied in get_lock.
+ * */
+
+/* The old log functions.
+ * These need their own sort of clean up someday as well.
+ * */
+#define log_msg_lk(key, keylen, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( key, keylen, bb); \
+      printk(PROTO_NAME ": On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_err_lk(key, keylen, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( key, keylen, bb); \
+      printk(KERN_ERR PROTO_NAME ": ERROR On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_msg_lck(lck, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( (lck)->key, (lck)->keylen, bb); \
+      printk(PROTO_NAME ": On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#define log_err_lck(lck, fmt, args...) {\
+      uint8_t bb[GIO_KEY_SIZE*2 +3]; \
+      lck_key_to_hex( (lck)->key, (lck)->keylen, bb); \
+      printk(KERN_ERR PROTO_NAME ": ERROR On lock 0x%s " fmt , bb , ## args ); \
+   }
+
+#ifdef DEBUG_LVB
+static void __inline__
+print_lk_lvb (uint8_t * key, uint8_t * lvb, uint8_t st, uint8_t * dir)
+{
+	uint8_t bk[GIO_KEY_SIZE * 2 + 3];
+	uint8_t bl[GIO_LVB_SIZE * 2 + 3];
+	int i;
+	for (i = 0; i < GIO_KEY_SIZE; i++)
+		sprintf (&bk[(i * 2)], "%02x", (key[i]) & 0xff);
+	for (i = 0; i < GIO_LVB_SIZE; i++)
+		sprintf (&bl[(i * 2)], "%02x", (lvb[i]) & 0xff);
+	printk (PROTO_NAME ": On lock 0x%s with state %d\n\t%s LVB 0x%s\n",
+		bk, st, dir, bl);
+}
+
+#define lvb_log_msg_lk(k, fmt, args...) log_msg_lk( k , fmt , ## args )
+#define lvb_log_msg(fmt, args...) log_msg(lgm_Always , fmt , ## args )
+#else				/*DEBUG_LVB */
+#define print_lk_lvb(k,l,s,d)
+#define lvb_log_msg_lk(k, fmt, args...)
+#define lvb_log_msg(fmt, args...)
+#endif				/*DEBUG_LVB */
+
+/****************************************************************************/
+/**
+ * pack_lock_key - 
+ * @key: 
+ * @keylen: 
+ * 
+ * key is: <type><fsname len><fsname>\0<pk len><pk>\0
+ * <type> is: G J F N
+ * <fsname len> is 0-256
+ * 
+ * Returns: int
+ */
+int pack_lock_key(uint8_t *key, uint16_t keylen, uint8_t type,
+		uint8_t *fsname, uint8_t *pk, uint8_t pklen)
+{
+	int fsnlen;
+	fsnlen = strlen(fsname);
+
+	if( keylen <= (fsnlen + pklen + 5) ) return -1;
+
+	memset (key, 0, keylen);
+
+	key[0] = type;
+
+	key[1] = fsnlen;
+	memcpy(&key[2], fsname, fsnlen);
+	key[2 + fsnlen] = 0;
+
+	key[3 + fsnlen] = pklen;
+
+	memcpy(&key[4 + fsnlen], pk, pklen);
+
+	key[4 + fsnlen + pklen] = 0;
+
+	return fsnlen + pklen + 5;
+}
+
+/**
+ * unpack_lock_key - 
+ * @key: <
+ * @keylen: <
+ * @type: >
+ * @fsname: >
+ * @fsnlen: >
+ * @pk: >
+ * @pklen: >
+ * 
+ * if you're gonna fiddle with bytes returned here, copy first!
+ *
+ * this is broken. do I even really need this?
+ * 
+ * Returns: int
+ */
+int unpack_lock_key(uint8_t *key, uint16_t keylen, uint8_t *type,
+		uint8_t **fsname, uint8_t *fsnlen,
+		uint8_t **pk, uint8_t *pklen)
+{
+	int fsnl, pkl;
+	if( type != NULL )
+		*type = key[0];
+
+	fsnl = key[1];
+	if( fsnlen != NULL && *fsname != NULL ) {
+		*fsnlen = key[1];
+		*fsname = &key[2];
+	}
+
+	/* 0 = key[2 + fsnl] */
+
+	pkl = key[3 + fsnl];
+	if( pklen != NULL && *pk != NULL ) {
+		*pklen = key[3 + fsnl];
+		*pk = &key[4 + fsnl];
+	}
+
+	/* 0 = key[4 + fsnl + *pklen] */
+
+	return fsnl + pkl + 5;
+}
+
+/**
+ * pack_drop_mask - 
+ * @mask: 
+ * @fsname: 
+ * 
+ * 
+ * Returns: int
+ */
+int pack_drop_mask(uint8_t *mask, uint16_t mlen, uint8_t *fsname)
+{
+	int fsnlen;
+	fsnlen = strlen(fsname);
+
+	memset (mask, 0, GIO_KEY_SIZE);
+
+	mask[0] = 0xff;
+	mask[1] = fsnlen;
+	memcpy(&mask[2], fsname, fsnlen);
+	mask[2 + fsnlen] = 0;
+	/* rest should be 0xff */
+
+	return 3 + fsnlen;
+}
+
+/**
+ * find_and_mark_lock - 
+ * @key: 
+ * @keylen: 
+ * @lockp: 
+ * 
+ * looks for a lock struct of key.  If found, marks it.
+ * 
+ * Returns: TRUE or FALSE
+ */
+int
+find_and_mark_lock (uint8_t * key, uint8_t keylen, gulm_lock_t ** lockp)
+{
+	int found = FALSE;
+	uint32_t bkt;
+	gulm_lock_t *lck = NULL;
+	struct list_head *tmp;
+
+	/* now find the lock */
+	bkt = hash_lock_key (key, keylen);
+	bkt %= gulm_cm.ltpx.hashbuckets;
+
+	spin_lock (&gulm_cm.ltpx.hshlk[bkt]);
+	list_for_each (tmp, &gulm_cm.ltpx.lkhsh[bkt]) {
+		lck = list_entry (tmp, gulm_lock_t, gl_list);
+		if (memcmp (lck->key, key, keylen) == 0) {
+			found = TRUE;
+			atomic_inc (&lck->count);
+			break;
+		}
+	}
+	spin_unlock (&gulm_cm.ltpx.hshlk[bkt]);
+
+	if (found)
+		*lockp = lck;
+
+	return found;
+}
+
+/**
+ * mark_lock - 
+ * @lck: 
+ * 
+ * like above, but since we have the lock, don't search for it.
+ * 
+ * Returns: int
+ */
+void __inline__
+mark_lock (gulm_lock_t * lck)
+{
+	atomic_inc (&lck->count);
+}
+
+/**
+ * unmark_and_release_lock - 
+ * @lck: 
+ * 
+ * decrement the counter on a lock, freeing it if it reaches 0.
+ * (also removes it from the hash table)
+ * 
+ * TRUE if lock was freed.
+ *
+ * Returns: TRUE or FALSE
+ */
+int
+unmark_and_release_lock (gulm_lock_t * lck)
+{
+	uint32_t bkt;
+	int deld = FALSE;
+
+	bkt = hash_lock_key (lck->key, lck->keylen);
+	bkt %= gulm_cm.ltpx.hashbuckets;
+	spin_lock (&gulm_cm.ltpx.hshlk[bkt]);
+	if (atomic_dec_and_test (&lck->count)) {
+		list_del (&lck->gl_list);
+		deld = TRUE;
+	}
+	spin_unlock (&gulm_cm.ltpx.hshlk[bkt]);
+	if (deld) {
+		gulm_cm.ltpx.locks_total--;
+		gulm_cm.ltpx.locks_unl--;
+		if (lck->lvb != NULL) {
+			kfree (lck->lvb);
+		}
+		kfree (lck);
+	}
+
+	return deld;
+}
+
+/****************************************************************************/
+
+/**
+ * gulm_key_to_lm_lockname - 
+ * @key: 
+ * @lockname: 
+ * 
+ */
+void
+gulm_key_to_lm_lockname (uint8_t * key, struct lm_lockname *lockname)
+{
+	int pos;
+
+	pos = key[1] + 4;
+	/* pos now points to the first byte of the GFS lockname that was
+	 * embedded in the gulm lock key
+	 */
+
+	(*lockname).ln_type = key[pos];
+	(*lockname).ln_number  = (u64) (key[pos+1]) << 56;
+	(*lockname).ln_number |= (u64) (key[pos+2]) << 48;
+	(*lockname).ln_number |= (u64) (key[pos+3]) << 40;
+	(*lockname).ln_number |= (u64) (key[pos+4]) << 32;
+	(*lockname).ln_number |= (u64) (key[pos+5]) << 24;
+	(*lockname).ln_number |= (u64) (key[pos+6]) << 16;
+	(*lockname).ln_number |= (u64) (key[pos+7]) << 8;
+	(*lockname).ln_number |= (u64) (key[pos+8]) << 0;
+}
+
+void
+do_drop_lock_req (gulm_fs_t * fs, uint8_t state, uint8_t key[GIO_KEY_SIZE])
+{
+	unsigned int type;
+	struct lm_lockname lockname;
+	/* i might want to shove most of this function into the new
+	 * lockcallback handing queue.
+	 * later.
+	 */
+
+	/* don't do callbacks on the gulm mount lock.
+	 * */
+	if (key[0] != 'G') {
+		return;
+	}
+
+	switch (state) {
+	case lg_lock_state_Unlock:
+		type = LM_CB_DROPLOCKS;
+		break;
+	case lg_lock_state_Exclusive:
+		type = LM_CB_NEED_E;
+		break;
+	case lg_lock_state_Shared:
+		type = LM_CB_NEED_S;
+		break;
+	case lg_lock_state_Deferred:
+		type = LM_CB_NEED_D;
+		break;
+	default:
+		type = LM_CB_DROPLOCKS;
+		break;
+	}
+	gulm_key_to_lm_lockname (key, &lockname);
+
+	qu_drop_req (&fs->cq, fs->cb, fs->fsdata, type,
+		     lockname.ln_type, lockname.ln_number);
+}
+
+/**
+ * send_async_reply - 
+ * @lck: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+send_async_reply (gulm_lock_t * lck)
+{
+	gulm_fs_t *fs = lck->fs;
+	struct lm_lockname lockname;
+
+	if (lck->key[0] == 'F') {
+		/* whee! it is the first mounter lock.  two things:
+		 * A: gfs could care less about this.
+		 * B: we need to up the sleeper in the fs.  (hack)
+		 */
+		complete (&fs->sleep);
+		return;
+	}
+
+	if( lck->key[0] != 'G' ) return;
+
+	gulm_key_to_lm_lockname (lck->key, &lockname);
+
+	qu_async_rpl (&fs->cq, fs->cb, fs->fsdata, &lockname, lck->result);
+}
+
+/**
+ * send_drop_exp_inter - 
+ * @lt: 
+ * @name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+send_drop_exp_inter (gulm_fs_t * fs, lock_table_t * lt, char *name)
+{
+	int err, len;
+	uint8_t mask[GIO_KEY_SIZE];
+
+	len = pack_drop_mask(mask, GIO_KEY_SIZE, fs->fs_name); 
+
+	err = lg_lock_drop_exp (gulm_cm.hookup, name, mask, len);
+
+	return err;
+}
+
+/**
+ * send_lock_action - 
+ * @lck: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+send_lock_action (gulm_lock_t * lck, uint8_t action)
+{
+	int err;
+
+	GULM_ASSERT (lck->req_type == glck_action, dump_gulm_lock_t (lck););
+
+	err = lg_lock_action_req (gulm_cm.hookup, lck->key, lck->keylen,
+				  0, action, lck->lvb, lck->fs->lvb_size);
+	if (err != 0)
+		log_err ("Issues sending action request. %d\n", err);
+
+	return err;
+}
+
+/**
+ * send_lock_req - 
+ * @lck: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+send_lock_req (gulm_lock_t * lck)
+{
+	gulm_fs_t *fs = lck->fs;
+	int err;
+	uint32_t flags = 0;
+	uint8_t state;
+
+	GULM_ASSERT (lck->req_type == glck_state, dump_gulm_lock_t (lck););
+
+	switch (lck->req_state) {
+	case LM_ST_EXCLUSIVE:
+		state = lg_lock_state_Exclusive;
+		break;
+	case LM_ST_DEFERRED:
+		state = lg_lock_state_Deferred;
+		break;
+	case LM_ST_SHARED:
+		state = lg_lock_state_Shared;
+		break;
+	case LM_ST_UNLOCKED:
+		state = lg_lock_state_Unlock;
+		break;
+	default:
+		GULM_ASSERT (0, log_err ("fsid=%s: Anit no lock state %d.\n",
+					 fs->fs_name, lck->req_state););
+		break;
+	}
+	if (lck->flags & LM_FLAG_TRY) {
+		flags |= lg_lock_flag_Try;
+	}
+	if (lck->flags & LM_FLAG_TRY_1CB) {
+		flags |= lg_lock_flag_Try | lg_lock_flag_DoCB;
+	}
+	if (lck->flags & LM_FLAG_NOEXP) {
+		flags |= lg_lock_flag_IgnoreExp;
+	}
+	if (lck->flags & LM_FLAG_ANY) {
+		flags |= lg_lock_flag_Any;
+	}
+	if (lck->flags & LM_FLAG_PRIORITY) {
+		flags |= lg_lock_flag_Piority;
+	}
+	if (lck->lvb != NULL) {
+		print_lk_lvb (lck->key, lck->lvb, lck->req_state, "Sending");
+	}
+
+	err = lg_lock_state_req (gulm_cm.hookup, lck->key, lck->keylen,
+				 0, 0, ~((uint64_t)0),
+				 state, flags, lck->lvb, lck->fs->lvb_size);
+	if (err != 0)
+		log_err ("Issues sending state request. %d\n", err);
+
+	return err;
+}
+
+/**
+ * toggle_lock_counters - 
+ * 
+ * called after a succesful request to change lock state.  Decrements
+ * counts for what the lock was, and increments for what it is now.
+ */
+void
+toggle_lock_counters (lock_table_t * lt, int old, int new)
+{
+	/* what we had it in */
+	switch (old) {
+	case LM_ST_EXCLUSIVE:
+		lt->locks_exl--;
+		break;
+	case LM_ST_DEFERRED:
+		lt->locks_dfr--;
+		break;
+	case LM_ST_SHARED:
+		lt->locks_shd--;
+		break;
+	case LM_ST_UNLOCKED:
+		lt->locks_unl--;
+		break;
+	}
+	/* what we have it in */
+	switch (new) {
+	case LM_ST_EXCLUSIVE:
+		lt->locks_exl++;
+		break;
+	case LM_ST_DEFERRED:
+		lt->locks_dfr++;
+		break;
+	case LM_ST_SHARED:
+		lt->locks_shd++;
+		break;
+	case LM_ST_UNLOCKED:
+		lt->locks_unl++;
+		break;
+	}
+}
+
+/**
+ * calc_lock_result - 
+ * @lck: 
+ * @state: 
+ * @error: 
+ * @flags: 
+ * 
+ * This calculates the correct result to return for gfs lock requests.
+ * 
+ * Returns: int
+ */
+int
+calc_lock_result (gulm_lock_t * lck,
+		  uint8_t state, uint32_t error, uint32_t flags)
+{
+	gulm_fs_t *fs = lck->fs;
+	lock_table_t *lt = &gulm_cm.ltpx;
+	int result = -69;
+
+	/* adjust result based on success status. */
+	switch (error) {
+	case lg_err_Ok:
+		/* set result to current lock state. */
+		if (!(lck->flags & LM_FLAG_ANY)) {
+			/* simple case, we got what we asked for. */
+			result = lck->req_state;
+		} else {
+			/* complex case, we got something else, but we said that was ok */
+			switch (state) {
+			case lg_lock_state_Shared:
+				result = LM_ST_SHARED;
+				break;
+			case lg_lock_state_Deferred:
+				result = LM_ST_DEFERRED;
+				break;
+
+			case lg_lock_state_Exclusive:
+			case lg_lock_state_Unlock:
+				GULM_ASSERT (0,
+					     dump_gulm_lock_t (lck);
+					     log_err
+					     ("fsid=%s: lock state %d is invalid on "
+					      "ANY flag return\n", fs->fs_name,
+					      state);
+				    );
+				break;
+
+			default:
+				GULM_ASSERT (0,
+					     dump_gulm_lock_t (lck);
+					     log_err_lck (lck,
+							  "fsid=%s: Anit no lock state %d.\n",
+							  fs->fs_name, state);
+				    );
+				break;
+			}
+		}
+
+		/* toggle counters.
+		 * due to ANY flag, new state may not be req_state.
+		 * */
+		toggle_lock_counters (lt, lck->cur_state, result);
+
+		/* if no internal unlocks, it is cachable. */
+		if (result != LM_ST_UNLOCKED && (flags & lg_lock_flag_Cachable))
+			result |= LM_OUT_CACHEABLE;
+
+		/* record and move on
+		 * */
+		lck->last_suc_state = result & LM_OUT_ST_MASK;
+		break;
+	case lg_err_Canceled:
+		result = LM_OUT_CANCELED | lck->cur_state;
+		break;
+	case lg_err_TryFailed:
+		result = lck->cur_state;	/* if we didn't get it. */
+		break;
+	default:
+		result = -error;
+		break;
+	}
+
+	return result;
+}
+
+/**
+ * my_strdup - 
+ * @s: 
+ * 
+ * 
+ * Returns: char
+ */
+char *
+my_strdup (char *s)
+{
+	char *tmp;
+	int len;
+	len = strlen (s) + 1;
+	tmp = kmalloc (len, GFP_KERNEL);
+	if (tmp == NULL)
+		return NULL;
+	memcpy (tmp, s, len);
+	return tmp;
+}
+
+/* Instead of directly calling the send function below, the functions will
+ * create of of these.
+ * Which exist only because I cannot stick the lock_t onto two lists
+ * at once.
+ *
+ * this could use some clean up.
+ */
+typedef struct send_req_s {
+	struct list_head sr_list;
+	enum { sr_lock, sr_act, sr_cancel, sr_drop } type;
+	gulm_lock_t *who;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+	char *name;
+} send_req_t;
+
+/**
+ * alloc_send_req - 
+ * @oid: 
+ * 
+ * 
+ * Returns: send_req_t
+ */
+send_req_t *
+alloc_send_req (void)
+{
+	send_req_t *tmp;
+	tmp = kmalloc (sizeof (send_req_t), GFP_KERNEL);
+	GULM_ASSERT (tmp != NULL,);	/* so evil.... */
+	return tmp;
+}
+
+/**
+ * send_drop_exp - 
+ * @fs: 
+ * @lt: 
+ * @name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+send_drop_exp (gulm_fs_t * fs, lock_table_t * lt, char *name)
+{
+	send_req_t *sr;
+
+	sr = alloc_send_req ();
+	INIT_LIST_HEAD (&sr->sr_list);
+	sr->type = sr_drop;
+	sr->who = NULL;
+	sr->fs = fs;
+	sr->lt = lt;
+	if (name != NULL) {
+		sr->name = my_strdup (name);
+	} else {
+		sr->name = NULL;
+	}
+
+	spin_lock (&lt->queue_sender);
+	list_add (&sr->sr_list, &lt->to_be_sent);
+	spin_unlock (&lt->queue_sender);
+
+	wake_up (&lt->send_wchan);
+	return 0;
+}
+
+/**
+ * add_lock_to_send_req_queue - 
+ * @lt: 
+ * @lck: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+add_lock_to_send_req_queue (lock_table_t * lt, gulm_lock_t * lck, int type)
+{
+	send_req_t *sr;
+
+	sr = alloc_send_req ();
+	INIT_LIST_HEAD (&sr->sr_list);
+	sr->type = type;
+	sr->who = lck;
+	sr->fs = NULL;
+	sr->lt = NULL;
+	sr->name = NULL;
+	if (type != sr_cancel)
+		lck->in_to_be_sent = TRUE;
+
+	mark_lock (lck);
+
+	spin_lock (&lt->queue_sender);
+	list_add (&sr->sr_list, &lt->to_be_sent);
+	spin_unlock (&lt->queue_sender);
+
+	wake_up (&lt->send_wchan);
+}
+
+/**
+ * queue_empty - 
+ * @lt: 
+ * 
+ * 
+ * Returns: int
+ */
+static __inline__ int
+queue_empty (lock_table_t * lt)
+{
+	int ret;
+	spin_lock (&lt->queue_sender);
+	ret = list_empty (&lt->to_be_sent);
+	spin_unlock (&lt->queue_sender);
+	return ret;
+}
+
+/**
+ * lt_io_sender_thread - 
+ * @data: 
+ *
+ * Right now, only gfs lock requests should go through this thread.
+ * Must look, May not even need this.
+ * well, it is nice to get the socket io off of what ever process the user
+ * is running that is going through gfs into here. ?is it?
+ *
+ * 
+ * Returns: int
+ */
+int
+lt_io_sender_thread (void *data)
+{
+	lock_table_t *lt = (lock_table_t *) data;
+	struct list_head *tmp;
+	send_req_t *sr = NULL;
+	int err = 0;
+
+	daemonize ("gulm_LT_sender");
+	lt->sender_task = current;
+	complete (&lt->startup);
+
+	while (lt->running) {
+		do {
+			DECLARE_WAITQUEUE (__wait_chan, current);
+			current->state = TASK_INTERRUPTIBLE;
+			add_wait_queue (&lt->send_wchan, &__wait_chan);
+			if (queue_empty (lt))
+				schedule ();
+			remove_wait_queue (&lt->send_wchan, &__wait_chan);
+			current->state = TASK_RUNNING;
+		} while (0);
+		if (!lt->running)
+			break;
+
+		/* check to make sure socket is ok. */
+		down (&lt->sender);
+
+		/* pop next item to be sent
+		 *  (it will get pushed back if there was problems.)
+		 */
+		spin_lock (&lt->queue_sender);
+		if (list_empty (&lt->to_be_sent)) {
+			spin_unlock (&lt->queue_sender);
+			up (&lt->sender);
+			continue;
+		}
+		tmp = (&lt->to_be_sent)->prev;
+		list_del (tmp);
+		spin_unlock (&lt->queue_sender);
+		sr = list_entry (tmp, send_req_t, sr_list);
+
+		/* send. */
+		if (sr->type == sr_lock) {
+			err = send_lock_req (sr->who);
+			if (err == 0) {
+				sr->who->in_to_be_sent = FALSE;
+				unmark_and_release_lock (sr->who);
+			}
+		} else if (sr->type == sr_act) {
+			err = send_lock_action (sr->who, sr->who->action);
+			if (err == 0) {
+				sr->who->in_to_be_sent = FALSE;
+				unmark_and_release_lock (sr->who);
+			}
+		} else if (sr->type == sr_cancel) {
+			err =
+			    lg_lock_cancel_req (gulm_cm.hookup, sr->who->key,
+						sr->who->keylen, 0);
+			if (err == 0)
+				unmark_and_release_lock (sr->who);
+		} else if (sr->type == sr_drop) {
+			/* XXX sr->lt isn't really needed.
+			 * just lt should be fine.
+			 * look into it someday.
+			 */
+			err = send_drop_exp_inter (sr->fs, sr->lt, sr->name);
+		} else {
+			log_err ("Unknown send_req type! %d\n", sr->type);
+		}
+		up (&lt->sender);
+
+		/* if no errors, remove from queue. */
+		if (err == 0) {
+			if (sr->type == sr_drop && sr->name != NULL)
+				kfree (sr->name);
+			kfree (sr);
+			sr = NULL;
+		} else {
+			/* if errors, re-queue.
+			 * the send_* funcs already reported the error, so we won't
+			 * repeat that.
+			 * */
+			spin_lock (&lt->queue_sender);
+			/* reset the pointers. otherwise things get weird. */
+			INIT_LIST_HEAD (&sr->sr_list);
+			list_add_tail (&sr->sr_list, &lt->to_be_sent);
+			spin_unlock (&lt->queue_sender);
+
+			current->state = TASK_INTERRUPTIBLE;
+			schedule_timeout (3 * HZ);
+
+			/* gotta break shit up.
+			 * else this loops hard and fast.
+			 */
+		}
+	}			/* while( lt->running ) */
+
+	complete (&lt->startup);
+	return 0;
+}
+
+/**
+ * cancel_pending_sender - 
+ * @lck: 
+ * 
+ * want to cancel a lock request that we haven't sent to the server yet.
+ * 
+ * this must skip over unlock requests. (never cancel unlocks)
+ * 
+ * Returns: int
+ */
+int
+cancel_pending_sender (gulm_lock_t * lck)
+{
+	lock_table_t *lt = &gulm_cm.ltpx;
+	struct list_head *tmp, *nxt;
+	send_req_t *sr;
+	int found = FALSE;
+
+	spin_lock (&lt->queue_sender);
+
+	list_for_each_safe (tmp, nxt, &lt->to_be_sent) {
+		sr = list_entry (tmp, send_req_t, sr_list);
+		if (sr->who == lck) {	/* good enough? */
+			if (lck->req_type == sr_cancel)
+				continue;
+			if (lck->req_state == LM_ST_UNLOCKED)
+				continue;	/*donot cancel unlocks */
+			list_del (tmp);
+			kfree (sr);
+			found = TRUE;
+			lck->in_to_be_sent = FALSE;
+
+			/* Now we need to tell the waiting lock req that it got canceled.
+			 * basically, we need to fake a lg_err_Canceled return....
+			 */
+			lck->result = LM_OUT_CANCELED | lck->cur_state;
+			lck->actuallypending = FALSE;
+			lck->req_type = glck_nothing;
+			atomic_dec (&lt->locks_pending);
+#ifndef USE_SYNC_LOCKING
+			send_async_reply (lck);
+#else
+			complete (&lck->actsleep);
+#endif
+			unmark_and_release_lock (lck);
+			break;
+		}
+	}
+
+	spin_unlock (&lt->queue_sender);
+	return found;
+}
+
+/**
+ * gulm_lt_login_reply - 
+ * @misc: 
+ * @error: 
+ * @which: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_login_reply (void *misc, uint32_t error, uint8_t which)
+{
+	if (error != 0) {
+		gulm_cm.ltpx.running = FALSE;
+		log_err ("LTPX: Got a %d from the login request.\n", error);
+	} else {
+		log_msg (lgm_Network2, "Logged into local LTPX.\n");
+	}
+	return error;
+}
+
+/**
+ * gulm_lt_logout_reply - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_logout_reply (void *misc)
+{
+	gulm_cm.ltpx.running = FALSE;
+	log_msg (lgm_Network2, "Logged out of local LTPX.\n");
+	return 0;
+}
+
+/**
+ * gulm_lt_lock_state - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags: 
+ * @error: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_lock_state (void *misc, uint8_t * key, uint16_t keylen,
+		    uint64_t subid, uint64_t start, uint64_t stop,
+		    uint8_t state, uint32_t flags, uint32_t error,
+		    uint8_t * LVB, uint16_t LVBlen)
+{
+	gulm_lock_t *lck;
+
+	if (key[0] == 'J' || key[0] == 'N' ) {
+		jid_state_reply (key, keylen, LVB, LVBlen);
+		return 0;
+	}
+
+	if (!find_and_mark_lock (key, keylen, &lck)) {
+		log_err_lk (key, keylen, "Got a lock state reply for a lock "
+			    "that we don't know of. state:%#x flags:%#x error:%#x\n",
+			    state, flags, error);
+		return 0;
+	}
+
+	lck->result = calc_lock_result (lck, state, error, flags);
+
+	if ((lck->result & LM_OUT_ST_MASK) != LM_ST_UNLOCKED &&
+	    lck->lvb != NULL) {
+		memcpy (lck->lvb, LVB, MIN (lck->fs->lvb_size, LVBlen));
+	}
+
+	lck->actuallypending = FALSE;
+	lck->req_type = glck_nothing;
+	atomic_dec (&gulm_cm.ltpx.locks_pending);
+#ifndef USE_SYNC_LOCKING
+	send_async_reply (lck);
+#else
+	complete (&lck->actsleep);
+#endif
+
+	if (error != 0 && error != lg_err_TryFailed && error != lg_err_Canceled)
+		log_msg_lck (lck, "Error: %d:%s (req:%#x rpl:%#x lss:%#x)\n",
+			     error, gio_Err_to_str (error),
+			     lck->req_state, state, lck->last_suc_state);
+
+	unmark_and_release_lock (lck);
+	return 0;
+}
+
+/**
+ * gulm_lt_lock_action - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @action: 
+ * @error: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_lock_action (void *misc, uint8_t * key, uint16_t keylen,
+		     uint64_t subid, uint8_t action, uint32_t error)
+{
+	gulm_lock_t *lck;
+
+	if (key[0] == 'J') {
+		jid_action_reply (key, keylen);
+		return 0;
+	}
+
+	if (!find_and_mark_lock (key, keylen, &lck)) {
+		log_err_lk (key, keylen, "Got a lock action reply for a lock "
+			    "that we don't know of. action:%#x error:%#x\n",
+			    action, error);
+		return 0;
+	}
+
+	if (action == lg_lock_act_HoldLVB ||
+	    action == lg_lock_act_UnHoldLVB || action == lg_lock_act_SyncLVB) {
+		/*  */
+		lck->result = error;
+		if (error != lg_err_Ok) {
+			log_err ("on action reply act:%d err:%d\n", action,
+				 error);
+		}
+		lck->req_type = glck_nothing;
+		lck->actuallypending = FALSE;
+		complete (&lck->actsleep);
+	} else {
+		log_err_lck (lck, "Got strange Action %#x\n", action);
+	}
+	unmark_and_release_lock (lck);
+	return 0;
+}
+
+/**
+ * gulm_lt_drop_lock_req - 
+ * @misc: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_drop_lock_req (void *misc, uint8_t * key, uint16_t keylen,
+		       uint64_t subid, uint8_t state)
+{
+	gulm_lock_t *lck;
+
+	if (key[0] == 'J') {
+		jid_header_lock_drop (key, keylen);
+		return 0;
+	}
+
+	if (!find_and_mark_lock (key, keylen, &lck)) {
+		log_err_lk (key, keylen, "Got a drop lcok request for a lock "
+			    "that we don't know of. state:%#x\n", state);
+		return 0;
+	}
+
+	do_drop_lock_req (lck->fs, state, key);
+
+	unmark_and_release_lock (lck);
+	return 0;
+}
+
+/**
+ * gulm_lt_drop_all - 
+ * @misc: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_drop_all (void *misc)
+{
+	passup_droplocks ();
+	return 0;
+}
+
+/**
+ * gulm_lt_error - 
+ * @misc: 
+ * @err: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+gulm_lt_error (void *misc, uint32_t err)
+{
+	log_err ("LTPX: RANDOM ERROR %d\n", err);
+	return err;
+}
+
+static lg_lockspace_callbacks_t lock_cb = {
+      login_reply:gulm_lt_login_reply,
+      logout_reply:gulm_lt_logout_reply,
+      lock_state:gulm_lt_lock_state,
+      lock_action:gulm_lt_lock_action,
+      drop_lock_req:gulm_lt_drop_lock_req,
+      drop_all:gulm_lt_drop_all,
+      error:gulm_lt_error
+};
+
+/**
+ * lt_io_recving_thread - 
+ * @data: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lt_io_recving_thread (void *data)
+{
+	lock_table_t *lt = &gulm_cm.ltpx;
+	int err;
+
+	daemonize ("gulm_LT_recver");
+	lt->recver_task = current;
+	complete (&lt->startup);
+
+	while (lt->running) {
+		err = lg_lock_handle_messages (gulm_cm.hookup, &lock_cb, NULL);
+		if (err != 0) {
+			log_err ("gulm_LT_recver err %d\n", err);
+			lt->running = FALSE;	/* should stop the sender thread. */
+			wake_up (&lt->send_wchan);
+			break;
+		}
+	}			/* while( lt->running ) */
+
+	complete (&lt->startup);
+	return 0;
+}
+
+/**
+ * lt_logout - log out of all of the lock tables
+ */
+void
+lt_logout (void)
+{
+	lock_table_t *lt = &gulm_cm.ltpx;
+	int err;
+
+	if (lt->running) {
+		lt->running = FALSE;
+
+		/* stop sender thread */
+		wake_up (&lt->send_wchan);
+		wait_for_completion (&lt->startup);
+
+		/* stop recver thread */
+		down (&lt->sender);
+		err = lg_lock_logout (gulm_cm.hookup);
+		up (&lt->sender);
+
+		/* wait for thread to finish */
+		wait_for_completion (&lt->startup);
+	}
+
+}
+
+/**
+ * lt_login - login to lock tables.
+ * 
+ * Returns: int
+ */
+int
+lt_login (void)
+{
+	int err;
+	lock_table_t *lt = &gulm_cm.ltpx;
+
+	if (lt->running)
+		log_err
+		    ("Trying to log into LTPX when it appears to be logged in!\n");
+
+	err = lg_lock_login (gulm_cm.hookup, "GFS ");
+	if (err != 0) {
+		log_err ("Failed to send login request. %d\n", err);
+		goto fail;
+	}
+
+	/* start recver thread. */
+	lt->running = TRUE;
+	err = kernel_thread (lt_io_recving_thread, lt, 0);
+	if (err < 0) {
+		log_err ("Failed to start gulm_lt_IOd. (%d)\n", err);
+		goto fail;
+	}
+	wait_for_completion (&lt->startup);
+
+	/* start sender thread */
+	err = kernel_thread (lt_io_sender_thread, lt, 0);
+	if (err < 0) {
+		log_err ("Failed to start gulm_LT_sender. (%d)\n", err);
+		goto fail;
+	}
+	wait_for_completion (&lt->startup);
+
+	return 0;
+      fail:
+	lt_logout ();
+	log_msg (lgm_Always, "Exiting lt_login. err:%d\n", err);
+	return err;
+}
+
+/****************************************************************************/
+
+/**
+ * internal_gulm_get_lock - 
+ * @fs: 
+ * @key: 
+ * @keylen: 
+ * @lockp: 
+ * 
+ * 
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+internal_gulm_get_lock (gulm_fs_t * fs, uint8_t * key, uint8_t keylen,
+			gulm_lock_t ** lockp)
+{
+	int found = FALSE;
+	uint32_t bkt;
+	gulm_lock_t *lck = NULL;
+
+	found = find_and_mark_lock (key, keylen, &lck);
+
+	/* malloc space */
+	if (found) {
+		GULM_ASSERT (lck->magic_one == 0xAAAAAAAA,);
+	} else {
+		lck = kmalloc (sizeof (gulm_lock_t), GFP_KERNEL);
+		if (lck == NULL) {
+			log_err
+			    ("fsid=%s: Out of memory for lock struct in get_lock!\n",
+			     fs->fs_name);
+			return -ENOMEM;
+		}
+		memset (lck, 0, sizeof (gulm_lock_t));
+		INIT_LIST_HEAD (&lck->gl_list);
+		atomic_set (&lck->count, 1);
+		lck->magic_one = 0xAAAAAAAA;
+		lck->fs = fs;
+		memcpy (lck->key, key, keylen);
+		lck->keylen = keylen;
+		lck->lvb = NULL;
+		init_completion (&lck->actsleep);
+		lck->actuallypending = FALSE;
+		lck->in_to_be_sent = FALSE;
+		lck->result = 0;
+		lck->action = -1;
+		lck->req_type = glck_nothing;
+		lck->last_suc_state = LM_ST_UNLOCKED;
+
+		gulm_cm.ltpx.locks_total++;
+		gulm_cm.ltpx.locks_unl++;
+
+		bkt = hash_lock_key (key, keylen);
+		bkt %= gulm_cm.ltpx.hashbuckets;
+
+		spin_lock (&gulm_cm.ltpx.hshlk[bkt]);
+		list_add (&lck->gl_list, &gulm_cm.ltpx.lkhsh[bkt]);
+		spin_unlock (&gulm_cm.ltpx.hshlk[bkt]);
+	}
+
+	*lockp = lck;
+
+	return 0;
+}
+
+/**
+ * gulm_get_lock - 
+ * @lockspace: 
+ * @name: 
+ * @lockp:
+ * 
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_get_lock (lm_lockspace_t * lockspace, struct lm_lockname *name,
+	       lm_lock_t ** lockp)
+{
+	int err, len;
+	gulm_fs_t *fs = (gulm_fs_t *) lockspace;
+	uint8_t key[GIO_KEY_SIZE]; uint8_t temp[9];
+
+	down (&fs->get_lock);
+
+
+	temp[0] = name->ln_type & 0xff;
+	temp[1] = (name->ln_number >> 56) & 0xff;
+	temp[2] = (name->ln_number >> 48) & 0xff;
+	temp[3] = (name->ln_number >> 40) & 0xff;
+	temp[4] = (name->ln_number >> 32) & 0xff;
+	temp[5] = (name->ln_number >> 24) & 0xff;
+	temp[6] = (name->ln_number >> 16) & 0xff;
+	temp[7] = (name->ln_number >> 8) & 0xff;
+	temp[8] = (name->ln_number >> 0) & 0xff;
+
+	len = pack_lock_key(key, GIO_KEY_SIZE, 'G', fs->fs_name, temp, 9);
+	if( len <=0 ) {err = len; goto exit;}
+
+	err = internal_gulm_get_lock (fs, key, len, (gulm_lock_t **) lockp);
+
+	up (&fs->get_lock);
+exit:
+	return err;
+}
+
+/**
+ * gulm_put_lock - 
+ * @lock: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+gulm_put_lock (lm_lock_t * lock)
+{
+	gulm_lock_t *lck = (gulm_lock_t *) lock;
+	lock_table_t *lt = &gulm_cm.ltpx;
+	gulm_fs_t *fs = lck->fs;
+
+	down (&fs->get_lock);
+
+	GULM_ASSERT (lt != NULL,);
+
+	if (lck->last_suc_state != LM_ST_UNLOCKED) {
+		log_err_lck (lck,
+			     "fsid=%s: gulm_put_lock called on a lock that is not unlocked!"
+			     " Current state:%#x\n", lck->fs->fs_name,
+			     lck->last_suc_state);
+		/* I'm still not sure about this one.  We should never see it, so I
+		 * don't think it is that big of a deal, but i duno.
+		 *
+		 * Maybe should just make it an assertion.
+		 *
+		 * with the mark/unmark code, is it even a concern?
+		 */
+	}
+
+	unmark_and_release_lock (lck);
+	/* lck = NULL; */
+
+	up (&fs->get_lock);
+
+}
+
+static int
+valid_trasition (unsigned int cur, unsigned int req)
+{
+	int lock_state_changes[16] = {	/* unl   exl    def    shr  */
+		FALSE, TRUE, TRUE, TRUE,	/* unl */
+		TRUE, FALSE, TRUE, TRUE,	/* exl */
+		TRUE, TRUE, FALSE, TRUE,	/* def */
+		TRUE, TRUE, TRUE, FALSE	/* shr */
+	};
+	GULM_ASSERT (cur < 4
+		     && req < 4, log_err ("cur:%d req:%d\n", cur, req););
+
+	return (lock_state_changes[4 * cur + req]);
+}
+
+/**
+ * verify_gulm_lock_t - 
+ * @lck: 
+ * 
+ * wonder if I should add some other checks.
+ * 
+ * Returns: int
+ */
+int
+verify_gulm_lock_t (gulm_lock_t * lck)
+{
+	if (lck == NULL) {
+		log_err ("Lock pointer was NULL!\n");
+		return -1;
+	}
+	if (lck->fs == NULL) {
+		log_err ("This lock has no filesystem!!!\n");
+		return -1;
+	}
+	return 0;
+}
+
+/**
+ * gulm_lock - 
+ * @lock: 
+ * @cur_state: 
+ * @req_state: 
+ * @flags: 
+ * 
+ * 
+ * Returns: int
+ */
+unsigned int
+gulm_lock (lm_lock_t * lock, unsigned int cur_state,
+	   unsigned int req_state, unsigned int flags)
+{
+	gulm_lock_t *lck = NULL;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+
+	/* verify vars. */
+	lck = (gulm_lock_t *) lock;
+	if (verify_gulm_lock_t (lck) != 0) {
+		return -EINVAL;
+	}
+	lt = &gulm_cm.ltpx;
+	fs = lck->fs;
+
+	GULM_ASSERT (valid_trasition (cur_state, req_state),
+		     log_err_lck (lck, "want %d with %s thinks:%d\n", req_state,
+				  (LM_FLAG_TRY & flags) ? "try" : (LM_FLAG_NOEXP
+								   & flags) ?
+				  "noexp" : "no flags", cur_state);
+	    );
+
+	GULM_ASSERT (lck->actuallypending == FALSE, dump_gulm_lock_t (lck););
+
+	/* save the details of this request. */
+	lck->req_type = glck_state;
+	lck->result = 0;
+	lck->cur_state = cur_state;
+	lck->req_state = req_state;
+	lck->flags = flags;
+
+	/* moving these here fixes a race on the s390 that ben found.
+	 * basically, the request was sent to the server, the server receives
+	 * it, the server processes, the server sends a reply, the client
+	 * receives the reply, and the client tries to processe the reply before
+	 * this thread could mark it as actuallypending.
+	 * */
+	lck->actuallypending = TRUE;
+	atomic_inc (&lt->locks_pending);
+	add_lock_to_send_req_queue (lt, lck, sr_lock);
+
+	lt->lops++;
+#ifdef USE_SYNC_LOCKING
+	wait_for_completion (&lck->actsleep);
+#endif
+
+#ifdef USE_SYNC_LOCKING
+	return lck->result;
+#else
+	return LM_OUT_ASYNC;
+#endif
+}
+
+/**
+ * gulm_unlock - 
+ * @lock: 
+ * @cur_state: 
+ * 
+ * 
+ * Returns: int
+ */
+unsigned int
+gulm_unlock (lm_lock_t * lock, unsigned int cur_state)
+{
+	int e;
+	e = gulm_lock (lock, cur_state, LM_ST_UNLOCKED, 0);
+	return e;
+}
+
+/**
+ * gulm_cancel - 
+ * @lock: 
+ * 
+ */
+void
+gulm_cancel (lm_lock_t * lock)
+{
+	gulm_lock_t *lck;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+
+	/* verify vars. */
+	lck = (gulm_lock_t *) lock;
+	if (verify_gulm_lock_t (lck) != 0) {
+		return;
+	}
+	lt = &gulm_cm.ltpx;
+	fs = lck->fs;
+
+	if (lck->actuallypending) {
+		if (lck->in_to_be_sent) {
+			/* this should pull the req out of the send queue and have it
+			 * return with a cancel code without going to the server.
+			 */
+			cancel_pending_sender (lck);
+		} else {
+			add_lock_to_send_req_queue (lt, lck, sr_cancel);
+		}
+	} else {
+		log_msg_lck (lck, "Cancel called with no pending request.\n");
+	}
+
+}
+
+/**
+ * gulm_hold_lvb - 
+ * @lock: 
+ * @lvbp:
+ * 
+ * 
+ * Returns: 0 on success, -EXXX on failure
+ */
+int
+gulm_hold_lvb (lm_lock_t * lock, char **lvbp)
+{
+	gulm_lock_t *lck;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+	int err = -1;
+
+	/* verify vars. */
+	lck = (gulm_lock_t *) lock;
+	if (verify_gulm_lock_t (lck) != 0) {
+		return -EINVAL;
+	}
+	lt = &gulm_cm.ltpx;
+	fs = lck->fs;
+
+	/* what where these for? */
+	GULM_ASSERT (lck->magic_one == 0xAAAAAAAA,
+		     log_msg_lck (lck, "Bad gulm_lock magic.\n"););
+	GULM_ASSERT (lt->magic_one == 0xAAAAAAAA,
+		     log_msg_lck (lck, "Bad lock_table magic.\n"););
+
+	lvb_log_msg_lk (lck->key, "Entering gulm_hold_lvb\n");
+
+	GULM_ASSERT (lck->lvb == NULL,
+		     log_msg_lck (lck,
+				  "fsid=%s: Lvb data wasn't null! must be held "
+				  "already.\n", fs->fs_name);
+	    );
+
+	GULM_ASSERT (lck->actuallypending == FALSE, dump_gulm_lock_t (lck););
+
+	lck->lvb = kmalloc (fs->lvb_size, GFP_KERNEL);
+	if (lck->lvb == NULL) {
+		err = -ENOMEM;
+		goto fail;
+	}
+	memset (lck->lvb, 0, fs->lvb_size);
+
+	lck->req_type = glck_action;
+	lck->action = lg_lock_act_HoldLVB;
+	lck->result = 0;
+	lck->actuallypending = TRUE;
+	add_lock_to_send_req_queue (lt, lck, sr_act);
+
+	wait_for_completion (&lck->actsleep);
+
+	if (lck->result != lg_err_Ok) {
+		log_err ("fsid=%s: Got error %d on hold lvb request.\n",
+			 fs->fs_name, lck->result);
+		kfree (lck->lvb);
+		lck->lvb = NULL;
+		goto fail;
+	}
+
+	lt->locks_lvbs++;
+
+	*lvbp = lck->lvb;
+
+	lvb_log_msg_lk (lck->key, "fsid=%s: Exiting gulm_hold_lvb\n",
+			fs->fs_name);
+	return 0;
+      fail:
+	if (err != 0)
+		log_msg (lgm_Always,
+			 "fsid=%s: Exiting gulm_hold_lvb with errors (%d)\n",
+			 fs->fs_name, err);
+	return err;
+}
+
+/**
+ * gulm_unhold_lvb - 
+ * @lock: 
+ * @lvb: 
+ * 
+ * 
+ * Returns: void
+ */
+void
+gulm_unhold_lvb (lm_lock_t * lock, char *lvb)
+{
+	gulm_lock_t *lck = NULL;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+
+	/* verify vars. */
+	lck = (gulm_lock_t *) lock;
+	if (verify_gulm_lock_t (lck) != 0) {
+		return;
+	}
+	lt = &gulm_cm.ltpx;
+	fs = lck->fs;
+
+	GULM_ASSERT (lck->actuallypending == FALSE, dump_gulm_lock_t (lck););
+
+	if (lck->lvb != lvb) {
+		log_err ("fsid=%s: AH! LVB pointer missmatch! %p != %p\n",
+			 fs->fs_name, lck->lvb, lvb);
+		goto exit;
+	}
+
+	lvb_log_msg_lk (lck->key, "Entering gulm_unhold_lvb\n");
+
+	lck->req_type = glck_action;
+	lck->action = lg_lock_act_UnHoldLVB;
+	lck->result = 0;
+	lck->actuallypending = TRUE;
+	add_lock_to_send_req_queue (lt, lck, sr_act);
+
+	wait_for_completion (&lck->actsleep);
+
+	/* XXX ummm, is it sane to not free the memory if the command fails?
+	 * gfs will still think that the lvb was dropped sucessfully....
+	 * (it assumes it is always sucessful)
+	 * Maybe I should retry the drop request then?
+	 */
+	if (lck->result != lg_err_Ok) {
+		log_err ("fsid=%s: Got error %d on unhold LVB request.\n",
+			 lck->fs->fs_name, lck->result);
+	} else {
+		if (lck->lvb != NULL)
+			kfree (lck->lvb);
+		lck->lvb = NULL;
+		lt->locks_lvbs--;
+	}
+      exit:
+	lvb_log_msg ("Exiting gulm_unhold_lvb\n");
+}
+
+/**
+ * gulm_sync_lvb - 
+ * @lock: 
+ * @lvb: 
+ * 
+ * umm, is this even used anymore? yes.
+ * 
+ * Returns: void
+ */
+void
+gulm_sync_lvb (lm_lock_t * lock, char *lvb)
+{
+	gulm_lock_t *lck = NULL;
+	gulm_fs_t *fs;
+	lock_table_t *lt;
+
+	/* verify vars. */
+	lck = (gulm_lock_t *) lock;
+	if (verify_gulm_lock_t (lck) != 0) {
+		return;
+	}
+	lt = &gulm_cm.ltpx;
+	fs = lck->fs;
+
+	GULM_ASSERT (lck->actuallypending == FALSE, dump_gulm_lock_t (lck););
+
+	/* this check is also in the server, so it isn't really needed here. */
+	if (lck->last_suc_state != LM_ST_EXCLUSIVE) {
+		log_err ("sync_lvb: You must hold the lock Exclusive first.\n");
+		goto exit;	/*cannot do anything */
+	}
+	if (lck->lvb == NULL) {
+		log_err ("sync_lvb: You forgot to call hold lvb first.\n");
+		goto exit;
+	}
+	if (lck->lvb != lvb) {
+		log_err ("fsid=%s: AH! LVB pointer missmatch! %p != %p\n",
+			 fs->fs_name, lck->lvb, lvb);
+		goto exit;
+	}
+
+	lvb_log_msg_lk (lck->key, "Entering gulm_sync_lvb\n");
+
+	lck->req_type = glck_action;
+	lck->action = lg_lock_act_SyncLVB;
+	lck->result = 0;
+	lck->actuallypending = TRUE;
+	add_lock_to_send_req_queue (lt, lck, sr_act);
+
+	wait_for_completion (&lck->actsleep);
+
+	/* XXX? retry if I get an error? */
+	if (lck->result != lg_err_Ok) {
+		log_err_lck (lck,
+			     "fsid=%s: Got error %d:%s on Sync LVB request.\n",
+			     fs->fs_name, lck->result,
+			     gio_Err_to_str (lck->result));
+	}
+      exit:
+	lvb_log_msg ("Exiting gulm_sync_lvb\n");
+}
+
+/*****************************************************************************/
+static int
+gulm_plock_get (lm_lockspace_t * lockspace,
+		struct lm_lockname *name, unsigned long owner,
+		uint64_t * start, uint64_t * end, int *exclusive,
+		unsigned long *rowner)
+{
+	return -ENOSYS;
+}
+
+static int
+gulm_plock (lm_lockspace_t * lockspace,
+	    struct lm_lockname *name, unsigned long owner,
+	    int wait, int exclusive, uint64_t start, uint64_t end)
+{
+	return -ENOSYS;
+}
+
+static int
+gulm_punlock (lm_lockspace_t * lockspace,
+	      struct lm_lockname *name, unsigned long owner,
+	      uint64_t start, uint64_t end)
+{
+	return -ENOSYS;
+}
+
+/****************************************************************************/
+/****************************************************************************/
+/****************************************************************************/
+/* should move the firstmounter lock stuff into its own file perhaps? */
+/**
+ * get_special_lock - 
+ * @fs: <> filesystem we're getting special lock for
+ *
+ * Returns: gulm_lock_t
+ */
+STATIC gulm_lock_t *
+get_special_lock (gulm_fs_t * fs)
+{
+	int err, len;
+	gulm_lock_t *lck = NULL;
+	uint8_t key[GIO_KEY_SIZE];
+
+	len = pack_lock_key(key, GIO_KEY_SIZE, 'F', fs->fs_name, "irstMount", 9);
+	if( len <= 0 ) return NULL;
+
+	err = internal_gulm_get_lock (fs, key, len, &lck);
+
+	/* return pointer */
+	return lck;
+}
+
+/**
+ * do_lock_time_out - 
+ * @d: 
+ *
+ * after timeout, set cancel request on the handler queue. (since we cannot
+ * call it from within the timer code.
+ * 
+ */
+static void
+do_lock_time_out (unsigned long d)
+{
+	gulm_lock_t *lck = (gulm_lock_t *) d;
+	qu_function_call (&lck->fs->cq, gulm_cancel, lck);
+}
+
+/**
+ * get_mount_lock - 
+ * @fs: 
+ * @first: 
+ * 
+ * Get the Firstmount lock.
+ * We try to grab it Exl.  IF we get that, then we are the first client
+ * mounting this fs.  Otherwise we grab it shared to show that there are
+ * clients using this fs.
+ * 
+ * Returns: int
+ */
+int
+get_mount_lock (gulm_fs_t * fs, int *first)
+{
+	int err;
+	struct timer_list locktimeout;
+	gulm_lock_t *lck = NULL;
+	/*
+	 * first we need to get the lock into the hash.
+	 * then we can try to get it Exl with try and noexp.
+	 * if the try fails, grab it shared.
+	 */
+
+	lck = get_special_lock (fs);	/* there is only a mount lock. */
+	if (lck == NULL) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	fs->mountlock = lck;
+      try_it_again:
+	*first = FALSE;		/* assume we're not first */
+
+	err = gulm_lock (lck, LM_ST_UNLOCKED, LM_ST_EXCLUSIVE,
+			 LM_FLAG_TRY | LM_FLAG_NOEXP);
+#ifndef USE_SYNC_LOCKING
+	wait_for_completion (&fs->sleep);
+#endif
+
+	if ((lck->result & LM_OUT_ST_MASK) == LM_ST_EXCLUSIVE) {
+		/* we got the lock, we're the first mounter. */
+		*first = TRUE;
+		log_msg (lgm_locking, "fsid=%s: Got mount lock Exclusive.\n",
+			 fs->fs_name);
+		return 0;
+	} else if ((lck->result & LM_OUT_ST_MASK) == LM_ST_UNLOCKED) {
+		log_msg (lgm_locking,
+			 "fsid=%s: Didn't get mount lock Exl, someone else "
+			 "was first, trying for shared.\n", fs->fs_name);
+
+		/* the try failed, pick it up shared. */
+		/* There was a case (bug #220) where we could hang here.
+		 *
+		 * To handle this, we put up a timer for a couple of
+		 * minutes.  That if it trips, it cancels our shared
+		 * request.  Which we then see, so we go back and try the
+		 * EXL again.  If the Firstmounter is fine and is just
+		 * taking a damn long time to do its work, this just ends
+		 * back here, no worse for the wear.
+		 *
+		 * Another way to do this, is to wait for a killed message
+		 * for the master.  When we get that, && we're pending
+		 * shared here, send the gulm_canel for the mounter lock.
+		 * (too bad we are not in the fs list yet at this point.
+		 * (well, maybe that *isn't* a bad thing))
+		 */
+		init_timer (&locktimeout);
+		locktimeout.function = do_lock_time_out;
+		locktimeout.data = (unsigned long) lck;
+		mod_timer (&locktimeout, jiffies + (120 * HZ));
+		err = gulm_lock (lck, LM_ST_UNLOCKED, LM_ST_SHARED, 0);
+#ifndef USE_SYNC_LOCKING
+		wait_for_completion (&fs->sleep);
+#endif
+		del_timer (&locktimeout);
+
+		if ((lck->result & LM_OUT_ST_MASK) == LM_ST_SHARED) {
+			/* kewl we got it. */
+			log_msg (lgm_locking,
+				 "fsid=%s: Got mount lock shared.\n",
+				 fs->fs_name);
+			return 0;
+		}
+
+		log_msg (lgm_locking,
+			 "fsid=%s: Shared req timed out, trying Exl again.\n",
+			 fs->fs_name);
+		goto try_it_again;
+	}
+      fail:
+	log_err ("Exit get_mount_lock err=%d\n", err);
+	return err;
+}
+
+/**
+ * downgrade_mount_lock - 
+ * @fs: 
+ * 
+ * drop the Firstmount lock down to shared.  This lets other mount.
+ * 
+ * Returns: int
+ */
+int
+downgrade_mount_lock (gulm_fs_t * fs)
+{
+	int err;
+	gulm_lock_t *lck = (gulm_lock_t *) fs->mountlock;
+	/* we were first, so we have it exl.
+	 * shift it to shared so others may mount.
+	 */
+	err = gulm_lock (lck, LM_ST_EXCLUSIVE, LM_ST_SHARED, LM_FLAG_NOEXP);
+#ifndef USE_SYNC_LOCKING
+	wait_for_completion (&fs->sleep);
+#endif
+
+	if ((lck->result & LM_OUT_ST_MASK) != LM_ST_SHARED) {
+		log_err
+		    ("fsid=%s: Couldn't downgrade mount lock to shared!!!!!\n",
+		     fs->fs_name);
+	}
+	return 0;
+}
+
+/**
+ * drop_mount_lock - drop our hold on the firstmount lock.
+ * @fs: <> the filesystem pointer.
+ * 
+ * Returns: int
+ */
+int
+drop_mount_lock (gulm_fs_t * fs)
+{
+	int err;
+	gulm_lock_t *lck = (gulm_lock_t *) fs->mountlock;
+
+	if (fs->mountlock == NULL) {
+		log_err ("fsid=%s: There's no Mount lock!!!!!\n", fs->fs_name);
+		return -1;
+	}
+	err = gulm_unlock (lck, LM_ST_SHARED);
+#ifndef USE_SYNC_LOCKING
+	wait_for_completion (&fs->sleep);
+#endif
+
+	if (lck->result != LM_ST_UNLOCKED)
+		log_err ("fsid=%s: Couldn't unlock mount lock!!!!!!\n",
+			 fs->fs_name);
+	gulm_put_lock (fs->mountlock);
+	fs->mountlock = NULL;
+	return 0;
+}
+
+/*****************************************************************************/
+struct lm_lockops gulm_ops = {
+      lm_proto_name:PROTO_NAME,
+      lm_mount:gulm_mount,
+      lm_others_may_mount:gulm_others_may_mount,
+      lm_unmount:gulm_unmount,
+      lm_get_lock:gulm_get_lock,
+      lm_put_lock:gulm_put_lock,
+      lm_lock:gulm_lock,
+      lm_unlock:gulm_unlock,
+      lm_cancel:gulm_cancel,
+      lm_hold_lvb:gulm_hold_lvb,
+      lm_unhold_lvb:gulm_unhold_lvb,
+      lm_sync_lvb:gulm_sync_lvb,
+      lm_plock_get:gulm_plock_get,
+      lm_plock:gulm_plock,
+      lm_punlock:gulm_punlock,
+      lm_recovery_done:gulm_recovery_done,
+      lm_owner:THIS_MODULE,
+};
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_prints.h linux-patched/fs/gfs_locking/lock_gulm/gulm_prints.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_prints.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_prints.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,45 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_prints_h__
+#define __gulm_prints_h__
+#include "gulm_log_msg_bits.h"
+
+#define PROTO_NAME "lock_gulm"
+
+#ifdef GULM_ASSERT
+#undef GULM_ASSERT
+#endif
+#define GULM_ASSERT(x, do) \
+{ \
+  if (!(x)) \
+  { \
+    printk("\n"PROTO_NAME":  Assertion failed on line %d of file %s\n" \
+               PROTO_NAME":  assertion:  \"%s\"\n", \
+               __LINE__, __FILE__, #x ); \
+    {do} \
+    panic("\n"PROTO_NAME":  Record message above and reboot.\n"); \
+  } \
+}
+
+#define log_msg(v, fmt, args...) if(((v)&gulm_cm.verbosity)==(v)||(v)==lgm_Always) {\
+   printk(PROTO_NAME ": " fmt, ## args); \
+}
+#define log_err(fmt, args...) {\
+   printk(KERN_ERR PROTO_NAME ": ERROR " fmt, ## args); \
+}
+
+#define log_nop(fmt, args...)
+#define TICK printk("TICK==>" PROTO_NAME ": [%s:%d] pid:%d\n" , __FILE__ , __LINE__ , current->pid )
+
+#endif /*__gulm_prints_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_procinfo.c linux-patched/fs/gfs_locking/lock_gulm/gulm_procinfo.c
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_procinfo.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_procinfo.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,165 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+#include "util.h"
+
+extern gulm_cm_t gulm_cm;
+
+struct proc_dir_entry *gulm_proc_dir;
+struct proc_dir_entry *gulm_fs_proc_dir;
+
+/* the read operating function. */
+int
+gulm_fs_proc_read (char *buf, char **start, off_t off, int count, int *eof,
+		   void *data)
+{
+	gulm_fs_t *fs = (gulm_fs_t *) data;
+	count = 0;		/* ignore how much it wants */
+
+	count += sprintf (buf + count, "Filesystem: %s\nJID: %d\n"
+			  "handler_queue_cur: %d\n"
+			  "handler_queue_max: %d\n",
+			  fs->fs_name, fs->fsJID,
+			  fs->cq.task_count, fs->cq.task_max);
+
+	*eof = TRUE;
+	if (off >= count)
+		return 0;
+	*start = buf + off;
+	return (count - off);
+}
+
+/* read the stuff for all */
+int
+gulm_core_proc_read (char *buf, char **start, off_t off, int count,
+		     int *eof, void *data)
+{
+	count = 0;		/* ignore how much it wants */
+
+	count = sprintf (buf,
+			 "cluster id: %s\n"
+			 "my name: %s\n", gulm_cm.clusterID, gulm_cm.myName);
+
+	*eof = TRUE;
+	if (off >= count)
+		return 0;
+	*start = buf + off;
+	return (count - off);
+}
+
+int
+gulm_lt_proc_read (char *buf, char **start, off_t off, int count,
+		   int *eof, void *data)
+{
+	lock_table_t *lt = (lock_table_t *) data;
+	count = 0;		/* ignore how much it wants */
+
+	count += sprintf (buf + count, "\n"
+			  "lock counts:\n"
+			  "  total: %d\n"
+			  "    unl: %d\n"
+			  "    exl: %d\n"
+			  "    shd: %d\n"
+			  "    dfr: %d\n"
+			  "pending: %d\n"
+			  "   lvbs: %d\n"
+			  "   lops: %d\n\n",
+			  lt->locks_total,
+			  lt->locks_unl,
+			  lt->locks_exl,
+			  lt->locks_shd,
+			  lt->locks_dfr,
+			  atomic_read (&lt->locks_pending),
+			  lt->locks_lvbs, lt->lops);
+
+	*eof = TRUE;
+	if (off >= count)
+		return 0;
+	*start = buf + off;
+	return (count - off);
+}
+
+/* add entry to our proc folder
+ * call this on mount.
+ * */
+int
+add_to_proc (gulm_fs_t * fs)
+{
+	if (!(create_proc_read_entry (fs->fs_name, S_IFREG | S_IRUGO,
+				      gulm_fs_proc_dir, gulm_fs_proc_read,
+				      (void *) fs))) {
+		log_err ("couldn't register proc entry for %s\n", fs->fs_name);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+/* get rid of it
+ * this on umount.
+ * */
+void
+remove_from_proc (gulm_fs_t * fs)
+{
+	remove_proc_entry (fs->fs_name, gulm_fs_proc_dir);
+}
+
+ /* create our own root dir.
+  * initmodule
+  * */
+int
+init_proc_dir (void)
+{
+	if ((gulm_proc_dir = proc_mkdir ("gulm", &proc_root)) == NULL) {
+		log_err ("cannot create the gulm directory in /proc\n");
+		return -EINVAL;
+	}
+	if (!(create_proc_read_entry ("core", S_IFREG | S_IRUGO, gulm_proc_dir,
+				      gulm_core_proc_read, NULL))) {
+		log_err ("couldn't register proc entry for core\n");
+		remove_proc_entry ("gulm", &proc_root);
+		return -EINVAL;
+	}
+	if ((gulm_fs_proc_dir =
+	     proc_mkdir ("filesystems", gulm_proc_dir)) == NULL) {
+		log_err
+		    ("cannot create the filesystems directory in /proc/gulm\n");
+		remove_proc_entry ("core", gulm_proc_dir);
+		remove_proc_entry ("gulm", &proc_root);
+		return -EINVAL;
+	}
+	if (!(create_proc_read_entry ("lockspace", S_IFREG | S_IRUGO,
+				      gulm_proc_dir, gulm_lt_proc_read,
+				      (void *) &gulm_cm.ltpx))) {
+		remove_proc_entry ("filesystems", gulm_proc_dir);
+		remove_proc_entry ("core", gulm_proc_dir);
+		remove_proc_entry ("gulm", &proc_root);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+/* destroy it
+ * close module
+ * */
+void
+remove_proc_dir (void)
+{
+	remove_proc_entry ("lockspace", gulm_proc_dir);
+	remove_proc_entry ("filesystems", gulm_proc_dir);
+	remove_proc_entry ("core", gulm_proc_dir);
+	remove_proc_entry ("gulm", &proc_root);
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/gulm_procinfo.h linux-patched/fs/gfs_locking/lock_gulm/gulm_procinfo.h
--- linux-orig/fs/gfs_locking/lock_gulm/gulm_procinfo.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/gulm_procinfo.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,22 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __procinfo_h__
+#define __procinfo_h__
+int add_to_proc (gulm_fs_t * fs);
+void remove_from_proc (gulm_fs_t * fs);
+void remove_locktables_from_proc (void);
+void add_locktables_to_proc (void);
+int init_proc_dir (void);
+void remove_proc_dir (void);
+#endif /*__procinfo_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/handler.c linux-patched/fs/gfs_locking/lock_gulm/handler.c
--- linux-orig/fs/gfs_locking/lock_gulm/handler.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/handler.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,343 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/smp_lock.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include "handler.h"
+
+/* things about myself
+ * mostly just for verbosity here.
+ * */
+extern gulm_cm_t gulm_cm;
+
+/* the task struct */
+typedef struct runtask_s {
+	struct list_head rt_list;
+
+	gulm_fn fn;
+	lm_callback_t cb;
+	lm_fsdata_t *fsdata;
+	int type;
+	uint64_t lmnum;
+	unsigned int lmtype;
+	int result;
+
+} runtask_t;
+/* ooo crufty. */
+#define LM_CB_GULM_FN 169
+#if LM_CB_GULM_FN == LM_CB_NEED_E || \
+    LM_CB_GULM_FN == LM_CB_NEED_D || \
+    LM_CB_GULM_FN == LM_CB_NEED_S || \
+    LM_CB_GULM_FN == LM_CB_NEED_RECOVERY || \
+    LM_CB_GULM_FN == LM_CB_DROPLOCKS || \
+    LM_CB_GULM_FN == LM_CB_ASYNC
+#error "LM_CB_GULM_FN collision with other LM_CB_*"
+#endif
+
+static __inline__ int
+queue_empty (callback_qu_t * cq)
+{
+	int ret;
+	spin_lock (&cq->list_lock);
+	ret = list_empty (&cq->run_tasks);
+	spin_unlock (&cq->list_lock);
+	return ret;
+}
+
+/**
+ * handler - 
+ * @d: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+handler (void *d)
+{
+	callback_qu_t *cq = (callback_qu_t *) d;
+	runtask_t *rt;
+	struct list_head *tmp;
+	struct lm_lockname lockname;
+	struct lm_async_cb acb;
+
+	daemonize ("gulm_Cb_Handler");
+	atomic_inc (&cq->num_threads);
+	complete (&cq->startup);
+
+	while (cq->running) {
+		do {
+			DECLARE_WAITQUEUE (__wait_chan, current);
+			current->state = TASK_INTERRUPTIBLE;
+			add_wait_queue (&cq->waiter, &__wait_chan);
+			if (queue_empty (cq))
+				schedule ();
+			remove_wait_queue (&cq->waiter, &__wait_chan);
+			current->state = TASK_RUNNING;
+		} while (0);
+
+		if (!cq->running)
+			break;
+		/* remove item from list */
+		spin_lock (&cq->list_lock);
+		if (list_empty (&cq->run_tasks)) {
+			spin_unlock (&cq->list_lock);
+			continue;	/* nothing here. move on */
+		}
+		/* take items off the end of the list, since we add them to the
+		 * beginning.
+		 */
+		tmp = (&cq->run_tasks)->prev;
+		list_del (tmp);
+		cq->task_count--;
+		spin_unlock (&cq->list_lock);
+
+		rt = list_entry (tmp, runtask_t, rt_list);
+
+		if (rt->type == LM_CB_ASYNC) {
+			acb.lc_name.ln_number = rt->lmnum;
+			acb.lc_name.ln_type = rt->lmtype;
+			acb.lc_ret = rt->result;
+			rt->cb (rt->fsdata, rt->type, &acb);
+		} else if (rt->type == LM_CB_GULM_FN) {
+			rt->fn (rt->fsdata);
+		} else {
+			lockname.ln_number = rt->lmnum;
+			lockname.ln_type = rt->lmtype;
+			rt->cb (rt->fsdata, rt->type, &lockname);
+		}
+
+		kfree (rt);
+
+	}			/*while(running) */
+
+	atomic_dec (&cq->num_threads);
+	complete (&cq->startup);
+	return 0;
+}
+
+/**
+ * display_handler_queue - 
+ * @cq: 
+ * 
+ * remember, items are added to the head, and removed from the tail.
+ * So the last item listed, is the next item to be handled.
+ * 
+ */
+void
+display_handler_queue (callback_qu_t * cq)
+{
+	struct list_head *lltmp;
+	runtask_t *rt;
+	int i = 0;
+	log_msg (lgm_Always, "Dumping Handler queue with %d items, max %d\n",
+		 cq->task_count, cq->task_max);
+	spin_lock (&cq->list_lock);
+	list_for_each (lltmp, &cq->run_tasks) {
+		rt = list_entry (lltmp, runtask_t, rt_list);
+		if (rt->type == LM_CB_ASYNC) {
+			log_msg (lgm_Always,
+				 "%4d ASYNC    (%" PRIu64 ", %u) result:%#x\n",
+				 i, rt->lmnum, rt->lmtype, rt->result);
+		} else if (rt->type == LM_CB_GULM_FN) {
+			log_msg (lgm_Always, "%4d GULM FN  func:%p data:%p\n",
+				 i, rt->fn, rt->fsdata);
+		} else {	/* callback. */
+			log_msg (lgm_Always,
+				 "%4d CALLBACK req:%u (%" PRIu64 ", %u)\n", i,
+				 rt->type, rt->lmnum, rt->lmtype);
+		}
+		i++;
+	}
+	spin_unlock (&cq->list_lock);
+}
+
+/**
+ * alloc_runtask - 
+ * Returns: runtask_t
+ */
+runtask_t *
+alloc_runtask (void)
+{
+	runtask_t *rt;
+	rt = kmalloc (sizeof (runtask_t), GFP_KERNEL);
+	return rt;
+}
+
+/**
+ * qu_function_call - 
+ * @cq: 
+ * @fn: 
+ * @data: 
+ * 
+ * Generic function execing on the handler thread.  Mostly so I can add
+ * single things quick without having to build all the details into the
+ * handler queues.
+ * 
+ * Returns: int
+ */
+int
+qu_function_call (callback_qu_t * cq, gulm_fn fn, void *data)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = NULL;
+	rt->fn = fn;
+	rt->fsdata = data;
+	rt->type = LM_CB_GULM_FN;
+	rt->lmtype = 0;
+	rt->lmnum = 0;
+	rt->result = 0;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * qu_async_rpl - 
+ * @cq: 
+ * @cb: 
+ * @fsdata: 
+ * @lockname: 
+ * @result: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+qu_async_rpl (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+	      struct lm_lockname *lockname, int result)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = cb;
+	rt->fsdata = fsdata;
+	rt->type = LM_CB_ASYNC;
+	rt->lmtype = lockname->ln_type;
+	rt->lmnum = lockname->ln_number;
+	rt->result = result;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * qu_drop_req - 
+ * 
+ * Returns: <0:Error; =0:Ok
+ */
+int
+qu_drop_req (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+	     int type, uint8_t lmtype, uint64_t lmnum)
+{
+	runtask_t *rt;
+	rt = alloc_runtask ();
+	if (rt == NULL)
+		return -ENOMEM;
+	rt->cb = cb;
+	rt->fsdata = fsdata;
+	rt->type = type;
+	rt->lmtype = lmtype;
+	rt->lmnum = lmnum;
+	rt->result = 0;
+	INIT_LIST_HEAD (&rt->rt_list);
+	spin_lock (&cq->list_lock);
+	list_add (&rt->rt_list, &cq->run_tasks);
+	cq->task_count++;
+	if (cq->task_count > cq->task_max)
+		cq->task_max = cq->task_count;
+	spin_unlock (&cq->list_lock);
+	wake_up (&cq->waiter);
+	return 0;
+}
+
+/**
+ * stop_callback_qu - stop the handler thread
+ */
+void
+stop_callback_qu (callback_qu_t * cq)
+{
+	struct list_head *lltmp, *tmp;
+	runtask_t *rt;
+
+	if (cq->running) {
+		cq->running = FALSE;
+		/* make sure all thread stop.
+		 * */
+		while (atomic_read (&cq->num_threads) > 0) {
+			wake_up (&cq->waiter);
+			wait_for_completion (&cq->startup);
+		}
+		/* clear out any left overs. */
+		list_for_each_safe (tmp, lltmp, &cq->run_tasks) {
+			rt = list_entry (tmp, runtask_t, rt_list);
+			list_del (tmp);
+			kfree (rt);
+		}
+	}
+}
+
+/**
+ * start_callback_qu - 
+ *
+ * Returns: <0:Error, >=0:Ok
+ */
+int
+start_callback_qu (callback_qu_t * cq, int cnt)
+{
+	int err;
+	INIT_LIST_HEAD (&cq->run_tasks);
+	spin_lock_init (&cq->list_lock);
+	init_completion (&cq->startup);
+	init_waitqueue_head (&cq->waiter);
+	atomic_set (&cq->num_threads, 0);
+	cq->running = TRUE;
+	cq->task_count = 0;
+	cq->task_max = 0;
+	if (cnt <= 0)
+		cnt = 2;
+	for (; cnt > 0; cnt--) {
+		err = kernel_thread (handler, cq, 0);	/* XXX linux part */
+		if (err < 0) {
+			stop_callback_qu (cq);
+			/* calling stop here might not behave correctly in all error
+			 * cases.
+			 */
+			return err;
+		}
+		wait_for_completion (&cq->startup);
+	}
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/handler.h linux-patched/fs/gfs_locking/lock_gulm/handler.h
--- linux-orig/fs/gfs_locking/lock_gulm/handler.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/handler.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,42 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __handler_c__
+#define __handler_c__
+#include <linux/lm_interface.h>
+
+struct callback_qu_s {
+	struct completion startup;
+	int running;
+	int task_count;
+	int task_max;
+	struct list_head run_tasks;
+	spinlock_t list_lock;
+	wait_queue_head_t waiter;
+	atomic_t num_threads;
+};
+typedef struct callback_qu_s callback_qu_t;
+
+/* kinda an excess overloading */
+typedef void (*gulm_fn) (void *);
+int qu_function_call (callback_qu_t * cq, gulm_fn fn, void *data);
+
+int qu_async_rpl (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+		  struct lm_lockname *lockname, int result);
+int qu_drop_req (callback_qu_t * cq, lm_callback_t cb, lm_fsdata_t * fsdata,
+		 int type, uint8_t lmtype, uint64_t lmnum);
+int start_callback_qu (callback_qu_t * cq, int cnt);
+void stop_callback_qu (callback_qu_t * cq);
+void display_handler_queue (callback_qu_t * cq);
+
+#endif /*__handler_c__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_core.c linux-patched/fs/gfs_locking/lock_gulm/lg_core.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_core.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_core.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,669 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* All of the core related functions for services are here. */
+
+#include "lg_priv.h"
+
+/**
+ * lg_core_selector - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+xdr_socket
+lg_core_selector (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL || lg->first_magic != LGMAGIC
+	    || lg->last_magic != LGMAGIC)
+#ifdef __KERNEL__
+		return NULL;
+#else
+		return -EINVAL;
+#endif
+
+	return lg->core_fd;
+}
+
+/**
+ * lg_core_handle_messages - 
+ * @ulm_interface_p: 
+ * @lg_core_callbacks_t: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_handle_messages (gulm_interface_p lgp, lg_core_callbacks_t * ccbp,
+			 void *misc)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_dec_t *dec;
+	int err = 0;
+	uint64_t x_gen;
+	uint32_t x_code, x_error, x_rank;
+	struct in6_addr x_ip;
+	uint8_t x_state, x_mode;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EBADR;
+
+	down (&lg->core_recver);
+	if (lg->in_core_hm)
+		return -EDEADLK;
+	lg->in_core_hm = TRUE;
+	up (&lg->core_recver);
+
+	dec = lg->core_dec;
+
+	err = xdr_dec_uint32 (dec, &x_code);
+	if (err != 0)
+		goto exit;
+
+	if (gulm_core_login_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_uint64 (dec, &x_gen)) < 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) < 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_rank)) < 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) < 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (ccbp->login_reply == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->login_reply (misc, x_gen, x_error, x_rank, x_state);
+		goto exit;
+	} else if (gulm_core_logout_rpl == x_code) {
+		if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+			goto exit;
+		if (ccbp->logout_reply != NULL) {
+			err = ccbp->logout_reply (misc);
+		}
+
+		xdr_close (&lg->core_fd);
+		xdr_enc_release (lg->core_enc);
+		lg->core_enc = NULL;
+		xdr_dec_release (lg->core_dec);
+		lg->core_dec = NULL;
+
+		goto exit;
+	} else if (gulm_core_mbr_lstrpl == x_code) {
+		if (ccbp->nodelist != NULL) {
+			err = ccbp->nodelist (misc, lglcb_start, NULL, 0, 0);
+			if (err != 0)
+				goto exit;
+		}
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_mode)) != 0)
+					break;
+				if ((err = xdr_dec_uint8 (dec, &x_mode)) != 0)
+					break;
+				if ((err = xdr_dec_uint32 (dec, &x_rank)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+				if ((err = xdr_dec_uint64 (dec, &x_gen)) != 0)
+					break;
+
+				if (ccbp->nodelist != NULL) {
+					err =
+					    ccbp->nodelist (misc, lglcb_item,
+							    lg->cfba, &x_ip,
+							    x_state);
+					if (err != 0)
+						goto exit;
+				}
+
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->nodelist == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->nodelist (misc, lglcb_stop, NULL, 0, 0);
+		goto exit;
+	} else if (gulm_core_state_chgs == x_code) {
+		do {
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if (x_state == gio_Mbr_ama_Slave) {
+				if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->statechange == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->statechange (misc, x_state, &x_ip, lg->cfba);
+		goto exit;
+	} else if (gulm_core_mbr_updt == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_string_ag (dec, &lg->cfba,
+						&lg->cfba_len)) != 0)
+				break;
+			if ((err = xdr_dec_ipv6 (dec, &x_ip)) != 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->nodechange == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->nodechange (misc, lg->cfba, &x_ip, x_state);
+		goto exit;
+	} else if (gulm_core_res_list == x_code) {
+		if (ccbp->service_list != NULL) {
+			if ((err =
+			     ccbp->service_list (misc, lglcb_start, NULL)) != 0)
+				goto exit;
+		}
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec)) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if (ccbp->service_list != NULL) {
+					if ((err =
+					     ccbp->service_list (misc,
+								 lglcb_item,
+								 lg->cfba)) !=
+					    0) {
+						goto exit;
+					}
+				}
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (ccbp->service_list == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->service_list (misc, lglcb_stop, NULL);
+		goto exit;
+	} else if (gulm_info_stats_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfba,
+							&lg->cfba_len)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->cfbb,
+							&lg->cfbb_len)) != 0)
+					break;
+			}
+		} while (0);
+		goto exit;
+	} else if (gulm_err_reply == x_code) {
+		if ((err = xdr_dec_uint32 (dec, &x_code)) != 0)
+			goto exit;
+		if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+			goto exit;
+		if (ccbp->error == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = ccbp->error (misc, x_error);
+		goto exit;
+	} else {
+		/* unknown code. what to do? */
+		err = -EPROTO;
+		goto exit;
+	}
+
+      exit:
+	lg->in_core_hm = FALSE;
+	return err;
+}
+
+/**
+ * lg_core_login - 
+ * @lgp: 
+ * @important: 
+ *
+ * On any error, things are closed and released to the state of things
+ * before you called login.
+ * 
+ * Returns: int
+ */
+int
+lg_core_login (gulm_interface_p lgp, int important)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct sockaddr_in6 adr;
+	int err;
+	xdr_socket cfd;
+	xdr_enc_t *enc;
+	xdr_dec_t *dec;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	adr.sin6_family = AF_INET6;
+	adr.sin6_addr = in6addr_loopback;
+	adr.sin6_port = htons (lg->core_port);
+
+	if ((err = xdr_open (&cfd)) < 0) {
+		return err;
+	}
+
+	if ((err = xdr_connect (&adr, cfd)) < 0) {
+		xdr_close (&cfd);
+		return err;
+	}
+
+	enc = xdr_enc_init (cfd, 128);
+	if (enc == NULL) {
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	dec = xdr_dec_init (cfd, 128);
+	if (enc == NULL) {
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_reslgn_req)) < 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, GIO_WIREPROT_VERS)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->clusterID)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) < 0)
+			break;
+		if ((err =
+		     xdr_enc_uint32 (enc,
+				     important ? gulm_svc_opt_important : 0)) !=
+		    0)
+			break;
+		if ((err = xdr_enc_flush (enc)) < 0)
+			break;
+	} while (0);
+	if (err != 0) {
+		xdr_dec_release (dec);
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return err;
+	}
+
+	down (&lg->core_sender);
+	lg->core_fd = cfd;
+	lg->core_enc = enc;
+	lg->core_dec = dec;
+	up (&lg->core_sender);
+
+	return 0;
+}
+
+/**
+ * lg_core_logout - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_logout (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_logout_req)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_Mbr_ama_Resource)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_nodeinfo - 
+ * @lgp: 
+ * @nodename: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_nodeinfo (gulm_interface_p lgp, char *nodename)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	if (nodename == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_req)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, nodename)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_nodelist - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_nodelist (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_lstreq)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_servicelist - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_servicelist (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_res_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_corestate - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_corestate (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_state_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_shutdown - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_shutdown (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_shutdown)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_forceexpire - 
+ * @lgp: 
+ * @node_name: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_forceexpire (gulm_interface_p lgp, char *nodename)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	if (nodename == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_mbr_force)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, nodename)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/**
+ * lg_core_forcepending - 
+ * @lgp: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_core_forcepending (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_fd < 0 || lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->core_enc;
+
+	down (&lg->core_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_core_forcepend)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->core_sender);
+	return err;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_lock.c linux-patched/fs/gfs_locking/lock_gulm/lg_lock.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_lock.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_lock.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,638 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* all of the lock related fucntion are here. */
+#include "lg_priv.h"
+
+/**
+ * lg_lock_selector - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+xdr_socket
+lg_lock_selector (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL || lg->first_magic != LGMAGIC
+	    || lg->last_magic != LGMAGIC)
+#ifdef __KERNEL__
+		return NULL;
+#else
+		return -EINVAL;
+#endif
+
+	return lg->lock_fd;
+}
+
+/**
+ * lg_lock_handle_messages - 
+ * @ulm_interface_p: 
+ * @lg_lockspace_callbacks_t: 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_handle_messages (gulm_interface_p lgp, lg_lockspace_callbacks_t * cbp,
+			 void *misc)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_dec_t *dec;
+	int err = 0;
+	uint64_t x_subid, x_start, x_stop;
+	uint32_t x_code, x_error, x_flags;
+	uint16_t x_keylen, x_lvblen = 0;
+	uint8_t x_state;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->core_enc == NULL || lg->core_dec == NULL)
+		return -EBADR;
+
+	down (&lg->lock_recver);
+	if (lg->in_lock_hm)
+		return -EDEADLK;
+	lg->in_lock_hm = TRUE;
+	up (&lg->lock_recver);
+
+	dec = lg->lock_dec;
+
+	err = xdr_dec_uint32 (dec, &x_code);
+	if (err != 0)
+		goto exit;
+
+	if (gulm_lock_login_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (cbp->login_reply == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->login_reply (misc, x_error, x_state);
+		goto exit;
+	} else if (gulm_lock_logout_rpl == x_code) {
+		if (cbp->logout_reply != NULL) {
+			err = cbp->logout_reply (misc);
+		}
+
+		xdr_close (&lg->lock_fd);
+		xdr_enc_release (lg->lock_enc);
+		lg->lock_enc = NULL;
+		xdr_dec_release (lg->lock_dec);
+		lg->lock_dec = NULL;
+
+		goto exit;
+	} else if (gulm_lock_state_rpl == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_start)) != 0 )
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_stop)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_flags)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+			if (x_flags & gio_lck_fg_hasLVB) {
+				if ((err =
+				     xdr_dec_raw_ag (dec, (void **) &lg->lfbb,
+						     &lg->lfbb_len,
+						     &x_lvblen)) != 0)
+					break;
+			}
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (x_keylen <= 4) {
+			err = -EPROTO;	/* or something */
+			goto exit;
+		}
+		if (cbp->lock_state == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->lock_state (misc, &lg->lfba[4], x_keylen - 4,
+				       x_subid, x_start, x_stop,
+				       x_state, x_flags, x_error,
+				       lg->lfbb, x_lvblen);
+		goto exit;
+	} else if (gulm_lock_action_rpl == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (x_keylen <= 4) {
+			err = -EPROTO;	/* or something */
+			goto exit;
+		}
+		if (cbp->lock_action == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err =
+		    cbp->lock_action (misc, &lg->lfba[4], x_keylen - 4,
+				      x_subid, x_state, x_error);
+		goto exit;
+	} else if (gulm_lock_cb_state == x_code) {
+		do {
+			if ((err =
+			     xdr_dec_raw_ag (dec, (void **) &lg->lfba,
+					     &lg->lfba_len, &x_keylen)) != 0)
+				break;
+         		if ((err = xdr_dec_uint64(dec, &x_subid)) != 0 )
+				break;
+			if ((err = xdr_dec_uint8 (dec, &x_state)) != 0)
+				break;
+		} while (0);
+		if (err != 0) {
+			goto exit;
+		}
+		if (cbp->drop_lock_req == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err =
+		    cbp->drop_lock_req (misc, &lg->lfba[4], x_keylen - 4,
+					x_subid, x_state);
+		goto exit;
+	} else if (gulm_lock_cb_dropall == x_code) {
+		if (cbp->drop_all == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->drop_all (misc);
+		goto exit;
+	} else if (gulm_info_stats_rpl == x_code) {
+		do {
+			if ((err = xdr_dec_list_start (dec)) != 0)
+				break;
+			while (xdr_dec_list_stop (dec) != 0) {
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->lfba,
+							&lg->lfba_len)) != 0)
+					break;
+				if ((err =
+				     xdr_dec_string_ag (dec, &lg->lfbb,
+							&lg->lfbb_len)) != 0)
+					break;
+			}
+		} while (0);
+		goto exit;
+	} else if (gulm_err_reply == x_code) {
+		do {
+			if ((err = xdr_dec_uint32 (dec, &x_code)) != 0)
+				break;
+			if ((err = xdr_dec_uint32 (dec, &x_error)) != 0)
+				break;
+		} while (0);
+		if (err != 0)
+			goto exit;
+		if (cbp->error == NULL) {
+			err = 0;
+			goto exit;
+		}
+		err = cbp->error (misc, x_error);
+		goto exit;
+	} else {
+		err = -EPROTO;
+		goto exit;
+	}
+
+      exit:
+	lg->in_lock_hm = FALSE;
+	return err;
+}
+
+/**
+ * lg_lock_login - 
+ * @ulm_interface_p: 
+ * @4: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_login (gulm_interface_p lgp, uint8_t lockspace[4])
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct sockaddr_in6 adr;
+	int err;
+	xdr_socket cfd;
+	xdr_enc_t *enc;
+	xdr_dec_t *dec;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	adr.sin6_family = AF_INET6;
+	adr.sin6_addr = in6addr_loopback;
+	adr.sin6_port = htons (lg->lock_port);
+
+	if ((err = xdr_open (&cfd)) < 0) {
+		return err;
+	}
+
+	if ((err = xdr_connect (&adr, cfd)) < 0) {
+		xdr_close (&cfd);
+		return err;
+	}
+
+	enc = xdr_enc_init (cfd, 512);
+	if (enc == NULL) {
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	dec = xdr_dec_init (cfd, 512);
+	if (enc == NULL) {
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return -ENOMEM;
+	}
+
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_login_req)) < 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, GIO_WIREPROT_VERS)) < 0)
+			break;
+		if ((err = xdr_enc_string (enc, lg->service_name)) < 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_lck_st_Client)) < 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) < 0)
+			break;
+
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_sel_lckspc)) < 0)
+			break;
+		if ((err = xdr_enc_raw (enc, lockspace, 4)) < 0)
+			break;
+		/* don't flush here.
+		 * dumb programmer stunt.  This way, the lockspace selection won't
+		 * happen until the next thing the user of this lib sends.  Which
+		 * means it will be after we have received the login reply.
+		 *
+		 * Is there really a good reason not to flush here?
+		 */
+	} while (0);
+	if (err != 0) {
+		xdr_dec_release (dec);
+		xdr_enc_release (enc);
+		xdr_close (&cfd);
+		return err;
+	}
+
+	down (&lg->lock_sender);
+	lg->lock_fd = cfd;
+	lg->lock_enc = enc;
+	lg->lock_dec = dec;
+
+	memcpy (lg->lockspace, lockspace, 4);
+	up (&lg->lock_sender);
+
+	return 0;
+}
+
+/**
+ * lg_lock_logout - 
+ * @ulm_interface_p: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_logout (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_logout_req)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_state_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * @state: 
+ * @flags: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_state_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		   uint64_t subid, uint64_t start, uint64_t stop,
+		   uint8_t state, uint32_t flags, uint8_t * LVB,
+		   uint16_t LVBlen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	uint32_t iflgs = 0;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	if (state != lg_lock_state_Unlock &&
+	    state != lg_lock_state_Exclusive &&
+	    state != lg_lock_state_Deferred && state != lg_lock_state_Shared)
+		return -EINVAL;
+
+	/* make sure only the accepted flags get passed through. */
+	if ((flags & lg_lock_flag_DoCB) == lg_lock_flag_DoCB)
+		iflgs |= lg_lock_flag_DoCB;
+	if ((flags & lg_lock_flag_Try) == lg_lock_flag_Try)
+		iflgs |= lg_lock_flag_Try;
+	if ((flags & lg_lock_flag_Any) == lg_lock_flag_Any)
+		iflgs |= lg_lock_flag_Any;
+	if ((flags & lg_lock_flag_IgnoreExp) == lg_lock_flag_IgnoreExp)
+		iflgs |= lg_lock_flag_IgnoreExp;
+	if ((flags & lg_lock_flag_Piority) == lg_lock_flag_Piority)
+		iflgs |= lg_lock_flag_Piority;
+
+	enc = lg->lock_enc;
+
+	if (LVB != NULL && LVBlen > 0)
+		iflgs |= gio_lck_fg_hasLVB;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_state_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, start)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, stop)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, state)) != 0)
+			break;
+		if ((err = xdr_enc_uint32 (enc, iflgs)) != 0)
+			break;
+		if (iflgs & gio_lck_fg_hasLVB)
+			if ((err = xdr_enc_raw (enc, LVB, LVBlen)) != 0)
+				break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_cancel_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_lock_cancel_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		uint64_t subid)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_action_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, gio_lck_st_Cancel)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_action_req - 
+ * @lgp: 
+ * @key: 
+ * @keylen: 
+ * @action: 
+ * @LVB: 
+ * @LVBlen: 
+ * 
+ * XXX
+ * I wonder if I should actually break this into three seperate calls for
+ * the lvb stuff.  Does it really matter?
+ * 
+ * Returns: int
+ */
+int
+lg_lock_action_req (gulm_interface_p lgp, uint8_t * key, uint16_t keylen,
+		    uint64_t subid, uint8_t action, uint8_t * LVB,
+		    uint16_t LVBlen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	if (action != lg_lock_act_HoldLVB &&
+	    action != lg_lock_act_UnHoldLVB && action != lg_lock_act_SyncLVB)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = keylen;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_action_req)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_uint64 (enc, subid)) != 0)
+			break;
+		if ((err = xdr_enc_uint8 (enc, action)) != 0)
+			break;
+		if (action == gio_lck_st_SyncLVB)
+			if ((err = xdr_enc_raw (enc, LVB, LVBlen)) != 0)
+				break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/**
+ * lg_lock_drop_exp - 
+ * @ulm_interface_p: 
+ * @holder: 
+ * @keymask: 
+ * @kmlen: 
+ * 
+ * holder is the node name of the expired holder that you want to clear.
+ * Only locks matching the keymask will be looked at. (most of the time you
+ * will just set key to a bunch of 0xff to match all) The keymask lets you
+ * basically subdivide your lockspace into smaller seperate parts.
+ * (example, there is one gfs lockspace, but each filesystem gets its own
+ * subpart of that larger space)
+ *
+ * If holder is NULL, all expired holders in your lockspace will get
+ * dropped.
+ * 
+ * Returns: int
+ */
+int
+lg_lock_drop_exp (gulm_interface_p lgp, uint8_t * holder, uint8_t * key,
+		  uint16_t keylen)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	struct iovec iov[2];
+	xdr_enc_t *enc;
+	int err;
+
+	/* make sure it is a gulm_interface_p. */
+	if (lg == NULL)
+		return -EINVAL;
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	if (lg->lock_fd < 0 || lg->lock_enc == NULL || lg->lock_dec == NULL)
+		return -EINVAL;
+
+	enc = lg->lock_enc;
+
+	iov[0].iov_base = lg->lockspace;
+	iov[0].iov_len = 4;
+	iov[1].iov_base = key;
+	iov[1].iov_len = (key != NULL) ? keylen : 0;
+
+	down (&lg->lock_sender);
+	do {
+		if ((err = xdr_enc_uint32 (enc, gulm_lock_drop_exp)) != 0)
+			break;
+		if ((err = xdr_enc_string (enc, holder)) != 0)
+			break;
+		if ((err = xdr_enc_raw_iov (enc, 2, iov)) != 0)
+			break;
+		if ((err = xdr_enc_flush (enc)) != 0)
+			break;
+	} while (0);
+	up (&lg->lock_sender);
+	return err;
+}
+
+/* vim: set ai cin noet sw=8 ts=8 : */
+
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_main.c linux-patched/fs/gfs_locking/lock_gulm/lg_main.c
--- linux-orig/fs/gfs_locking/lock_gulm/lg_main.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_main.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,209 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/* This is where all of the library specific functions exist.
+ * Not many, but keeps things clean.
+ */
+
+#include "lg_priv.h"
+#include "gulm.h"
+extern gulm_cm_t gulm_cm;
+
+/**
+ * lg_initialize - 
+ * @gulm_interface_p:
+ * @cluster_name:
+ * @service_name: 
+ * 
+ * if returning an error, nothing was done to the value of gulm_interface_p
+ * 
+ * Returns: gulm_interface_p
+ */
+int
+lg_initialize (gulm_interface_p * ret, char *cluster_name, char *service_name)
+{
+	gulm_interface_t *lg;
+	int err, len;
+
+	lg = kmalloc (sizeof (gulm_interface_t), GFP_KERNEL);
+	if (lg == NULL)
+		return -ENOMEM;
+
+	memset (lg, 0, sizeof (gulm_interface_t));
+	lg->first_magic = LGMAGIC;
+	lg->last_magic = LGMAGIC;
+
+	if (cluster_name == NULL)
+		cluster_name = "cluster";
+	len = strlen (cluster_name) + 1;
+	lg->clusterID = kmalloc (len, GFP_KERNEL);
+	if (lg->clusterID == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+	memcpy (lg->clusterID, cluster_name, len);
+
+	len = strlen (service_name) + 1;
+	lg->service_name = kmalloc (len, GFP_KERNEL);
+	if (lg->service_name == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+	memcpy (lg->service_name, service_name, len);
+
+	/* set up flutter bufs. */
+	lg->cfba_len = 64;
+	lg->cfba = kmalloc (lg->cfba_len, GFP_KERNEL);
+	if (lg->cfba == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->cfbb_len = 64;
+	lg->cfbb = kmalloc (lg->cfbb_len, GFP_KERNEL);
+	if (lg->cfbb == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->lfba_len = 128;
+	lg->lfba = kmalloc (lg->lfba_len, GFP_KERNEL);
+	if (lg->lfba == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	lg->lfbb_len = 128;
+	lg->lfbb = kmalloc (lg->lfbb_len, GFP_KERNEL);
+	if (lg->lfbb == NULL) {
+		err = -ENOMEM;
+		goto fail_nomem;
+	}
+
+	/* setup mutexes */
+	init_MUTEX (&lg->core_sender);
+	init_MUTEX (&lg->core_recver);
+	init_MUTEX (&lg->lock_sender);
+	init_MUTEX (&lg->lock_recver);
+
+	lg->core_port = 40040;
+	lg->lock_port = 40042;
+
+	*ret = lg;
+	return 0;
+      fail_nomem:
+	if (lg->clusterID != NULL)
+		kfree (lg->clusterID);
+	if (lg->service_name != NULL)
+		kfree (lg->service_name);
+	if (lg->cfba != NULL)
+		kfree (lg->cfba);
+	if (lg->cfbb != NULL)
+		kfree (lg->cfbb);
+	if (lg->lfba != NULL)
+		kfree (lg->lfba);
+	if (lg->lfbb != NULL)
+		kfree (lg->lfbb);
+	kfree (lg);
+	return err;
+}
+
+/**
+ * lg_release - 
+ * @lg: 
+ * 
+ */
+void
+lg_release (gulm_interface_p lgp)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return;
+
+	if (lg->service_name != NULL)
+		kfree (lg->service_name);
+	if (lg->clusterID != NULL)
+		kfree (lg->clusterID);
+
+	/* wonder if I should send a logout packet? */
+	if (lg->core_enc != NULL)
+		xdr_enc_release (lg->core_enc);
+	if (lg->core_dec != NULL)
+		xdr_dec_release (lg->core_dec);
+	xdr_close (&lg->core_fd);
+
+	if (lg->lock_enc != NULL)
+		xdr_enc_release (lg->lock_enc);
+	if (lg->lock_dec != NULL)
+		xdr_dec_release (lg->lock_dec);
+	xdr_close (&lg->lock_fd);
+
+	if (lg->cfba != NULL)
+		kfree (lg->cfba);
+	if (lg->cfbb != NULL)
+		kfree (lg->cfbb);
+	if (lg->lfba != NULL)
+		kfree (lg->lfba);
+	if (lg->lfbb != NULL)
+		kfree (lg->lfbb);
+
+	kfree (lg);
+}
+
+/**
+ * lg_set_core_port - 
+ * @lgp: 
+ * @new: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_set_core_port (gulm_interface_p lgp, uint16_t new)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return -EINVAL;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	lg->core_port = new;
+	return 0;
+}
+
+/**
+ * lg_set_ltpx_port - 
+ * @lgp: 
+ * @new: 
+ * 
+ * 
+ * Returns: int
+ */
+int
+lg_set_lock_port (gulm_interface_p lgp, uint16_t new)
+{
+	gulm_interface_t *lg = (gulm_interface_t *) lgp;
+	if (lgp == NULL)
+		return -EINVAL;
+	/* make sure it is a gulm_interface_p. */
+	if (lg->first_magic != LGMAGIC || lg->last_magic != LGMAGIC)
+		return -EINVAL;
+
+	lg->lock_port = new;
+
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lg_priv.h linux-patched/fs/gfs_locking/lock_gulm/lg_priv.h
--- linux-orig/fs/gfs_locking/lock_gulm/lg_priv.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lg_priv.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,86 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __lg_priv_h__
+#define __lg_priv_h__
+/* private details that we don't want to give the users of this lib access
+ * to go here.
+ */
+
+#ifdef __linux__
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+#endif /*__linux__*/
+
+#include "xdr.h"
+#include "gio_wiretypes.h"
+#include "libgulm.h"
+
+#define LGMAGIC (0x474d4354)
+
+struct gulm_interface_s {
+	/* since we've masked this to a void* to the users, it is a nice safty
+	 * net to put a little magic in here so we know things stay good.
+	 */
+	uint32_t first_magic;
+
+	/* WHAT IS YOUR NAME?!? */
+	char *service_name;
+
+	char *clusterID;
+
+	uint16_t core_port;
+	xdr_socket core_fd;
+	xdr_enc_t *core_enc;
+	xdr_dec_t *core_dec;
+	struct semaphore core_sender;
+	struct semaphore core_recver;
+	int in_core_hm;
+
+	uint16_t lock_port;
+	xdr_socket lock_fd;
+	xdr_enc_t *lock_enc;
+	xdr_dec_t *lock_dec;
+	struct semaphore lock_sender;
+	struct semaphore lock_recver;
+	int in_lock_hm;
+	uint8_t lockspace[4];
+
+	/* in the message recver func, we read data into these buffers and pass
+	 * them to the callback function.  This way we avoid doinf mallocs and
+	 * frees on every callback.
+	 */
+	uint16_t cfba_len;
+	uint8_t *cfba;
+	uint16_t cfbb_len;
+	uint8_t *cfbb;
+	uint16_t lfba_len;
+	uint8_t *lfba;
+	uint16_t lfbb_len;
+	uint8_t *lfbb;
+
+	uint32_t last_magic;
+};
+typedef struct gulm_interface_s gulm_interface_t;
+
+#ifndef TRUE
+#define TRUE (1)
+#endif
+
+#ifndef FALSE
+#define FALSE (0)
+#endif
+
+#endif /*__lg_priv_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/libgulm.h linux-patched/fs/gfs_locking/lock_gulm/libgulm.h
--- linux-orig/fs/gfs_locking/lock_gulm/libgulm.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/libgulm.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,189 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __libgulm_h__
+#define __libgulm_h__
+
+/* bit messy, but we need this to be rather seemless in both kernel and
+ * userspace. and this seems the easiest way to do it.
+ */
+
+#ifdef __linux__
+#include <linux/in6.h>
+typedef struct socket *lg_socket;
+#endif /*__linux__*/
+
+typedef void *gulm_interface_p;
+
+/* mallocs the interface structure.
+ */
+int lg_initialize (gulm_interface_p *, char *cluster_name, char *service_name);
+/* frees struct.
+ */
+void lg_release (gulm_interface_p);
+
+/* Determins where we are with a itemlist callback */
+typedef enum { lglcb_start, lglcb_item, lglcb_stop } lglcb_t;
+
+/****** Core specifics ******/
+
+/* leaving a callback pointer as NULL, will cause that message type to 
+ * be ignored. */
+typedef struct lg_core_callbacks_s {
+	int (*login_reply) (void *misc, uint64_t gen, uint32_t error,
+			    uint32_t rank, uint8_t corestate);
+	int (*logout_reply) (void *misc);
+	int (*nodelist) (void *misc, lglcb_t type, char *name,
+			 struct in6_addr * ip, uint8_t state);
+	int (*statechange) (void *misc, uint8_t corestate,
+			    struct in6_addr * masterip, char *mastername);
+	int (*nodechange) (void *misc, char *nodename,
+			   struct in6_addr * nodeip, uint8_t nodestate);
+	int (*service_list) (void *misc, lglcb_t type, char *service);
+	int (*error) (void *misc, uint32_t err);
+} lg_core_callbacks_t;
+
+/* this will trigger a callback from gulm_core_callbacks_t 
+ * handles one message! Either stick this inside of a thread,
+ * or in a poll()/select() loop using the function below.
+ * This will block until there is a message sent from core. 
+ */
+int lg_core_handle_messages (gulm_interface_p, lg_core_callbacks_t *,
+			     void *misc);
+
+/* this returns the filedescriptor that the library is using to 
+ * communicate with the core. This is only for using in a poll() 
+ * or select() call to avoid having the gulm_core_handle_messages()
+ * call block. 
+ */
+lg_socket lg_core_selector (gulm_interface_p);
+
+/* Queue requests. */
+int lg_core_login (gulm_interface_p, int important);
+int lg_core_logout (gulm_interface_p);
+int lg_core_nodeinfo (gulm_interface_p, char *nodename);
+int lg_core_nodelist (gulm_interface_p);
+int lg_core_servicelist (gulm_interface_p);
+int lg_core_corestate (gulm_interface_p);
+
+/* for completeness mostly. */
+int lg_core_shutdown (gulm_interface_p);
+int lg_core_forceexpire (gulm_interface_p, char *node_name);
+int lg_core_forcepending (gulm_interface_p);
+
+/* Node states
+ * First three are actual states, as well as changes.  Last is only a node
+ * change message.
+ * */
+#define lg_core_Logged_in  (0x05)
+#define lg_core_Logged_out (0x06)
+#define lg_core_Expired    (0x07)
+#define lg_core_Fenced     (0x08)
+/* Core states */
+#define lg_core_Slave       (0x01)
+#define lg_core_Master      (0x02)
+#define lg_core_Pending     (0x03)
+#define lg_core_Arbitrating (0x04)
+#define lg_core_Client      (0x06)
+
+/****** lock space specifics *****/
+/* note that this library masks out the lock table seperation. 
+ */
+
+typedef struct lg_lockspace_callbacks_s {
+	int (*login_reply) (void *misc, uint32_t error, uint8_t which);
+	int (*logout_reply) (void *misc);
+	int (*lock_state) (void *misc, uint8_t * key, uint16_t keylen,
+			   uint64_t subid, uint64_t start, uint64_t stop,
+			   uint8_t state, uint32_t flags, uint32_t error,
+			   uint8_t * LVB, uint16_t LVBlen);
+	int (*lock_action) (void *misc, uint8_t * key, uint16_t keylen,
+			    uint64_t subid, uint8_t action, uint32_t error);
+	int (*drop_lock_req) (void *misc, uint8_t * key, uint16_t keylen,
+			      uint64_t subid, uint8_t state);
+	int (*drop_all) (void *misc);
+	int (*error) (void *misc, uint32_t err);
+} lg_lockspace_callbacks_t;
+
+/* Like the core handle messages function, but for the lockspace.
+ * Handles one message, blocks.
+ */
+
+int lg_lock_handle_messages (gulm_interface_p, lg_lockspace_callbacks_t *,
+			     void *misc);
+
+/* this returns the filedescriptor that the library is using to 
+ * communicate with the ltpx. This is only for using in a poll() 
+ * or select() call to avoid having the gulm_lock_handle_messages()
+ * call block. 
+ */
+lg_socket lg_lock_selector (gulm_interface_p);
+
+/* Lockspace request calls */
+int lg_lock_login (gulm_interface_p, uint8_t lockspace[4]);
+int lg_lock_logout (gulm_interface_p);
+int lg_lock_state_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+                       uint64_t subid, uint64_t start, uint64_t stop,
+		       uint8_t state, uint32_t flags, uint8_t * LVB,
+		       uint16_t LVBlen);
+int lg_lock_cancel_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+			uint64_t subid);
+int lg_lock_action_req (gulm_interface_p, uint8_t * key, uint16_t keylen,
+			uint64_t subid, uint8_t action,
+			uint8_t * LVB, uint16_t LVBlen);
+int lg_lock_drop_exp (gulm_interface_p, uint8_t * holder,
+		      uint8_t * keymask, uint16_t kmlen);
+
+/* state requests */
+#define lg_lock_state_Unlock    (0x00)
+#define lg_lock_state_Exclusive (0x01)
+#define lg_lock_state_Deferred  (0x02)
+#define lg_lock_state_Shared    (0x03)
+
+/* actions */
+#define lg_lock_act_HoldLVB     (0x0b)
+#define lg_lock_act_UnHoldLVB   (0x0c)
+#define lg_lock_act_SyncLVB     (0x0d)
+
+/* flags */
+#define lg_lock_flag_DoCB        (0x00000001)
+#define lg_lock_flag_Try         (0x00000002)
+#define lg_lock_flag_Any         (0x00000004)
+#define lg_lock_flag_IgnoreExp   (0x00000008)
+#define lg_lock_flag_Cachable    (0x00000020)
+#define lg_lock_flag_Piority     (0x00000040)
+
+/* These are the possible values that can be in the error fields. */
+#define lg_err_Ok              (0)
+#define lg_err_BadLogin        (1001)
+#define lg_err_BadCluster      (1003)
+#define lg_err_BadConfig       (1004)
+#define lg_err_BadGeneration   (1005)
+#define lg_err_BadWireProto    (1019)
+
+#define lg_err_NotAllowed      (1006)
+#define lg_err_Unknown_Cs      (1007)
+#define lg_err_BadStateChg     (1008)
+#define lg_err_MemoryIssues    (1009)
+
+#define lg_err_TryFailed       (1011)
+#define lg_err_AlreadyPend     (1013)
+#define lg_err_Canceled        (1015)
+
+#define lg_err_NoSuchFS        (1016)
+#define lg_err_NoSuchJID       (1017)
+#define lg_err_NoSuchName      (1018)
+
+#endif /*__libgulm_h__*/
+
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/linux_gulm_main.c linux-patched/fs/gfs_locking/lock_gulm/linux_gulm_main.c
--- linux-orig/fs/gfs_locking/lock_gulm/linux_gulm_main.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/linux_gulm_main.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,107 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#define EXPORT_SYMTAB
+#define WANT_DEBUG_NAMES
+#define WANT_GMALLOC_NAMES
+#define EXTERN
+#include "gulm.h"
+
+#include <linux/init.h>
+
+#include "util.h"
+#include "gulm_procinfo.h"
+
+MODULE_DESCRIPTION ("Grand Unified Locking Module " GULM_RELEASE_NAME);
+MODULE_AUTHOR ("Red Hat, Inc.");
+MODULE_LICENSE ("GPL");
+
+extern gulm_cm_t gulm_cm;
+
+/**
+ * init_gulm - Initialize the gulm module
+ *
+ * Returns: 0 on success, -EXXX on failure
+ */
+int __init
+init_gulm (void)
+{
+	int error;
+
+	memset (&gulm_cm, 0, sizeof (gulm_cm_t));
+	gulm_cm.loaded = FALSE;
+	gulm_cm.hookup = NULL;
+
+	/* register with the lm layers. */
+	error = lm_register_proto (&gulm_ops);
+	if (error)
+		goto fail;
+
+	error = init_proc_dir ();
+	if (error != 0) {
+		goto fail_lm;
+	}
+
+	init_gulm_fs ();
+
+	printk ("Gulm %s (built %s %s) installed\n",
+		GULM_RELEASE_NAME, __DATE__, __TIME__);
+
+	return 0;
+
+      fail_lm:
+	lm_unregister_proto (&gulm_ops);
+
+      fail:
+	return error;
+}
+
+/**
+ * exit_gulm - cleanup the gulm module
+ *
+ */
+
+void __exit
+exit_gulm (void)
+{
+	remove_proc_dir ();
+	lm_unregister_proto (&gulm_ops);
+}
+
+module_init (init_gulm);
+module_exit (exit_gulm);
+
+/* the libgulm.h interface. */
+EXPORT_SYMBOL (lg_initialize);
+EXPORT_SYMBOL (lg_release);
+
+EXPORT_SYMBOL (lg_core_handle_messages);
+EXPORT_SYMBOL (lg_core_selector);
+EXPORT_SYMBOL (lg_core_login);
+EXPORT_SYMBOL (lg_core_logout);
+EXPORT_SYMBOL (lg_core_nodeinfo);
+EXPORT_SYMBOL (lg_core_nodelist);
+EXPORT_SYMBOL (lg_core_servicelist);
+EXPORT_SYMBOL (lg_core_corestate);
+EXPORT_SYMBOL (lg_core_shutdown);
+EXPORT_SYMBOL (lg_core_forceexpire);
+EXPORT_SYMBOL (lg_core_forcepending);
+
+EXPORT_SYMBOL (lg_lock_handle_messages);
+EXPORT_SYMBOL (lg_lock_selector);
+EXPORT_SYMBOL (lg_lock_login);
+EXPORT_SYMBOL (lg_lock_logout);
+EXPORT_SYMBOL (lg_lock_state_req);
+EXPORT_SYMBOL (lg_lock_cancel_req);
+EXPORT_SYMBOL (lg_lock_action_req);
+EXPORT_SYMBOL (lg_lock_drop_exp);
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lm_interface.h linux-patched/fs/gfs_locking/lock_gulm/lm_interface.h
--- linux-orig/fs/gfs_locking/lock_gulm/lm_interface.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lm_interface.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,193 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+
+   Sooner or later, I need to put all the documentation back into this file.
+   In the mean time, here are some notes.
+
+   -  The lock module is now responsible for STOMITHing the an expired
+   client before calling the callback with type LM_CB_NEED_RECOVERY.
+
+   -  If mount() operation returns first == TRUE, GFS will check all the
+   journals.  GFS itself can't/shouldn't stomith the machines, so the lock module
+   needs to make sure that there are no zombie machines on any of the
+   journals.  (i.e. this should probably be on the first mount of the lock
+   space where all mounts by other machines are blocked.)  GFS will call
+   others_may_mount() when the filesystem is in a consistent state.
+
+   -  GFS can issue multiple simultaneous get_lock()s for the same lockname.
+   The lock module needs to deal with it, either by 1)  building a hash table
+   to lookup the structures and keeping a reference count so there is only
+   on lm_lock_t for a given lockname. or 2) just dealing with multiple 
+   lm_lock_t structures for a given lockname.
+
+*/
+
+#ifndef __LM_INTERFACE_DOT_H__
+#define __LM_INTERFACE_DOT_H__
+
+typedef void lm_lockspace_t;
+typedef void lm_lock_t;
+typedef void lm_fsdata_t;
+typedef void (*lm_callback_t) (lm_fsdata_t *fsdata, unsigned int type,
+			       void *data);
+
+/* Flags for the struct lm_lockstruct->ls_flags field */
+
+#define LM_LSFLAG_LOCAL        (0x00000001)
+#define LM_LSFLAG_ASYNC        (0x00000002)
+
+/* Lock types */
+
+#define LM_TYPE_RESERVED       (0x00)
+#define LM_TYPE_NONDISK        (0x01)
+#define LM_TYPE_INODE          (0x02)
+#define LM_TYPE_RGRP           (0x03)
+#define LM_TYPE_META           (0x04)
+#define LM_TYPE_IOPEN          (0x05)
+#define LM_TYPE_FLOCK          (0x06)
+#define LM_TYPE_PLOCK          (0x07)
+#define LM_TYPE_QUOTA          (0x08)
+
+/* States passed to lock() */
+
+#define LM_ST_UNLOCKED         (0)
+#define LM_ST_EXCLUSIVE        (1)
+#define LM_ST_DEFERRED         (2)
+#define LM_ST_SHARED           (3)
+
+/* Flags passed to lock() */
+
+#define LM_FLAG_TRY            (0x00000001)
+#define LM_FLAG_TRY_1CB        (0x00000002)
+#define LM_FLAG_NOEXP          (0x00000004)
+#define LM_FLAG_ANY            (0x00000008)
+#define LM_FLAG_PRIORITY       (0x00000010)
+
+/* Flags returned by lock() */
+
+#define LM_OUT_ST_MASK         (0x00000003)
+#define LM_OUT_CACHEABLE       (0x00000004)
+#define LM_OUT_CANCELED        (0x00000008)
+#define LM_OUT_NEED_E          (0x00000010)
+#define LM_OUT_NEED_D          (0x00000020)
+#define LM_OUT_NEED_S          (0x00000040)
+#define LM_OUT_ASYNC           (0x00000080)
+#define LM_OUT_LVB_INVALID     (0x00000100)
+
+/* Callback types */
+
+#define LM_CB_NEED_E           (257)
+#define LM_CB_NEED_D           (258)
+#define LM_CB_NEED_S           (259)
+#define LM_CB_NEED_RECOVERY    (260)
+#define LM_CB_DROPLOCKS        (261)
+#define LM_CB_ASYNC            (262)
+
+/* Reset_exp messages */
+
+#define LM_RD_GAVEUP           (308)
+#define LM_RD_SUCCESS          (309)
+
+struct lm_lockname {
+	uint64_t ln_number;
+	unsigned int ln_type;
+};
+
+#define lm_name_equal(name1, name2) \
+(((name1)->ln_number == (name2)->ln_number) && \
+ ((name1)->ln_type == (name2)->ln_type)) \
+
+struct lm_async_cb {
+	struct lm_lockname lc_name;
+	int lc_ret;
+};
+
+struct lm_lockstruct;
+
+struct lm_lockops {
+	char lm_proto_name[256];
+
+	/* Mount/Unmount */
+
+	int (*lm_mount) (char *table_name, char *host_data,
+			 lm_callback_t cb, lm_fsdata_t *fsdata,
+			 unsigned int min_lvb_size,
+			 struct lm_lockstruct *lockstruct);
+	void (*lm_others_may_mount) (lm_lockspace_t *lockspace);
+	void (*lm_unmount) (lm_lockspace_t *lockspace);
+
+	/* Lock oriented operations */
+
+	int (*lm_get_lock) (lm_lockspace_t *lockspace,
+			    struct lm_lockname *name, lm_lock_t **lockp);
+	void (*lm_put_lock) (lm_lock_t *lock);
+
+	unsigned int (*lm_lock) (lm_lock_t *lock, unsigned int cur_state,
+				 unsigned int req_state, unsigned int flags);
+	unsigned int (*lm_unlock) (lm_lock_t *lock, unsigned int cur_state);
+
+	void (*lm_cancel) (lm_lock_t *lock);
+
+	int (*lm_hold_lvb) (lm_lock_t *lock, char **lvbp);
+	void (*lm_unhold_lvb) (lm_lock_t *lock, char *lvb);
+	void (*lm_sync_lvb) (lm_lock_t *lock, char *lvb);
+
+	/* Posix Lock oriented operations  */
+
+	int (*lm_plock_get) (lm_lockspace_t *lockspace,
+			     struct lm_lockname *name, unsigned long owner,
+			     uint64_t *start, uint64_t *end, int *exclusive,
+			     unsigned long *rowner);
+
+	int (*lm_plock) (lm_lockspace_t *lockspace,
+			 struct lm_lockname *name, unsigned long owner,
+			 int wait, int exclusive, uint64_t start,
+			 uint64_t end);
+
+	int (*lm_punlock) (lm_lockspace_t *lockspace,
+			   struct lm_lockname *name, unsigned long owner,
+			   uint64_t start, uint64_t end);
+
+	/* Client oriented operations */
+
+	void (*lm_recovery_done) (lm_lockspace_t *lockspace, unsigned int jid,
+				  unsigned int message);
+
+	struct module *lm_owner;
+};
+
+struct lm_lockstruct {
+	unsigned int ls_jid;
+	unsigned int ls_first;
+	unsigned int ls_lvb_size;
+	lm_lockspace_t *ls_lockspace;
+	struct lm_lockops *ls_ops;
+	int ls_flags;
+};
+
+/* Bottom interface */
+
+int lm_register_proto(struct lm_lockops *proto);
+void lm_unregister_proto(struct lm_lockops *proto);
+
+/* Top interface */
+
+int lm_mount(char *proto_name,
+	     char *table_name, char *host_data,
+	     lm_callback_t cb, lm_fsdata_t *fsdata,
+	     unsigned int min_lvb_size, struct lm_lockstruct *lockstruct);
+void lm_unmount(struct lm_lockstruct *lockstruct);
+
+#endif /* __LM_INTERFACE_DOT_H__ */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/load_info.c linux-patched/fs/gfs_locking/lock_gulm/load_info.c
--- linux-orig/fs/gfs_locking/lock_gulm/load_info.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/load_info.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,95 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gulm.h"
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+
+#include <linux/utsname.h>	/* for extern system_utsname */
+
+#include "util.h"
+
+gulm_cm_t gulm_cm;
+
+/**
+ * init_ltpx - 
+ */
+int
+init_ltpx (void)
+{
+	int j;
+	lock_table_t *lt = &gulm_cm.ltpx;
+
+	INIT_LIST_HEAD (&lt->to_be_sent);
+	spin_lock_init (&lt->queue_sender);
+	init_waitqueue_head (&lt->send_wchan);
+	lt->magic_one = 0xAAAAAAAA;
+	init_MUTEX (&lt->sender);
+	init_completion (&lt->startup);
+	atomic_set (&lt->locks_pending, 0);
+	lt->hashbuckets = 8191;
+	lt->hshlk = kmalloc (sizeof (spinlock_t) * lt->hashbuckets, GFP_KERNEL);
+	if (lt->hshlk == NULL)
+		return -ENOMEM;
+	lt->lkhsh =
+	    kmalloc (sizeof (struct list_head) * lt->hashbuckets, GFP_KERNEL);
+	if (lt->lkhsh == NULL) {
+		kfree (lt->hshlk);
+		return -ENOMEM;
+	}
+	for (j = 0; j < lt->hashbuckets; j++) {
+		spin_lock_init (&lt->hshlk[j]);
+		INIT_LIST_HEAD (&lt->lkhsh[j]);
+	}
+	return 0;
+}
+
+/**
+ * load_info - 
+ * @hostdata: < optionally override the name of this node.
+ * 
+ * Returns: int
+ */
+int
+load_info (char *hostdata)
+{
+	int err = 0;
+
+	if (gulm_cm.loaded)
+		goto exit;
+
+	gulm_cm.verbosity = 0;
+	if (hostdata != NULL && strlen (hostdata) > 0) {
+		strncpy (gulm_cm.myName, hostdata, 64);
+	} else {
+		strncpy (gulm_cm.myName, system_utsname.nodename, 64);
+	}
+	gulm_cm.myName[63] = '\0';
+
+	/* breaking away from ccs. just hardcoding defaults here.
+	 * Noone really used these anyways and if ppl want them badly, we'll
+	 * find another way to set them. (modprobe options for example.)
+	 * */
+	gulm_cm.handler_threads = 2;
+	gulm_cm.verbosity = lgm_Network | lgm_Stomith | lgm_Forking;
+
+	init_ltpx ();
+
+	gulm_cm.loaded = TRUE;
+      exit:
+	return err;
+}
+/* vim: set ai cin noet sw=8 ts=8 : */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/load_info.h linux-patched/fs/gfs_locking/lock_gulm/load_info.h
--- linux-orig/fs/gfs_locking/lock_gulm/load_info.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/load_info.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,17 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __load_info_h__
+#define __load_info_h__
+int load_info (char *);
+#endif /*__load_info_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/lock_gulm.mod.c linux-patched/fs/gfs_locking/lock_gulm/lock_gulm.mod.c
--- linux-orig/fs/gfs_locking/lock_gulm/lock_gulm.mod.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/lock_gulm.mod.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,64 @@
+#include <linux/module.h>
+#include <linux/vermagic.h>
+#include <linux/compiler.h>
+
+MODULE_INFO(vermagic, VERMAGIC_STRING);
+
+#undef unix
+struct module __this_module
+__attribute__((section(".gnu.linkonce.this_module"))) = {
+ .name = __stringify(KBUILD_MODNAME),
+ .init = init_module,
+#ifdef CONFIG_MODULE_UNLOAD
+ .exit = cleanup_module,
+#endif
+};
+
+static const struct modversion_info ____versions[]
+__attribute_used__
+__attribute__((section("__versions"))) = {
+	{ 0x4cdc490c, "cleanup_module" },
+	{ 0xcd58c830, "init_module" },
+	{ 0x2fd6183e, "struct_module" },
+	{ 0x7da8156e, "__kmalloc" },
+	{ 0x15413d5, "del_timer" },
+	{ 0xfcb2e1be, "malloc_sizes" },
+	{ 0xf28971c5, "remove_wait_queue" },
+	{ 0x6cef6a5d, "sock_release" },
+	{ 0xa82cd6, "sock_recvmsg" },
+	{ 0x7ff583dc, "remove_proc_entry" },
+	{ 0x1d26aa98, "sprintf" },
+	{ 0xda02d67, "jiffies" },
+	{ 0x62129c6f, "default_wake_function" },
+	{ 0x4abe8112, "wait_for_completion" },
+	{ 0x364f95fe, "proc_mkdir" },
+	{ 0x1b7d4074, "printk" },
+	{ 0x4ee7a0fa, "sock_sendmsg" },
+	{ 0x1075bf0, "panic" },
+	{ 0x97abb28c, "in6addr_loopback" },
+	{ 0xa34f1ef5, "crc32_le" },
+	{ 0x44524640, "mod_timer" },
+	{ 0xe98f1978, "kmem_cache_alloc" },
+	{ 0xb12cdfe7, "system_utsname" },
+	{ 0x17d59d01, "schedule_timeout" },
+	{ 0x4292364c, "schedule" },
+	{ 0xfb6af58d, "recalc_sigpending" },
+	{ 0xe4e2b8a4, "create_proc_entry" },
+	{ 0x685bdb69, "proc_root" },
+	{ 0x830eb7ae, "__wake_up" },
+	{ 0xf4e820df, "add_wait_queue" },
+	{ 0x37a0cba, "kfree" },
+	{ 0x2e60bace, "memcpy" },
+	{ 0x3ff1c2f5, "sock_create" },
+	{ 0x7e9ebb05, "kernel_thread" },
+	{ 0xd22b546, "__up_wakeup" },
+	{ 0x136eba7c, "complete" },
+	{ 0xf2520b76, "__down_failed" },
+	{ 0xdc43a9c8, "daemonize" },
+};
+
+static const char __module_depends[]
+__attribute_used__
+__attribute__((section(".modinfo"))) =
+"depends=ipv6,crc32";
+
diff -urN linux-orig/fs/gfs_locking/lock_gulm/util.c linux-patched/fs/gfs_locking/lock_gulm/util.c
--- linux-orig/fs/gfs_locking/lock_gulm/util.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/util.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,109 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/crc32.h>
+
+/**
+ * atoi
+ *
+ * @c:
+ *
+ */
+
+int
+atoi (char *c)
+{
+	int x = 0;
+
+	while ('0' <= *c && *c <= '9') {
+		x = x * 10 + (*c - '0');
+		c++;
+	}
+
+	return (x);
+}
+
+/**
+ * inet_aton
+ *
+ * @ascii:
+ * @ip:
+ *
+ */
+
+int
+inet_aton (char *ascii, uint32_t * ip)
+{
+	uint32_t value;
+	int x;
+
+	*ip = 0;
+
+	for (x = 0; x < 4; x++) {
+		value = atoi (ascii);
+		if (value > 255)
+			return (-1);
+
+		*ip = (*ip << 8) | value;
+
+		if (x != 3) {
+			for (; *ascii != '.' && *ascii != '\0'; ascii++) {
+				if (*ascii < '0' || *ascii > '9') {
+					/* not a number. stop */
+					return -1;
+				}
+			}
+			if (*ascii == '\0')
+				return (-1);
+
+			ascii++;
+		}
+	}
+
+	return (0);
+}
+
+/**
+ * inet_ntoa
+ *
+ * @ascii:
+ * @ip:
+ *
+ */
+void
+inet_ntoa (uint32_t ip, char *buf)
+{
+	int i;
+	char *p;
+
+	p = buf;
+
+	for (i = 3; i >= 0; i--) {
+		p += sprintf (p, "%d", (ip >> (8 * i)) & 0xFF);
+		if (i > 0)
+			*(p++) = '.';
+	}
+
+}
+
+/* public functions */
+#define hash_init_val 0x6d696b65
+
+uint32_t __inline__
+hash_lock_key (uint8_t * in, uint8_t len)
+{
+   return crc32 (hash_init_val, in, len);
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/util.h linux-patched/fs/gfs_locking/lock_gulm/util.h
--- linux-orig/fs/gfs_locking/lock_gulm/util.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/util.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,29 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __UTIL_DOT_H__
+#define __UTIL_DOT_H__
+
+int atoi (char *c);
+int inet_aton (char *ascii, uint32_t * ip);
+void inet_ntoa (uint32_t ip, char *buf);
+void dump_buffer (void *buf, int len);
+
+uint32_t __inline__ hash_lock_key (uint8_t * in, uint8_t len);
+uint8_t __inline__ fourtoone (uint32_t);
+
+__inline__ int testbit (uint16_t bit, uint8_t * set);
+__inline__ void setbit (uint16_t bit, uint8_t * set);
+__inline__ void clearbit (uint16_t bit, uint8_t * set);
+
+#endif				/*  __UTIL_DOT_H__  */
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_crc.c linux-patched/fs/gfs_locking/lock_gulm/utils_crc.c
--- linux-orig/fs/gfs_locking/lock_gulm/utils_crc.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_crc.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,92 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include <linux/types.h>
+
+static const uint32_t crc_32_tab[] = {
+	0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419, 0x706af48f,
+	0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4, 0xe0d5e91e, 0x97d2d988,
+	0x09b64c2b, 0x7eb17cbd, 0xe7b82d07, 0x90bf1d91, 0x1db71064, 0x6ab020f2,
+	0xf3b97148, 0x84be41de, 0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7,
+	0x136c9856, 0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,
+	0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4, 0xa2677172,
+	0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b, 0x35b5a8fa, 0x42b2986c,
+	0xdbbbc9d6, 0xacbcf940, 0x32d86ce3, 0x45df5c75, 0xdcd60dcf, 0xabd13d59,
+	0x26d930ac, 0x51de003a, 0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423,
+	0xcfba9599, 0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,
+	0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190, 0x01db7106,
+	0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f, 0x9fbfe4a5, 0xe8b8d433,
+	0x7807c9a2, 0x0f00f934, 0x9609a88e, 0xe10e9818, 0x7f6a0dbb, 0x086d3d2d,
+	0x91646c97, 0xe6635c01, 0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e,
+	0x6c0695ed, 0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,
+	0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3, 0xfbd44c65,
+	0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2, 0x4adfa541, 0x3dd895d7,
+	0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a, 0x346ed9fc, 0xad678846, 0xda60b8d0,
+	0x44042d73, 0x33031de5, 0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa,
+	0xbe0b1010, 0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,
+	0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17, 0x2eb40d81,
+	0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6, 0x03b6e20c, 0x74b1d29a,
+	0xead54739, 0x9dd277af, 0x04db2615, 0x73dc1683, 0xe3630b12, 0x94643b84,
+	0x0d6d6a3e, 0x7a6a5aa8, 0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1,
+	0xf00f9344, 0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,
+	0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a, 0x67dd4acc,
+	0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5, 0xd6d6a3e8, 0xa1d1937e,
+	0x38d8c2c4, 0x4fdff252, 0xd1bb67f1, 0xa6bc5767, 0x3fb506dd, 0x48b2364b,
+	0xd80d2bda, 0xaf0a1b4c, 0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55,
+	0x316e8eef, 0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,
+	0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe, 0xb2bd0b28,
+	0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31, 0x2cd99e8b, 0x5bdeae1d,
+	0x9b64c2b0, 0xec63f226, 0x756aa39c, 0x026d930a, 0x9c0906a9, 0xeb0e363f,
+	0x72076785, 0x05005713, 0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38,
+	0x92d28e9b, 0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,
+	0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1, 0x18b74777,
+	0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c, 0x8f659eff, 0xf862ae69,
+	0x616bffd3, 0x166ccf45, 0xa00ae278, 0xd70dd2ee, 0x4e048354, 0x3903b3c2,
+	0xa7672661, 0xd06016f7, 0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc,
+	0x40df0b66, 0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,
+	0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605, 0xcdd70693,
+	0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8, 0x5d681b02, 0x2a6f2b94,
+	0xb40bbe37, 0xc30c8ea1, 0x5a05df1b, 0x2d02ef8d
+};
+
+/**
+ * crc32 - hash an array of data
+ * @data: the data to be hashed
+ * @len: the length of data to be hashed
+ *
+ * completely copied from GFS/src/fs.c
+ *
+ * Take some data and convert it to a 32-bit hash.
+ *
+ * The hash function is a 32-bit CRC of the data.  The algorithm uses
+ * the crc_32_tab table above.
+ *
+ * This may not be the fastest hash function, but it does a fair bit better
+ * at providing uniform results than the others I've looked at.  That's
+ * really important for efficient directories.
+ *
+ * Returns: the hash
+ */
+
+uint32_t
+crc32 (const char *data, int len, uint32_t init)
+{
+	uint32_t hash = init;
+
+	for (; len--; data++)
+		hash = crc_32_tab[(hash ^ *data) & 0xFF] ^ (hash >> 8);
+
+	hash = ~hash;
+
+	return hash;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_crc.h linux-patched/fs/gfs_locking/lock_gulm/utils_crc.h
--- linux-orig/fs/gfs_locking/lock_gulm/utils_crc.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_crc.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,17 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __utils_crc_h__
+#define __utils_crc_h__
+uint32_t crc32 (const char *data, int len, uint32_t init);
+#endif /*__utils_crc_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.c linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.c
--- linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,207 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#include "gio_wiretypes.h"
+
+char *
+gio_Err_to_str (int x)
+{
+	char *t = "Unknown GULM Err";
+	switch (x) {
+	case gio_Err_Ok:
+		t = "Ok";
+		break;
+
+	case gio_Err_BadLogin:
+		t = "Bad Login";
+		break;
+	case gio_Err_BadCluster:
+		t = "Bad Cluster ID";
+		break;
+	case gio_Err_BadConfig:
+		t = "Incompatible configurations";
+		break;
+	case gio_Err_BadGeneration:
+		t = "Bad Generation ID";
+		break;
+	case gio_Err_BadWireProto:
+		t = "Bad Wire Protocol Version";
+		break;
+
+	case gio_Err_NotAllowed:
+		t = "Not Allowed";
+		break;
+	case gio_Err_Unknown_Cs:
+		t = "Uknown Client";
+		break;
+	case gio_Err_BadStateChg:
+		t = "Bad State Change";
+		break;
+	case gio_Err_MemoryIssues:
+		t = "Memory Problems";
+		break;
+
+	case gio_Err_PushQu:
+		t = "Push Queue";
+		break;
+	case gio_Err_TryFailed:
+		t = "Try Failed";
+		break;
+	case gio_Err_AlreadyPend:
+		t = "Request Already Pending";
+		break;
+	case gio_Err_Canceled:
+		t = "Request Canceled";
+		break;
+
+	case gio_Err_NoSuchFS:
+		t = "No Such Filesystem";
+		break;
+	case gio_Err_NoSuchJID:
+		t = "No Such JID";
+		break;
+	case gio_Err_NoSuchName:
+		t = "No Such Node";
+		break;
+	}
+	return t;
+}
+
+char *
+gio_mbrupdate_to_str (int x)
+{
+	char *t = "Unknown Membership Update";
+	switch (x) {
+	case gio_Mbr_Logged_in:
+		t = "Logged in";
+		break;
+	case gio_Mbr_Logged_out:
+		t = "Logged out";
+		break;
+	case gio_Mbr_Expired:
+		t = "Expired";
+		break;
+	case gio_Mbr_Killed:
+		t = "Fenced";
+		break;
+	case gio_Mbr_OM_lgin:
+		t = "Was Logged in";
+		break;
+	}
+	return t;
+}
+
+char *
+gio_I_am_to_str (int x)
+{
+	switch (x) {
+	case gio_Mbr_ama_Slave:
+		return "Slave";
+		break;
+	case gio_Mbr_ama_Pending:
+		return "Pending";
+		break;
+	case gio_Mbr_ama_Arbitrating:
+		return "Arbitrating";
+		break;
+	case gio_Mbr_ama_Master:
+		return "Master";
+		break;
+	case gio_Mbr_ama_Resource:
+		return "Service";
+		break;
+	case gio_Mbr_ama_Client:
+		return "Client";
+		break;
+	default:
+		return "Unknown I_am state";
+		break;
+	}
+}
+
+char *
+gio_license_states (int x)
+{
+	switch (x) {
+	case 0:
+		return "valid";
+		break;
+	case 1:
+		return "expired";
+		break;
+	case 2:
+		return "invalid";
+		break;
+	default:
+		return "unknown";
+		break;
+	}
+}
+
+char *
+gio_opcodes (int x)
+{
+	switch (x) {
+#define CP(x) case (x): return #x ; break
+		CP (gulm_err_reply);
+
+		CP (gulm_core_login_req);
+		CP (gulm_core_login_rpl);
+		CP (gulm_core_logout_req);
+		CP (gulm_core_logout_rpl);
+		CP (gulm_core_reslgn_req);
+		CP (gulm_core_beat_req);
+		CP (gulm_core_beat_rpl);
+		CP (gulm_core_mbr_req);
+		CP (gulm_core_mbr_updt);
+		CP (gulm_core_mbr_lstreq);
+		CP (gulm_core_mbr_lstrpl);
+		CP (gulm_core_mbr_force);
+		CP (gulm_core_res_req);
+		CP (gulm_core_res_list);
+		CP (gulm_core_state_req);
+		CP (gulm_core_state_chgs);
+		CP (gulm_core_shutdown);
+		CP (gulm_core_forcepend);
+
+		CP (gulm_info_stats_req);
+		CP (gulm_info_stats_rpl);
+		CP (gulm_info_set_verbosity);
+		CP (gulm_socket_close);
+		CP (gulm_info_slave_list_req);
+		CP (gulm_info_slave_list_rpl);
+
+		CP (gulm_lock_login_req);
+		CP (gulm_lock_login_rpl);
+		CP (gulm_lock_logout_req);
+		CP (gulm_lock_logout_rpl);
+		CP (gulm_lock_state_req);
+		CP (gulm_lock_state_rpl);
+		CP (gulm_lock_state_updt);
+		CP (gulm_lock_action_req);
+		CP (gulm_lock_action_rpl);
+		CP (gulm_lock_action_updt);
+		CP (gulm_lock_update_rpl);
+		CP (gulm_lock_cb_state);
+		CP (gulm_lock_cb_dropall);
+		CP (gulm_lock_drop_exp);
+		CP (gulm_lock_dump_req);
+		CP (gulm_lock_dump_rpl);
+		CP (gulm_lock_rerunqueues);
+
+#undef CP
+	default:
+		return "Unknown Op Code";
+		break;
+	}
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.h linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.h
--- linux-orig/fs/gfs_locking/lock_gulm/utils_tostr.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/utils_tostr.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,22 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __utils_tostr_h__
+#define __utils_tostr_h__
+char *gio_Err_to_str (int x);
+char *gio_mbrupdate_to_str (int x);
+char *gio_mbrama_to_str (int x);
+char *gio_I_am_to_str (int x);
+char *gio_license_states (int x);
+char *gio_opcodes (int x);
+#endif /*__utils_tostr_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr.h linux-patched/fs/gfs_locking/lock_gulm/xdr.h
--- linux-orig/fs/gfs_locking/lock_gulm/xdr.h	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr.h	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,98 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+#ifndef __gulm_xdr_h__
+#define __gulm_xdr_h__
+typedef struct xdr_enc_s xdr_enc_t;
+typedef struct xdr_dec_s xdr_dec_t;
+
+/* sockets in kernel space are done a bit different than socket in
+ * userspace.  But we need to have them appear to be the same.
+ */
+#ifdef __KERNEL__
+
+#ifdef __linux__
+#include <linux/net.h>
+#include <linux/in.h>
+#include <linux/in6.h>
+#include <linux/socket.h>
+#include <net/sock.h>
+
+typedef struct socket *xdr_socket;
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+#include <sys/types.h>
+#include <sys/uio.h>
+#include <sys/socket.h>
+#include <netinet/in.h>
+#include <netinet/tcp.h>
+#include <unistd.h>
+#include <errno.h>
+typedef int xdr_socket;
+#endif /*__KERNEL__*/
+
+/* start things up */
+int xdr_open (xdr_socket * sk);
+int xdr_connect (struct sockaddr_in6 *adr, xdr_socket sk);
+void xdr_close (xdr_socket * sk);
+
+/* deep, basic io */
+#ifdef __KERNEL__
+#ifdef __linux__
+size_t xdr_send (struct socket *sock, void *buf, size_t size);
+size_t xdr_recv (struct socket *sock, void *buf, size_t size);
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+ssize_t xdr_recv (int fd, void *buf, size_t len);
+ssize_t xdr_send (int fd, void *buf, size_t len);
+#endif /*__KERNEL__*/
+
+xdr_enc_t *xdr_enc_init (xdr_socket sk, int buffer_size);
+xdr_dec_t *xdr_dec_init (xdr_socket sk, int buffer_size);
+int xdr_enc_flush (xdr_enc_t * xdr);
+int xdr_enc_release (xdr_enc_t * xdr);	/* calls xdr_enc_flush() */
+void xdr_enc_force_release (xdr_enc_t * xdr);	/* doesn't call xdr_enc_flush() */
+void xdr_dec_release (xdr_dec_t * xdr);
+/* xdr_enc_force_release() is for when you get and error sending and you
+ * want to free that stuff up right away.  If you use the regular release
+ * for enc, it will fail if it cannot send data over the filedesciptor.
+ */
+
+/* encoders add to a stream */
+int __inline__ xdr_enc_uint64 (xdr_enc_t * xdr, uint64_t i);
+int __inline__ xdr_enc_uint32 (xdr_enc_t * xdr, uint32_t i);
+int __inline__ xdr_enc_uint16 (xdr_enc_t * xdr, uint16_t i);
+int __inline__ xdr_enc_uint8 (xdr_enc_t * xdr, uint8_t i);
+int __inline__ xdr_enc_ipv6 (xdr_enc_t * enc, struct in6_addr *ip);
+int xdr_enc_raw (xdr_enc_t * xdr, void *pointer, uint16_t len);
+int xdr_enc_raw_iov (xdr_enc_t * xdr, int count, struct iovec *iov);
+int xdr_enc_string (xdr_enc_t * xdr, uint8_t * s);
+int xdr_enc_list_start (xdr_enc_t * xdr);
+int xdr_enc_list_stop (xdr_enc_t * xdr);
+
+/* decoders remove from stream */
+int xdr_dec_uint64 (xdr_dec_t * xdr, uint64_t * i);
+int xdr_dec_uint32 (xdr_dec_t * xdr, uint32_t * i);
+int xdr_dec_uint16 (xdr_dec_t * xdr, uint16_t * i);
+int xdr_dec_uint8 (xdr_dec_t * xdr, uint8_t * i);
+int xdr_dec_ipv6 (xdr_dec_t * xdr, struct in6_addr *ip);
+int xdr_dec_raw (xdr_dec_t * xdr, void *p, uint16_t * l);	/* no malloc */
+int xdr_dec_raw_m (xdr_dec_t * xdr, void **p, uint16_t * l);	/* mallocs p */
+int xdr_dec_raw_ag (xdr_dec_t * xdr, void **p, uint16_t * bl, uint16_t * rl);
+int xdr_dec_string (xdr_dec_t * xdr, uint8_t ** strp);	/* mallocs s */
+int xdr_dec_string_nm (xdr_dec_t * xdr, uint8_t * strp, size_t l);	/* no malloc */
+int xdr_dec_string_ag (xdr_dec_t * xdr, uint8_t ** s, uint16_t * bl);
+int xdr_dec_list_start (xdr_dec_t * xdr);
+int xdr_dec_list_stop (xdr_dec_t * xdr);
+
+#endif /*__gulm_xdr_h__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_base.c linux-patched/fs/gfs_locking/lock_gulm/xdr_base.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_base.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_base.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,904 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * This is a bit of an abstraction layer to get this working in both kernel
+ * and userspace.
+ */
+#define TRUE  (1)
+#define FALSE (0)
+#define MIN(a,b) ((a<b)?a:b)
+
+#ifdef __linux__
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+#define __KERNEL_SYSCALLS__
+#include <linux/unistd.h>
+#endif /*__linux__*/
+
+#include "xdr.h"
+
+/**
+ * xdr_realloc - a realloc for kernel space.
+ * @a: < pointer to realloc
+ * @nl: < desired new size
+ * @ol: < current old size
+ * 
+ * Not as good as the real realloc, since it always moves memory.  But good
+ * enough for as little as it will get used here.
+ *
+ * XXX this is broken.
+ * 
+ * Returns: void*
+ */
+static void *
+xdr_realloc (void *a, size_t nl, size_t ol)
+{
+	if (nl == ol) {
+		return a;
+	} else if (nl == 0) {
+		kfree (a);
+		return NULL;
+	} else if (a == NULL && nl > 0) {
+		return kmalloc (nl, GFP_KERNEL);
+	} else {
+		void *tmp;
+		tmp = kmalloc (nl, GFP_KERNEL);
+		if (tmp == NULL)
+			return NULL;
+		memcpy (tmp, a, MIN (nl, ol));
+		kfree (a);
+		return tmp;
+	}
+}
+
+typedef enum { xdr_enc, xdr_dec } xdr_type;
+
+/* encoders have this sorta non-blocking, growing buffering stunt.
+ * makes them a bit different from the decoders now.
+ */
+struct xdr_enc_s {
+	size_t default_buf_size;
+	xdr_socket fd;
+	xdr_type type;
+	size_t length;
+	size_t curloc;
+	uint8_t *stream;
+};
+
+/* decoders only pull a single item off of the socket at a time.
+ * so this is all they need.
+ */
+struct xdr_dec_s {
+	size_t length;		/* total byte length of the stream */
+	size_t curloc;		/* current byte offset from start */
+	uint8_t *stream;	/* start of the encoded stream. */
+	xdr_socket fd;
+	xdr_type type;
+};
+
+/* the types of data we support. */
+
+#define XDR_NULL          0x00	/* NOT A VALID TAG!!! used in dec code. */
+#define XDR_LIST_START    0x01
+#define XDR_LIST_STOP     0x02
+/* list is a variable length device.  It is a start tag, some number of
+ * xdr_enc_*, then an stop tag.  It's main purpose is to provide a method
+ * of encasing data.
+ * */
+#define XDR_STRING        0x04
+/* string tag is followed by a uint16 which is the byte length */
+#define XDR_RAW           0x05
+/* raw tag is followed by a uint16 which is the byte length
+ * if 65535 bytes isn't enough, split your data and put multiples of these
+ * back to back.  (idea of xdr is to avoid this twit.)
+ * */
+
+/* note, if the size of these should variate, I'm screwed.  Should consider
+ * changing this all to the bit shift and array access to be more concrete.
+ * later.
+ */
+#define XDR_UINT64        0x06
+#define XDR_UINT32        0x07
+#define XDR_UINT16        0x08
+#define XDR_UINT8         0x09
+/* should add signed ints */
+
+#define XDR_IPv6          0x0a	/* 16 bytes, IPv6 address */
+
+/* any other base types?
+ */
+
+#define XDR_DEFAULT_BUFFER_SIZE 4096
+/*****************************************************************************/
+
+/**
+ * xdr_enc_init - 
+ * @fd: 
+ * @buffer_size: 
+ * 
+ * 
+ * Returns: xdr_enc_t*
+ */
+xdr_enc_t *
+xdr_enc_init (xdr_socket fd, int buffer_size)
+{
+	xdr_enc_t *xdr;
+
+	if (buffer_size <= 0)
+		buffer_size = XDR_DEFAULT_BUFFER_SIZE;
+
+	xdr = kmalloc (sizeof (xdr_enc_t), GFP_KERNEL);
+	if (xdr == NULL)
+		return NULL;
+	xdr->stream = kmalloc (buffer_size, GFP_KERNEL);
+	if (xdr->stream == NULL) {
+		kfree (xdr);
+		return NULL;
+	}
+	xdr->fd = fd;
+	xdr->type = xdr_enc;
+	xdr->default_buf_size = buffer_size;
+	xdr->length = buffer_size;
+	xdr->curloc = 0;
+
+	return xdr;
+}
+
+/**
+ * xdr_dec_init - 
+ * @fd: 
+ * @buffer_size: 
+ * 
+ * 
+ * Returns: xdr_dec_t*
+ */
+xdr_dec_t *
+xdr_dec_init (xdr_socket fd, int buffer_size)
+{
+	xdr_dec_t *xdr;
+
+	if (buffer_size <= 0)
+		buffer_size = XDR_DEFAULT_BUFFER_SIZE;
+
+	xdr = kmalloc (sizeof (xdr_dec_t), GFP_KERNEL);
+	if (xdr == NULL)
+		return NULL;
+	xdr->length = buffer_size;
+	xdr->curloc = 0;
+	xdr->stream = kmalloc (buffer_size, GFP_KERNEL);
+	xdr->fd = fd;
+	xdr->type = xdr_dec;
+	if (xdr->stream == NULL) {
+		kfree (xdr);
+		return NULL;
+	}
+	*(xdr->stream) = XDR_NULL;	/* so the first dec_call will call get_next */
+	return xdr;
+}
+
+/*****************************************************************************/
+/**
+ * xdr_enc_flush - 
+ * @xdr: 
+ * 
+ * Returns: int
+ */
+int
+xdr_enc_flush (xdr_enc_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (xdr->type != xdr_enc)
+		return -EINVAL;
+	if (xdr->curloc == 0)
+		return 0;
+
+	err = xdr_send (xdr->fd, xdr->stream, xdr->curloc);
+	if (err < 0)
+		return err;
+	if (err == 0)
+		return -EPROTO;	/* why? */
+	xdr->curloc = 0;
+
+	return 0;
+}
+
+/**
+ * xdr_release - 
+ * @xdr: 
+ *
+ * Free the memory, losing whatever may be there.
+ */
+void
+xdr_dec_release (xdr_dec_t * xdr)
+{
+	if (xdr == NULL)
+		return;
+	kfree (xdr->stream);
+	kfree (xdr);
+}
+
+/**
+ * xdr_enc_force_release - 
+ * @xdr: 
+ * 
+ * Free the memory, losing whatever may be there.
+ */
+void
+xdr_enc_force_release (xdr_enc_t * xdr)
+{
+	if (xdr == NULL)
+		return;
+	if (xdr->stream != NULL)
+		kfree (xdr->stream);
+	kfree (xdr);
+}
+
+/**
+ * xdr_enc_release - 
+ * @xdr: 
+ * 
+ * Free things up, trying to send any possible leftover data first.
+ * 
+ * Returns: int
+ */
+int
+xdr_enc_release (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = xdr_enc_flush (xdr)) != 0)
+		return e;
+	xdr_enc_force_release (xdr);
+	return 0;
+}
+
+/*****************************************************************************/
+/**
+ * grow_stream - 
+ * @xdr: 
+ * @len: 
+ * 
+ * each single encoded call needs to fit within a buffer.  So we make sure
+ * the buffer is big enough.
+ *
+ * If the buffer is big enough, but just doesn't have room, we send the
+ * data in the buffer, emptying it, first.
+ * 
+ * Returns: int
+ */
+static int
+grow_stream (xdr_enc_t * enc, size_t len)
+{
+	int err;
+	uint8_t *c;
+
+	/* buffer must be big enough for one type entry. */
+	if (len > enc->length) {
+		c = xdr_realloc (enc->stream, len, enc->length);
+		if (c == NULL)
+			return -ENOMEM;
+		enc->stream = c;
+		enc->length = len;
+	}
+
+	/* if there isn't room on the end of this chunk,
+	 * try sending what we've got.
+	 */
+	if (enc->curloc + len > enc->length) {
+		err = xdr_enc_flush (enc);
+		if (err != 0) {
+			/* error, better pass this up. */
+			return err;
+		}
+	}
+
+	return 0;
+}
+
+/**
+ * append_bytes - 
+ * @xdr: 
+ * @xdr_type: 
+ * @bytes: 
+ * @len: 
+ * 
+ * 
+ * Returns: int
+ */
+static int
+append_bytes (xdr_enc_t * xdr, uint8_t xdr_type, void *bytes, size_t len)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (xdr->type != xdr_enc)
+		return -EINVAL;
+
+	/* len + 1; need the one byte for the type code. */
+	if ((e = grow_stream (xdr, len + 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = xdr_type;
+	xdr->curloc += 1;
+	memcpy ((xdr->stream + xdr->curloc), bytes, len);
+	xdr->curloc += len;
+
+	return 0;
+}
+
+int __inline__
+xdr_enc_uint64 (xdr_enc_t * xdr, uint64_t i)
+{
+	uint64_t b = cpu_to_be64 (i);
+	return append_bytes (xdr, XDR_UINT64, &b, sizeof (uint64_t));
+}
+
+int __inline__
+xdr_enc_uint32 (xdr_enc_t * xdr, uint32_t i)
+{
+	uint32_t b = cpu_to_be32 (i);
+	return append_bytes (xdr, XDR_UINT32, &b, sizeof (uint32_t));
+}
+
+int __inline__
+xdr_enc_uint16 (xdr_enc_t * xdr, uint16_t i)
+{
+	uint16_t b = cpu_to_be16 (i);
+	return append_bytes (xdr, XDR_UINT16, &b, sizeof (uint16_t));
+}
+
+int __inline__
+xdr_enc_uint8 (xdr_enc_t * xdr, uint8_t i)
+{
+	return append_bytes (xdr, XDR_UINT8, &i, sizeof (uint8_t));
+}
+
+int __inline__
+xdr_enc_ipv6 (xdr_enc_t * xdr, struct in6_addr *ip)
+{				/* bytes should already be in the right order. */
+	return append_bytes (xdr, XDR_IPv6, ip->s6_addr, 16);
+}
+
+int
+xdr_enc_raw (xdr_enc_t * xdr, void *p, uint16_t len)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, len + 3)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_RAW;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (len);
+	xdr->curloc += 2;
+	memcpy ((xdr->stream + xdr->curloc), p, len);
+	xdr->curloc += len;
+	return 0;
+}
+
+int
+xdr_enc_raw_iov (xdr_enc_t * xdr, int count, struct iovec *iov)
+{
+	size_t total = 0;
+	int i, err;
+	if (xdr == NULL || count < 1 || iov == NULL)
+		return -EINVAL;
+	for (i = 0; i < count; i++)
+		total += iov[i].iov_len;
+	/* make sure it fits in a uint16_t */
+	if (total > 0xffff)
+		return -EFBIG;
+	/* grow to fit */
+	if ((err = grow_stream (xdr, total + 3)) != 0)
+		return err;
+	/* copy in header and size */
+	*(xdr->stream + xdr->curloc) = XDR_RAW;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (total);
+	xdr->curloc += 2;
+	/* copy in all iovbufs */
+	for (i = 0; i < count; i++) {
+		if (iov[i].iov_base == NULL)
+			continue;
+		memcpy ((xdr->stream + xdr->curloc), iov[i].iov_base,
+			iov[i].iov_len);
+		xdr->curloc += iov[i].iov_len;
+	}
+	return 0;
+}
+
+int
+xdr_enc_string (xdr_enc_t * xdr, uint8_t * s)
+{
+	int len, e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (s == NULL)
+		len = 0;
+	else
+		len = strlen (s);
+	if ((e = grow_stream (xdr, len + 3)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_STRING;
+	xdr->curloc += 1;
+	(uint16_t) * ((uint16_t *) (xdr->stream + xdr->curloc)) =
+	    cpu_to_be16 (len);
+	xdr->curloc += 2;
+	if (len > 0) {
+		memcpy ((xdr->stream + xdr->curloc), s, len);
+		xdr->curloc += len;
+	}
+	return 0;
+}
+
+int
+xdr_enc_list_start (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_LIST_START;
+	xdr->curloc += 1;
+	return 0;
+}
+
+int
+xdr_enc_list_stop (xdr_enc_t * xdr)
+{
+	int e;
+	if (xdr == NULL)
+		return -EINVAL;
+	if ((e = grow_stream (xdr, 1)) != 0)
+		return e;
+	*(xdr->stream + xdr->curloc) = XDR_LIST_STOP;
+	xdr->curloc += 1;
+	return 0;
+}
+
+/*****************************************************************************/
+
+/**
+ * get_next - 
+ * @xdr: 
+ * 
+ * get what ever may be next, and put it into the buffer.
+ * 
+ * Returns: int
+ */
+static int
+get_next (xdr_dec_t * xdr)
+{
+	int err;
+	uint16_t len;
+	if ((err = xdr_recv (xdr->fd, xdr->stream, 1)) < 0)
+		return err;
+	if (err == 0)
+		return -EPROTO;
+	xdr->curloc = 1;
+	if (*(xdr->stream) == XDR_UINT64) {
+		len = sizeof (uint64_t);
+	} else if (*(xdr->stream) == XDR_UINT32) {
+		len = sizeof (uint32_t);
+	} else if (*(xdr->stream) == XDR_UINT16) {
+		len = sizeof (uint16_t);
+	} else if (*(xdr->stream) == XDR_UINT8) {
+		len = sizeof (uint8_t);
+	} else if (*(xdr->stream) == XDR_IPv6) {
+		len = 16;
+	} else if (*(xdr->stream) == XDR_STRING) {
+		if ((err = xdr_recv (xdr->fd, (xdr->stream + 1), 2)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+		len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+		xdr->curloc += 2;
+	} else if (*(xdr->stream) == XDR_RAW) {
+		if ((err = xdr_recv (xdr->fd, (xdr->stream + 1), 2)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+		len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+		xdr->curloc += 2;
+	} else if (*(xdr->stream) == XDR_LIST_START) {
+		xdr->curloc = 0;
+		return 0;
+	} else if (*(xdr->stream) == XDR_LIST_STOP) {
+		xdr->curloc = 0;
+		return 0;
+	} else {
+		return -1;
+	}
+
+	/* grow buffer if need be. */
+	if (xdr->curloc + len > xdr->length) {
+		uint8_t *c;
+		c = xdr_realloc (xdr->stream, xdr->curloc + len, xdr->length);
+		if (c == NULL)
+			return -ENOMEM;
+		xdr->stream = c;
+		xdr->length = xdr->curloc + len;
+	}
+
+	if (len > 0) {
+		if ((err =
+		     xdr_recv (xdr->fd, (xdr->stream + xdr->curloc), len)) < 0)
+			return err;
+		if (err == 0)
+			return -EPROTO;
+	}
+	xdr->curloc = 0;
+	return 0;
+}
+
+int
+xdr_dec_uint64 (xdr_dec_t * xdr, uint64_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT64)
+		return -ENOMSG;
+	*i = be64_to_cpu (*((uint64_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint32 (xdr_dec_t * xdr, uint32_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT32)
+		return -ENOMSG;
+	*i = be32_to_cpu (*((uint32_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint16 (xdr_dec_t * xdr, uint16_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT16)
+		return -ENOMSG;
+	*i = be16_to_cpu (*((uint16_t *) (xdr->stream + 1)));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_uint8 (xdr_dec_t * xdr, uint8_t * i)
+{
+	int err;
+	if (xdr == NULL || i == NULL)
+		return -EINVAL;
+
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_UINT8)
+		return -ENOMSG;
+	*i = *((uint8_t *) (xdr->stream + 1));
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_ipv6 (xdr_dec_t * xdr, struct in6_addr *ip)
+{
+	int err;
+	if (xdr == NULL || ip == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_IPv6)
+		return -ENOMSG;
+	memcpy (ip, xdr->stream + 1, 16);
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* mallocing version */
+int
+xdr_dec_raw_m (xdr_dec_t * xdr, void **p, uint16_t * l)
+{
+	int len;
+	void *str;
+	int err;
+
+	if (xdr == NULL || p == NULL || l == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	str = kmalloc (len, GFP_KERNEL);
+	if (str == NULL)
+		return -ENOMEM;
+	memcpy (str, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*p = str;
+	*l = len;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* non-mallocing version */
+int
+xdr_dec_raw (xdr_dec_t * xdr, void *p, uint16_t * l)
+{
+	int len;
+	int err;
+
+	if (xdr == NULL || p == NULL || l == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > *l)
+		return -1;
+
+	memcpy (p, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*l = len;
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/**
+ * xdr_dec_raw_ag - auto-growing version
+ * @xdr: 
+ * @p: <> pointer to buffer
+ * @bl: <> size of the buffer
+ * @rl: > size of data read from stream
+ * 
+ * This form of xdr_dec_raw will increase the size of a pre-malloced buffer
+ * to fit the data it is reading.  It is kind of a merger of the
+ * non-mallocing and mallocing versions.
+ * 
+ * Returns: int
+ */
+int
+xdr_dec_raw_ag (xdr_dec_t * xdr, void **p, uint16_t * bl, uint16_t * rl)
+{
+	int len;
+	int err;
+
+	if (xdr == NULL || p == NULL || bl == NULL || rl == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_RAW)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > *bl) {	/* grow p */
+		void *temp;
+		temp = xdr_realloc (*p, len, *bl);
+		if (temp == NULL)
+			return -ENOMEM;
+		*bl = len;
+		*p = temp;
+	}
+
+	memcpy (*p, (xdr->stream + xdr->curloc), len);
+	xdr->curloc += len;
+
+	*rl = len;
+
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* mallocing version */
+int
+xdr_dec_string (xdr_dec_t * xdr, uint8_t ** strp)
+{
+	int len;
+	char *str;
+	int err;
+	if (xdr == NULL || strp == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > 0) {
+		str = kmalloc (len + 1, GFP_KERNEL);
+		if (str == NULL)
+			return -ENOMEM;
+		str[len] = '\0';
+		memcpy (str, (xdr->stream + xdr->curloc), len);
+		xdr->curloc += len;
+
+		*strp = str;
+	} else {
+		*strp = NULL;
+	}
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+/* non-mallocing version */
+int
+xdr_dec_string_nm (xdr_dec_t * xdr, uint8_t * string, size_t l)
+{
+	int len;
+	int err;
+	if (xdr == NULL || string == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len > 0) {
+		memcpy (string, (xdr->stream + xdr->curloc), MIN (len, l));
+		if (l > len) {
+			string[len] = '\0';
+		}
+		string[l - 1] = '\0';
+	} else {
+		string[0] = '\0';
+	}
+
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_string_ag (xdr_dec_t * xdr, uint8_t ** s, uint16_t * bl)
+{
+	int len;
+	int err;
+	if (xdr == NULL || s == NULL || bl == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_STRING)
+		return -ENOMSG;
+	xdr->curloc = 1;
+
+	len = be16_to_cpu (*((uint16_t *) (xdr->stream + xdr->curloc)));
+	xdr->curloc += 2;
+
+	if (len == 0) {		/* empty string */
+		**s = '\0';
+		*(xdr->stream) = XDR_NULL;
+		return 0;
+	}
+
+	if (len >= *bl) {	/* grow s */
+		void *temp;
+		temp = xdr_realloc (*s, len + 1, *bl);
+		if (temp == NULL)
+			return -ENOMEM;
+		*bl = len + 1;
+		*s = temp;
+	}
+
+	memcpy (*s, (xdr->stream + xdr->curloc), len);
+	(*s)[len] = '\0';
+
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_list_start (xdr_dec_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_LIST_START)
+		return -ENOMSG;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
+
+int
+xdr_dec_list_stop (xdr_dec_t * xdr)
+{
+	int err;
+	if (xdr == NULL)
+		return -EINVAL;
+	if (*(xdr->stream) == XDR_NULL) {
+		if ((err = get_next (xdr)) != 0)
+			return err;
+	}
+	if (*(xdr->stream) != XDR_LIST_STOP)
+		return -ENOMSG;
+	/* read the item out, mark that */
+	*(xdr->stream) = XDR_NULL;
+	return 0;
+}
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_io.c linux-patched/fs/gfs_locking/lock_gulm/xdr_io.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_io.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_io.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,169 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * does the lowest level of reads and writes.
+ * In kernel and/or userspace.
+ */
+
+#include "xdr.h"
+
+#ifdef __KERNEL__
+#ifdef __linux__
+#include <linux/net.h>
+#include <linux/in.h>
+#include <linux/socket.h>
+#include <net/sock.h>
+#include "asm/uaccess.h"
+
+/**
+ * do_tfer - transfers data over a socket
+ * @sock: < socket
+ * @iov: <> iovec of buffers
+ * @n:    < how many iovecs
+ * @size: < total data size to send/recv
+ * @dir:  < send or recv
+ * @timeout: < how many sec to wait. 0 == forever.
+ * 
+ * Returns: <0: Error
+ *         >=0: Bytes transfered
+ */
+static int
+do_tfer (struct socket *sock, struct iovec *iov, int n, int size, int dir)
+{
+	unsigned long flags;
+	sigset_t oldset;
+	struct msghdr m;
+	mm_segment_t fs;
+	int rv, moved = 0;
+
+	fs = get_fs ();
+	set_fs (get_ds ());
+
+	/* XXX do I still want the signal stuff? */
+	spin_lock_irqsave (&current->sighand->siglock, flags);
+	oldset = current->blocked;
+	siginitsetinv (&current->blocked,
+		       sigmask (SIGKILL) | sigmask (SIGTERM));
+	recalc_sigpending ();
+	spin_unlock_irqrestore (&current->sighand->siglock, flags);
+
+	memset (&m, 0, sizeof (struct msghdr));
+	for (;;) {
+		m.msg_iov = iov;
+		m.msg_iovlen = n;
+		m.msg_flags = MSG_NOSIGNAL;
+
+		if (dir)
+			rv = sock_sendmsg (sock, &m, size - moved);
+		else
+			rv = sock_recvmsg (sock, &m, size - moved, 0);
+
+		if (rv <= 0)
+			goto out_err;
+		moved += rv;
+
+		if (moved >= size)
+			break;
+
+		/* adjust iov's for next transfer */
+		while (iov->iov_len == 0) {
+			iov++;
+			n--;
+		}
+
+	}
+	rv = moved;
+      out_err:
+	spin_lock_irqsave (&current->sighand->siglock, flags);
+	current->blocked = oldset;
+	recalc_sigpending ();
+	spin_unlock_irqrestore (&current->sighand->siglock, flags);
+
+	set_fs (fs);
+
+	return rv;
+}
+
+size_t
+xdr_send (struct socket * sock, void *buf, size_t size)
+{
+	struct iovec iov;
+	int res;
+
+	iov.iov_base = buf;
+	iov.iov_len = size;
+
+	res = do_tfer (sock, &iov, 1, size, 1);
+
+	return res;
+}
+
+size_t
+xdr_recv (struct socket * sock, void *buf, size_t size)
+{
+	struct iovec iov;
+	int res;
+
+	iov.iov_base = buf;
+	iov.iov_len = size;
+
+	res = do_tfer (sock, &iov, 1, size, 0);
+
+	return res;
+}
+
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+
+#include <errno.h>
+#include <sys/types.h>
+#include <sys/socket.h>
+
+ssize_t
+xdr_recv (int fd, void *buf, size_t len)
+{
+	ssize_t cnt = 0;
+	size_t ttl = 0;
+	while (len > 0) {
+		cnt = recv (fd, buf, len, 0);
+		if (cnt == 0)
+			return 0;
+		if (cnt < 0)
+			return -errno;
+		len -= cnt;
+		buf += cnt;
+		ttl += cnt;
+	}
+	return ttl;
+}
+
+ssize_t
+xdr_send (int fd, void *buf, size_t len)
+{
+	ssize_t cnt = 0;
+	size_t ttl = 0;
+	while (len > 0) {
+		cnt = send (fd, buf, len, 0);
+		if (cnt == 0)
+			return 0;
+		if (cnt < 0)
+			return -errno;
+		len -= cnt;
+		buf += cnt;
+		ttl += cnt;
+	}
+	return ttl;
+}
+
+#endif /*__KERNEL__*/
diff -urN linux-orig/fs/gfs_locking/lock_gulm/xdr_socket.c linux-patched/fs/gfs_locking/lock_gulm/xdr_socket.c
--- linux-orig/fs/gfs_locking/lock_gulm/xdr_socket.c	1969-12-31 18:00:00.000000000 -0600
+++ linux-patched/fs/gfs_locking/lock_gulm/xdr_socket.c	2004-09-08 13:26:32.000000000 -0500
@@ -0,0 +1,82 @@
+/******************************************************************************
+*******************************************************************************
+**
+**  Copyright (C) Sistina Software, Inc.  1997-2003  All rights reserved.
+**  Copyright (C) 2004 Red Hat, Inc.  All rights reserved.
+**
+**  This copyrighted material is made available to anyone wishing to use,
+**  modify, copy, or redistribute it subject to the terms and conditions
+**  of the GNU General Public License v.2.
+**
+*******************************************************************************
+******************************************************************************/
+
+/*
+ * This file opens and closes a socket.
+ * In kernel and/or userspace.
+ */
+
+#include "xdr.h"
+
+#ifdef __KERNEL__
+#ifdef __linux__
+
+int
+xdr_open (xdr_socket * xsk)
+{
+	return sock_create (AF_INET6, SOCK_STREAM, 0, xsk);
+}
+
+int
+xdr_connect (struct sockaddr_in6 *adr, xdr_socket xsk)
+{
+	return xsk->ops->connect (xsk,
+				  (struct sockaddr *) adr,
+				  sizeof (struct sockaddr_in6), 0);
+}
+
+void
+xdr_close (xdr_socket * xsk)
+{
+	if (*xsk == NULL)
+		return;
+	sock_release (*xsk);
+	*xsk = NULL;
+}
+
+#endif /*__linux__*/
+#else /*__KERNEL__*/
+
+int
+xdr_open (xdr_socket * xsk)
+{
+	int sk;
+	sk = socket (AF_INET6, SOCK_STREAM, 0);
+	if (sk < 0)
+		return -errno;
+	*xsk = sk;
+	return 0;
+}
+
+int
+xdr_connect (struct sockaddr_in6 *adr, xdr_socket xsk)
+{
+	int err;
+	err =
+	    connect (xsk, (struct sockaddr *) adr,
+		     sizeof (struct sockaddr_in6));
+	if (err < 0)
+		return -errno;
+	return 0;
+}
+
+void
+xdr_close (xdr_socket * xsk)
+{
+	if (*xsk < 0)
+		return;
+	close (*xsk);
+	*xsk = -1;
+}
+
+#endif /*__KERNEL__*/
