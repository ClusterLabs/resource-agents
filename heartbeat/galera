#!/bin/sh
#
# Copyright (c) 2014 David Vossel <davidvossel@gmail.com>
#               2015-2017 Damien Ciabrini <dciabrin@redhat.com>
#                    All Rights Reserved.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of version 2 of the GNU General Public License as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it would be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# Further, this software is distributed without any warranty that it is
# free of the rightful claim of any third person regarding infringement
# or the like.  Any license provided herein, whether implied or
# otherwise, applies only to this software file.  Patent licenses, if
# any, provided herein do not apply to combinations of this program with
# other software, or any other product whatsoever.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write the Free Software Foundation,
# Inc., 59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
#

##
# README.
# 
# This agent only supports being configured as a multistate Master
# resource.
#
# Slave vs Master role:
#
# The 'Slave' role exists as a means to determine which galera
# instance is the most up-to-date. The most up-to-date node will be
# used to bootstrap a galera cluster that has no current members.
#
# The first galera instance is started during the promotion to the
# Master role. This initial promotion only takes place once all
# the nodes in the 'wsrep_cluster_address' connection address
# have reported their local database state.
#
# Once the first Master instance has bootstrapped the galera cluster,
# the other nodes will join the cluster and start synchronizing via
# SST. They will stay in Slave role as long SST is in progress. Their
# promotion to Master will be triggered as soon as a monitor operation
# detects that synchronization is finished.
#
# Example: Create a galera cluster using nodes rhel7-node1 rhel7-node2 rhel7-node3
#
# pcs resource create db galera enable_creation=true \
# wsrep_cluster_address="gcomm://rhel7-auto1,rhel7-auto2,rhel7-auto3" meta master-max=3 --master
#
# By setting the 'enable_creation' option, the database will be automatically 
# generated at startup. The meta attribute 'master-max=3' means that all 3
# nodes listed in the wsrep_cluster_address list will be allowed to connect
# to the galera cluster and perform replication.
#
# NOTE: If you have more nodes in the pacemaker cluster then you wish
# to have in the galera cluster, make sure to use location contraints to prevent
# pacemaker from attempting to place a galera instance on a node that is
# not in the 'wsrep_cluster_address" list. 
#
##

#######################################################################
# Initialization:

: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs
. ${OCF_FUNCTIONS_DIR}/mysql-common.sh

# It is common for some galera instances to store
# check user that can be used to query status
# in this file
if [ -f "/etc/sysconfig/clustercheck" ]; then
    . /etc/sysconfig/clustercheck
elif [ -f "/etc/default/clustercheck" ]; then
    . /etc/default/clustercheck
fi

#######################################################################

usage() {
  cat <<UEND
usage: $0 (start|stop|validate-all|meta-data|monitor|promote|demote)

$0 manages a galera Database as an HA resource.

The 'start' operation starts the database.
The 'stop' operation stops the database.
The 'status' operation reports whether the database is running
The 'monitor' operation reports whether the database seems to be working
The 'promote' operation makes this mysql server run as master
The 'demote' operation makes this mysql server run as slave
The 'validate-all' operation reports whether the parameters are valid

UEND
}

meta_data() {
   cat <<END
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="galera">
<version>1.0</version>

<longdesc lang="en">
Resource script for managing galara database.
</longdesc>
<shortdesc lang="en">Manages a galara instance</shortdesc>
<parameters>

<parameter name="binary" unique="0" required="0">
<longdesc lang="en">
Location of the MySQL server binary
</longdesc>
<shortdesc lang="en">MySQL server binary</shortdesc>
<content type="string" default="${OCF_RESKEY_binary_default}" />
</parameter>

<parameter name="client_binary" unique="0" required="0">
<longdesc lang="en">
Location of the MySQL client binary
</longdesc>
<shortdesc lang="en">MySQL client binary</shortdesc>
<content type="string" default="${OCF_RESKEY_client_binary_default}" />
</parameter>

<parameter name="config" unique="0" required="0">
<longdesc lang="en">
Configuration file
</longdesc>
<shortdesc lang="en">MySQL config</shortdesc>
<content type="string" default="${OCF_RESKEY_config_default}" />
</parameter>

<parameter name="datadir" unique="0" required="0">
<longdesc lang="en">
Directory containing databases
</longdesc>
<shortdesc lang="en">MySQL datadir</shortdesc>
<content type="string" default="${OCF_RESKEY_datadir_default}" />
</parameter>

<parameter name="user" unique="0" required="0">
<longdesc lang="en">
User running MySQL daemon
</longdesc>
<shortdesc lang="en">MySQL user</shortdesc>
<content type="string" default="${OCF_RESKEY_user_default}" />
</parameter>

<parameter name="group" unique="0" required="0">
<longdesc lang="en">
Group running MySQL daemon (for logfile and directory permissions)
</longdesc>
<shortdesc lang="en">MySQL group</shortdesc>
<content type="string" default="${OCF_RESKEY_group_default}"/>
</parameter>

<parameter name="log" unique="0" required="0">
<longdesc lang="en">
The logfile to be used for mysqld.
</longdesc>
<shortdesc lang="en">MySQL log file</shortdesc>
<content type="string" default="${OCF_RESKEY_log_default}"/>
</parameter>

<parameter name="pid" unique="0" required="0">
<longdesc lang="en">
The pidfile to be used for mysqld.
</longdesc>
<shortdesc lang="en">MySQL pid file</shortdesc>
<content type="string" default="${OCF_RESKEY_pid_default}"/>
</parameter>

<parameter name="socket" unique="0" required="0">
<longdesc lang="en">
The socket to be used for mysqld.
</longdesc>
<shortdesc lang="en">MySQL socket</shortdesc>
<content type="string" default="${OCF_RESKEY_socket_default}"/>
</parameter>

<parameter name="enable_creation" unique="0" required="0">
<longdesc lang="en">
If the MySQL database does not exist, it will be created
</longdesc>
<shortdesc lang="en">Create the database if it does not exist</shortdesc>
<content type="boolean" default="${OCF_RESKEY_enable_creation_default}"/>
</parameter>

<parameter name="additional_parameters" unique="0" required="0">
<longdesc lang="en">
Additional parameters which are passed to the mysqld on startup.
(e.g. --skip-external-locking or --skip-grant-tables)
</longdesc>
<shortdesc lang="en">Additional parameters to pass to mysqld</shortdesc>
<content type="string" default="${OCF_RESKEY_additional_parameters_default}"/>
</parameter>


<parameter name="wsrep_cluster_address" unique="0" required="1">
<longdesc lang="en">
The galera cluster address. This takes the form of:
gcomm://node,node,node

Only nodes present in this node list will be allowed to start a galera instance.
The galera node names listed in this address are expected to match valid
pacemaker node names. If both names need to differ, you must provide a
mapping in option cluster_host_map.
</longdesc>
<shortdesc lang="en">Galera cluster address</shortdesc>
<content type="string" default=""/>
</parameter>

<parameter name="cluster_host_map" unique="0" required="0">
<longdesc lang="en">
A mapping of pacemaker node names to galera node names.

To be used when both pacemaker and galera names need to differ,
(e.g. when galera names map to IP from a specific network interface)
This takes the form of:
pcmk1:node.1.galera;pcmk2:node.2.galera;pcmk3:node.3.galera

where the galera resource started on node pcmk1 would be named
node.1.galera in the wsrep_cluster_address
</longdesc>
<shortdesc lang="en">Pacemaker to Galera name mapping</shortdesc>
<content type="string" default=""/>
</parameter>

<parameter name="check_user" unique="0" required="0">
<longdesc lang="en">
Cluster check user.
</longdesc>
<shortdesc lang="en">MySQL test user</shortdesc>
<content type="string" default="root" />
</parameter>

<parameter name="check_passwd" unique="0" required="0">
<longdesc lang="en">
Cluster check user password
</longdesc>
<shortdesc lang="en">check password</shortdesc>
<content type="string" default="" />
</parameter>

</parameters>

<actions>
<action name="start" timeout="120" />
<action name="stop" timeout="120" />
<action name="status" timeout="60" />
<action name="monitor" depth="0" timeout="30" interval="20" />
<action name="monitor" role="Master" depth="0" timeout="30" interval="10" />
<action name="monitor" role="Slave" depth="0" timeout="30" interval="30" />
<action name="monitor" role="Slave" depth="0" timeout="30" interval="8" on-fail="block"/>
<action name="promote" timeout="300" />
<action name="demote" timeout="120" />
<action name="validate-all" timeout="5" />
<action name="meta-data" timeout="5" />
</actions>
</resource-agent>
END
}

get_option_variable()
{
    local key=$1

    $MYSQL $MYSQL_OPTIONS_CHECK  -e "SHOW VARIABLES like '$key';" | tail -1
}

get_status_variable()
{
    local key=$1

    $MYSQL $MYSQL_OPTIONS_CHECK -e "show status like '$key';" | tail -1
}

set_bootstrap_node()
{
    local node=$1

    ${HA_SBIN_DIR}/crm_attribute -N $node -l reboot --name "${INSTANCE_ATTR_NAME}-bootstrap" -v "true"
}

clear_bootstrap_node()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-bootstrap" -D
}

is_bootstrap()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-bootstrap" -Q 2>/dev/null

}

set_no_grastate()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-no-grastate" -v "true"
}

clear_no_grastate()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-no-grastate" -D
}

is_no_grastate()
{
    local node=$1
    ${HA_SBIN_DIR}/crm_attribute -N $node -l reboot --name "${INSTANCE_ATTR_NAME}-no-grastate" -Q 2>/dev/null
}

clear_last_commit()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-last-committed" -D
}

set_last_commit()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-last-committed" -v $1
}

get_last_commit()
{
    local node=$1

    if [ -z "$node" ]; then
       ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-last-committed" -Q 2>/dev/null
    else 
       ${HA_SBIN_DIR}/crm_attribute -N $node -l reboot --name "${INSTANCE_ATTR_NAME}-last-committed" -Q 2>/dev/null
    fi
}

set_sync_needed()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-sync-needed" -v "true"
}

clear_sync_needed()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-sync-needed" -D
}

check_sync_needed()
{
    ${HA_SBIN_DIR}/crm_attribute -N $NODENAME -l reboot --name "${INSTANCE_ATTR_NAME}-sync-needed" -Q &>/dev/null
}


# This function is called when a mysqld server is running
# and attribute sync-needed is set in the CIB
monitor_sync_status()
{
    local promote_allowed=$1

    # if the pidfile is created, mysqld is up and running
    # an IST might still be in progress, check wsrep status
    if [ -e $OCF_RESKEY_pid ]; then
        local cluster_status=$(get_status_variable "wsrep_cluster_status")
        local state=$(get_status_variable "wsrep_local_state")
        local ready=$(get_status_variable "wsrep_ready")

        if [ -z "$cluster_status" -o -z "$state" -o -z "$ready" ]; then
            ocf_exit_reason "Unable to retrieve state transfer status, verify check_user '$OCF_RESKEY_check_user' has permissions to view status"
            return $OCF_ERR_GENERIC
        fi

        if [ "$cluster_status" != "Primary" ]; then
            ocf_exit_reason "local node <${NODENAME}> is started, but not in primary mode. Unknown state."
            return $OCF_ERR_GENERIC
        fi

        # when sync is finished, change resource state if requested
        if [ "$ready" = "ON" ] && [ "$state" = "4" -o "$state" = "2" ]; then
            if ocf_is_true "$promote_allowed"; then
                clear_sync_needed
                set_master_score
            fi
        fi
    fi

    # if we pass here, an IST or SST is still in progress
    return $OCF_SUCCESS
}

is_primary()
{
    cluster_status=$(get_status_variable "wsrep_cluster_status")
    if [ "$cluster_status" = "Primary" ]; then
        return 0
    fi

    if [ -z "$cluster_status" ]; then
        ocf_exit_reason "Unable to retrieve wsrep_cluster_status, verify check_user '$OCF_RESKEY_check_user' has permissions to view status"
    else
        ocf_log info "Galera instance wsrep_cluster_status=${cluster_status}"
    fi
    return 1
}

is_readonly()
{
    local res=$(get_option_variable "read_only")

    if ! ocf_is_true "$res"; then
        return 1
    fi

    cluster_status=$(get_status_variable "wsrep_cluster_status")
    if ! [ "$cluster_status" = "Disconnected" ]; then
        return 1
    fi

    return 0
}

master_exists()
{
    if [ "$__OCF_ACTION" = "demote" ]; then
        # We don't want to detect master instances during demote.
        # 1. we could be detecting ourselves as being master, which is no longer the case.
        # 2. we could be detecting other master instances that are in the process of shutting down.
        # by not detecting other master instances in "demote" we are deferring this check
        # to the next recurring monitor operation which will be much more accurate
        return 1
    fi
    # determine if a master instance is already up and is healthy
    crm_mon --as-xml | grep "resource.*id=\"${OCF_RESOURCE_INSTANCE}\".*role=\"Master\".*active=\"true\".*orphaned=\"false\".*failed=\"false\"" > /dev/null 2>&1
    return $?
}

clear_master_score()
{
    local node=$1
    if [ -z "$node" ]; then
        $CRM_MASTER -D
    else 
        $CRM_MASTER -D -N $node
    fi
}

set_master_score()
{
    local node=$1

    if [ -z "$node" ]; then
        $CRM_MASTER -v 100
    else 
        $CRM_MASTER -N $node -v 100
    fi
}

is_master()
{
    local node=$1

    if [ -z "$node" ]; then
        $CRM_MASTER -Q &>/dev/null
    else
        $CRM_MASTER -N $node -Q &>/dev/null
    fi
}

is_sync_monitor()
{
    # We can't use a dedicated op name for the sync monitor op, nor we
    # can distinguish it based on a specific depth value. So we assume
    # that this is the only monitor op that has on-fail=block
    [ "$OCF_RESKEY_CRM_meta_on_fail" = "block" ]
}

is_managed()
{
    ! (crm_resource -Q -r $OCF_RESOURCE_INSTANCE -N $NODENAME --meta -g is-managed 2>/dev/null | grep -q false)
}

last_probed_state()
{
    cibadmin -Q --xpath "//lrm_rsc_op[@id=\"${OCF_RESOURCE_INSTANCE}_last_0\" and @on_node=\"${NODENAME}\"]" 2>/dev/null | sed -n 's/.*rc-code="\([^"]*\)".*/\1/p'
}

greater_than_equal_long()
{
    # there are values we need to compare in this script
    # that are too large for shell -gt to process
    echo | awk -v n1="$1" -v n2="$2"  '{if (n1>=n2) printf ("true"); else printf ("false");}' |  grep -q "true"
}

galera_to_pcmk_name()
{
    local galera=$1
    if [ -z "$OCF_RESKEY_cluster_host_map" ]; then
        echo $galera
    else
        echo "$OCF_RESKEY_cluster_host_map" | tr ';' '\n' | tr -d ' ' | sed 's/:/ /' | awk -F' ' '$2=="'"$galera"'" {print $1;exit}'
    fi
}

pcmk_to_galera_name()
{
    local pcmk=$1
    if [ -z "$OCF_RESKEY_cluster_host_map" ]; then
        echo $pcmk
    else
        echo "$OCF_RESKEY_cluster_host_map" | tr ';' '\n' | tr -d ' ' | sed 's/:/ /' | awk -F' ' '$1=="'"$pcmk"'" {print $2;exit}'
    fi
}


detect_first_master()
{
    local best_commit=0
    local last_commit=0
    local missing_nodes=0
    local nodes=""
    local nodes_recovered=""
    local all_nodes
    local best_node_gcomm
    local best_node

    all_nodes=$(echo "$OCF_RESKEY_wsrep_cluster_address" | sed 's/gcomm:\/\///g' | tr -d ' ' | tr -s ',' ' ')
    best_node_gcomm=$(echo "$all_nodes" | sed 's/^.* \(.*\)$/\1/')
    best_node=$(galera_to_pcmk_name $best_node_gcomm)
    if [ -z "$best_node" ]; then
        ocf_log error "Could not determine initial best node from galera name <${best_node_gcomm}>."
        return
    fi

    # avoid selecting a recovered node as bootstrap if possible
    for node in $all_nodes; do
        local pcmk_node=$(galera_to_pcmk_name $node)
        if [ -z "$pcmk_node" ]; then
            ocf_log error "Could not determine pacemaker node from galera name <${node}>."
            return
        else
            node=$pcmk_node
        fi

        if is_no_grastate $node; then
            nodes_recovered="$nodes_recovered $node"
        else
            nodes="$nodes $node"
        fi
    done

    for node in $nodes_recovered $nodes; do
        last_commit=$(get_last_commit $node)

        if [ -z "$last_commit" ]; then
            ocf_log info "Waiting on node <${node}> to report database status before Master instances can start."
            missing_nodes=1
            continue
        fi

        # this means -1, or that no commit has occured yet.
        if [ "$last_commit" = "18446744073709551615" ]; then
            last_commit="0"
        fi

        greater_than_equal_long "$last_commit" "$best_commit"
        if [ $? -eq 0 ]; then
            best_node=$node
            best_commit=$last_commit
        fi

    done

    if [ $missing_nodes -eq 1 ]; then
        return
    fi

    ocf_log info "Promoting $best_node to be our bootstrap node"
    set_master_score $best_node
    set_bootstrap_node $best_node
}

detect_galera_pid()
{
    # detect the server process rather than the mysqld_safe script
    ps auxww | grep -v -e "${OCF_RESKEY_binary}" -e grep | grep -qe "--pid-file=$OCF_RESKEY_pid"
}

galera_status()
{
    local loglevel=$1
    local rc
    local running

    if [ -e $OCF_RESKEY_pid ]; then
        mysql_common_status $loglevel
        rc=$?
    else
        # if pidfile is not created, the server may
        # still be starting up, e.g. running SST
        detect_galera_pid
        running=$?
        if [ $running -eq 0 ]; then
            rc=$OCF_SUCCESS
        else
            ocf_log $loglevel "MySQL is not running"
            rc=$OCF_NOT_RUNNING
        fi
    fi

    return $rc
}

galera_start_nowait()
{
    local mysql_extra_params="$1"
    local pid
    local running

    ${OCF_RESKEY_binary} --defaults-file=$OCF_RESKEY_config \
    --pid-file=$OCF_RESKEY_pid \
    --socket=$OCF_RESKEY_socket \
    --datadir=$OCF_RESKEY_datadir \
    --log-error=$OCF_RESKEY_log \
    --user=$OCF_RESKEY_user $OCF_RESKEY_additional_parameters \
    $mysql_extra_params >/dev/null 2>&1 &
    pid=$!

    # Spin waiting for the server to be spawned.
    # Let the CRM/LRM time us out if required.
    start_wait=1
    while [ $start_wait = 1 ]; do
        if ! ps $pid > /dev/null 2>&1; then
            wait $pid
            ocf_exit_reason "MySQL server failed to start (pid=$pid) (rc=$?), please check your installation"
            return $OCF_ERR_GENERIC
        fi
        detect_galera_pid
        running=$?
        if [ $running -eq 0 ]; then
            start_wait=0
        else
            ocf_log info "MySQL is not running"
        fi
        sleep 2
    done

    return $OCF_SUCCESS
}

galera_start_local_node()
{
    local rc
    local extra_opts
    local bootstrap

    bootstrap=$(is_bootstrap)

    master_exists
    if [ $? -eq 0 ]; then
        # join without bootstrapping
        ocf_log info "Node <${NODENAME}> is joining the cluster"
        extra_opts="--wsrep-cluster-address=${OCF_RESKEY_wsrep_cluster_address}"
    elif ocf_is_true $bootstrap; then
        ocf_log info "Node <${NODENAME}> is bootstrapping the cluster"
        extra_opts="--wsrep-cluster-address=gcomm://"
    else
        ocf_exit_reason "Failure, Attempted to join cluster of $OCF_RESOURCE_INSTANCE before master node has been detected."
        clear_last_commit
        return $OCF_ERR_GENERIC
    fi

    # clear last_commit before we start galera to make sure there
    # won't be discrepency between the cib and galera if this node
    # processes a few transactions and fails before we detect it
    clear_last_commit

    mysql_common_prepare_dirs

    # At start time, if galera requires a SST rather than an IST, the
    # mysql server's pidfile won't be available until SST finishes,
    # which can be longer than the start timeout.  So we only check
    # bootstrap node extensively. Joiner nodes are monitored in a
    # dedicated "monitor" op
    if ocf_is_true $bootstrap; then
        # start server and wait until it's up and running
        mysql_common_start "$extra_opts"
        rc=$?
        if [ $rc != $OCF_SUCCESS ]; then
            return $rc
        fi

        mysql_common_status info
        rc=$?

        if [ $rc != $OCF_SUCCESS ]; then
            ocf_exit_reason "Failed initial monitor action"
            return $rc
        fi

        is_readonly
        if [ $? -eq 0 ]; then
            ocf_exit_reason "Failure. Master instance started in read-only mode, check configuration."
            return $OCF_ERR_GENERIC
        fi

        is_primary
        if [ $? -ne 0 ]; then
            ocf_exit_reason "Failure. Master instance started, but is not in Primary mode."
            return $OCF_ERR_GENERIC
        fi

        clear_bootstrap_node
        clear_no_grastate
    else
        # only start server, defer full checks to "monitor" op
        galera_start_nowait "$extra_opts"
        rc=$?
        if [ $rc != $OCF_SUCCESS ]; then
            return $rc
        fi

        set_sync_needed
        # attribute no-grastate will be cleared once the joiner
        # has finished syncing and is promoted to Master
    fi

    ocf_log info "Galera started"
    return $OCF_SUCCESS
}

detect_last_commit()
{
    local last_commit
    local recover_args="--defaults-file=$OCF_RESKEY_config \
                        --pid-file=$OCF_RESKEY_pid \
                        --socket=$OCF_RESKEY_socket \
                        --datadir=$OCF_RESKEY_datadir \
                        --user=$OCF_RESKEY_user"
    local recovery_file_regex='s/.*WSREP\:.*position\s*recovery.*--log_error='\''\([^'\'']*\)'\''.*/\1/p'
    local recovered_position_regex='s/.*WSREP\:\s*[R|r]ecovered\s*position.*\:\(.*\)\s*$/\1/p'

    ocf_log info "attempting to detect last commit version by reading ${OCF_RESKEY_datadir}/grastate.dat"
    last_commit="$(cat ${OCF_RESKEY_datadir}/grastate.dat | sed -n 's/^seqno.\s*\(.*\)\s*$/\1/p')"
    if [ -z "$last_commit" ] || [ "$last_commit" = "-1" ]; then
        local tmp=$(mktemp)
        chown $OCF_RESKEY_user:$OCF_RESKEY_group $tmp

        # if we pass here because grastate.dat doesn't exist,
        # try not to bootstrap from this node if possible
        if [ ! -f ${OCF_RESKEY_datadir}/grastate.dat ]; then
            set_no_grastate
        fi

        ocf_log info "now attempting to detect last commit version using 'mysqld_safe --wsrep-recover'"

        ${OCF_RESKEY_binary} $recover_args --wsrep-recover --log-error=$tmp 2>/dev/null

        last_commit="$(cat $tmp | sed -n $recovered_position_regex | tail -1)"
        if [ -z "$last_commit" ]; then
            # Galera uses InnoDB's 2pc transactions internally. If
            # server was stopped in the middle of a replication, the
            # recovery may find a "prepared" XA transaction in the
            # redo log, and mysql won't recover automatically

            local recovery_file="$(cat $tmp | sed -n $recovery_file_regex)"
            if [ -e $recovery_file ]; then
                cat $recovery_file | grep -q -E '\[ERROR\]\s+Found\s+[0-9]+\s+prepared\s+transactions!' 2>/dev/null
                if [ $? -eq 0 ]; then
                    # we can only rollback the transaction, but that's OK
                    # since the DB will get resynchronized anyway
                    ocf_log warn "local node <${NODENAME}> was not shutdown properly. Rollback stuck transaction with --tc-heuristic-recover"
                    ${OCF_RESKEY_binary} $recover_args --wsrep-recover \
                                         --tc-heuristic-recover=rollback --log-error=$tmp 2>/dev/null

                    last_commit="$(cat $tmp | sed -n $recovered_position_regex | tail -1)"
                    if [ ! -z "$last_commit" ]; then
                        ocf_log warn "State recovered. force SST at next restart for full resynchronization"
                        rm -f ${OCF_RESKEY_datadir}/grastate.dat
                        # try not to bootstrap from this node if possible
                        set_no_grastate
                    fi
                fi
            fi
        fi
        rm -f $tmp
    fi

    if [ ! -z "$last_commit" ]; then
        ocf_log info "Last commit version found:  $last_commit"
        set_last_commit $last_commit
        return $OCF_SUCCESS
    else
        ocf_exit_reason "Unable to detect last known write sequence number"
        clear_last_commit
        return $OCF_ERR_GENERIC
    fi
}

galera_promote()
{
    local rc
    local extra_opts
    local bootstrap

    master_exists
    if [ $? -ne 0 ]; then
        # promoting the first master will bootstrap the cluster
        if is_bootstrap; then
            galera_start_local_node
            rc=$?
            return $rc
        else
            ocf_exit_reason "Attempted to start the cluster without being a bootstrap node."
            return $OCF_ERR_GENERIC
        fi
    else
        # promoting other masters only performs sanity checks
        # as the joining nodes were started during the "monitor" op
        if ! check_sync_needed; then
            # sync is done, clear info about last startup
            ocf_log info "local node synced with the cluster"
            clear_no_grastate
            return $OCF_SUCCESS
        else
            ocf_exit_reason "Attempted to promote local node while sync was still needed."
            return $OCF_ERR_GENERIC
        fi
    fi
}

galera_demote()
{
    mysql_common_stop
    rc=$?
    if [ $rc -ne $OCF_SUCCESS ] && [ $rc -ne $OCF_NOT_RUNNING ]; then
        ocf_exit_reason "Failed to stop Master galera instance during demotion to Master"
        return $rc
    fi

    # if this node was previously a bootstrap node, that is no longer the case.
    clear_bootstrap_node
    clear_last_commit
    clear_no_grastate

    # Clear master score here rather than letting pacemaker do so once
    # demote finishes. This way a promote cannot take place right
    # after this demote even if pacemaker is requested to do so. It
    # will first have to run a start/monitor op, to reprobe the state
    # of the other galera nodes and act accordingly.
    # This start/monitor op will record the last commit when needed
    clear_master_score

    return $rc
}

galera_start()
{
    local rc
    local galera_node

    galera_node=$(pcmk_to_galera_name $NODENAME)
    if [ -z "$galera_node" ]; then
        ocf_exit_reason "Could not determine galera name from pacemaker node <${NODENAME}>."
        return $OCF_ERR_CONFIGURED
    fi

    echo $OCF_RESKEY_wsrep_cluster_address | grep -q -F $galera_node
    if [ $? -ne 0 ]; then
        ocf_exit_reason "local node <${NODENAME}> (galera node <${galera_node}>) must be a member of the wsrep_cluster_address <${OCF_RESKEY_wsrep_cluster_address}> to start this galera instance"
        return $OCF_ERR_CONFIGURED
    fi

    galera_status info
    if [ $? -ne $OCF_NOT_RUNNING ]; then
        ocf_exit_reason "master galera instance started outside of the cluster's control"
        return $OCF_ERR_GENERIC
    fi

    mysql_common_prepare_dirs

    if check_sync_needed; then
        ocf_log warn "Previous start failed during sync. force SST for full resynchronization"
        rm -f ${OCF_RESKEY_datadir}/grastate.dat
        clear_sync_needed
    fi

    detect_last_commit
    rc=$?
    if [ $rc -ne $OCF_SUCCESS ]; then
        return $rc
    fi

    master_exists
    if [ $? -eq 0 ]; then
        ocf_log info "Master instances are already up, local node will join in when started"
    else
        clear_master_score
        detect_first_master
    fi

    return $OCF_SUCCESS
}

# a probe runs all the monitor tests and updates the attributes
# according to the server state (e.g. sync-needed)
galera_probe()
{
    local rc

    galera_status info
    rc=$?
    if [ $rc -ne $OCF_SUCCESS ]; then
        clear_master_score
        return $rc
    fi

    # server is running, check synchronization status.

    if [ ! -e $OCF_RESKEY_pid ]; then
        # pidfile is not created yet, assume the server is still
        # starting up and performing an SST -> slave
        clear_master_score
        set_sync_needed
        return $OCF_SUCCESS
    else
        # ensure server is healthy, and update sync-needed flag
        # according to the server's wsrep sync status
        set_sync_needed
        monitor_sync_status true
        rc=$?
        if [ $rc -eq $OCF_SUCCESS ]; then
            # if sync is finished, a regular monitor op will validate
            # the master state
            check_sync_needed
            if [ $? -ne 0 ]; then
                galera_monitor
                rc=$?
            fi
        fi
        if [ $rc -ne $OCF_RUNNING_MASTER ];then
            clear_master_score
        fi
        return $rc
    fi
}

# This monitor function only perform state checks when attribute
# sync-needed is set. Failure will block automatic restart.
galera_sync_monitor()
{
    local rc
    local promote_allowed=$(is_managed && echo true)
    if [ -n "$1" ]; then
        promote_allowed="$1"
    fi

    # when a galera server is starting up, not all SST failures can be
    # recovered automatically (e.g. wsrep_sst_rsync crashing, leaving
    # a rsyncd process running), so we need a dedicated monitor action
    # to prevent the resource from restarting in case mysqld_safe
    # fails during startup
    check_sync_needed
    if [ $? -eq 0 ]; then
        galera_status err
        rc=$?
        if [ $rc -eq $OCF_SUCCESS ]; then
            # When the SST or IST is finished, clear sync flag and
            # promote the resource to Master.
            monitor_sync_status $promote_allowed
            rc=$?
            if [ $rc -eq $OCF_SUCCESS ]; then
                check_sync_needed
                if [ $? -eq 0 ]; then
                    # log progress if sync is still ongoing
                    ocf_log info "local node syncing"
                fi
            fi
        fi
    else
        # no sync to monitor, leave checks to regular monitor op
        # This function is called only during slave state, hence
        # the return code here
        rc=$OCF_SUCCESS
    fi

    return $rc
}

galera_monitor()
{
    local rc
    local galera_node
    local status_loglevel="err"

    # when sync is in progress, delegate real monitoring to
    # galera_sync_monitor, because any failure during sync must
    # prevent resource from restarting automatically
    check_sync_needed
    if [ $? -eq 0 ]; then
        return $OCF_SUCCESS
    fi

    # check whether mysql is running
    if ! is_master; then
        status_loglevel="info"
    fi
    galera_status $status_loglevel
    rc=$?

    if [ $rc -eq $OCF_NOT_RUNNING ]; then
        if is_managed; then
            # only perform these checks when starting up
            if ! is_master; then
                last_commit=$(get_last_commit $NODENAME)
                if [ -n "$last_commit" ];then
                    rc=$OCF_SUCCESS

                    master_exists
                    if [ $? -ne 0 ]; then
                        detect_first_master
                    else
                        # a master instance exists and is healthy.
                        # start this node and mark it as "pending sync"
                        ocf_log info "cluster is running. start local node to join in"
                        galera_start_local_node
                        rc=$?
                    fi
                fi
            fi
        else
            # when unmanaged, return "error" rather than "not running"
            # to recover state if mysqld is manually restarted
            rc=$OCF_ERR_GENERIC
        fi
        return $rc
    elif [ $rc -ne $OCF_SUCCESS ]; then
        return $rc
    fi

    # if we make it here, mysql is running. Check cluster status now.
    galera_node=$(pcmk_to_galera_name $NODENAME)
    if [ -z "$galera_node" ]; then
        ocf_exit_reason "Could not determine galera name from pacemaker node <${NODENAME}>."
        return $OCF_ERR_CONFIGURED
    fi

    echo $OCF_RESKEY_wsrep_cluster_address | grep -q -F $galera_node
    if [ $? -ne 0 ]; then
        ocf_exit_reason "local node <${NODENAME}> (galera node <${galera_node}>) is started, but is not a member of the wsrep_cluster_address <${OCF_RESKEY_wsrep_cluster_address}>"
        return $OCF_ERR_GENERIC
    fi

    is_primary
    if [ $? -ne 0 ]; then
        ocf_exit_reason "local node <${NODENAME}> is started, but not in primary mode. Unknown state."
        rc=$OCF_ERR_GENERIC
    else
        # galera is running, no need to sync: master state
        rc=$OCF_RUNNING_MASTER
    fi

    return $rc
}


galera_unmanaged_monitor()
{
    # In case of error, galera won't be restarted automatically when
    # it is unmanaged.  If for any reason mysqld is manually restarted
    # while the resource is still unmanaged, try to update the sync
    # flag according to the server's state to give monitor op a chance
    # to recover.

    if detect_galera_pid; then
        if [ ! -e $OCF_RESKEY_pid ]; then
            set_sync_needed
        else
            # We can't promote the resource while it is unmanaged, so
            # proceed with sync monitoring only if the resource was
            # already in Master state before being unmanaged
            if check_sync_needed && [ "$(last_probed_state)" = "$OCF_RUNNING_MASTER" ]; then
                galera_sync_monitor true
            fi
        fi
    fi

    # sync flag updated, continue with regular monitor op
    galera_monitor
}


galera_stop()
{
    local rc
    # make sure the process is stopped
    mysql_common_stop
    rc=$?

    clear_last_commit
    clear_master_score
    clear_bootstrap_node
    clear_sync_needed
    clear_no_grastate
    return $rc
}

galera_validate()
{
    if ! ocf_is_ms; then
        ocf_exit_reason "Galera must be configured as a multistate Master/Slave resource."
        return $OCF_ERR_CONFIGURED
    fi

    if [ -z "$OCF_RESKEY_wsrep_cluster_address" ]; then
        ocf_exit_reason "Galera must be configured with a wsrep_cluster_address value."
        return $OCF_ERR_CONFIGURED
    fi

    mysql_common_validate
}

case "$1" in
  meta-data)    meta_data
        exit $OCF_SUCCESS;;
  usage|help)   usage
        exit $OCF_SUCCESS;;
esac

galera_validate
rc=$?
LSB_STATUS_STOPPED=3
if [ $rc -ne 0 ]; then
    case "$1" in
        stop) exit $OCF_SUCCESS;;
        monitor) exit $OCF_NOT_RUNNING;;
        status) exit $LSB_STATUS_STOPPED;;
        *) exit $rc;;
    esac
fi

if [ -z "${OCF_RESKEY_check_passwd}" ]; then
    # This value is automatically sourced from /etc/sysconfig/checkcluster if available
    OCF_RESKEY_check_passwd=${MYSQL_PASSWORD}
fi
if [ -z "${OCF_RESKEY_check_user}" ]; then
    # This value is automatically sourced from /etc/sysconfig/checkcluster if available
    OCF_RESKEY_check_user=${MYSQL_USERNAME}
fi
: ${OCF_RESKEY_check_user="root"}

MYSQL_OPTIONS_CHECK="-nNE --user=${OCF_RESKEY_check_user}"
if [ -n "${OCF_RESKEY_check_passwd}" ]; then
    MYSQL_OPTIONS_CHECK="$MYSQL_OPTIONS_CHECK --password=${OCF_RESKEY_check_passwd}"
fi

# This value is automatically sourced from /etc/sysconfig/checkcluster if available
if [ -n "${MYSQL_HOST}" ]; then
    MYSQL_OPTIONS_CHECK="$MYSQL_OPTIONS_CHECK -h ${MYSQL_HOST}"
fi

# This value is automatically sourced from /etc/sysconfig/checkcluster if available
if [ -n "${MYSQL_PORT}" ]; then
    MYSQL_OPTIONS_CHECK="$MYSQL_OPTIONS_CHECK -P ${MYSQL_PORT}"
fi



# What kind of method was invoked?
case "$1" in
  start)    galera_start;;
  stop)     galera_stop;;
  status)   galera_status err;;
  monitor)
      if ocf_is_probe; then
          galera_probe
      elif is_sync_monitor; then
          galera_sync_monitor
      elif ! is_managed; then
          galera_unmanaged_monitor
      else
          galera_monitor
      fi
      ;;
  promote)  galera_promote;;
  demote)   galera_demote;;
  validate-all) exit $OCF_SUCCESS;;

 *)     usage
        exit $OCF_ERR_UNIMPLEMENTED;;
esac

# vi:sw=4:ts=4:et:
